---
layout:		post
title:  	不均衡分类下的 ROC 与 PRC 曲线
subtitle:   曲线、面积的解释与利弊
date:       2020-01-11
author:     一轩明月
header-img: img/post-bg-code.jpg
catalog: 	 true
tags:
    - math
excerpt:    本文先行介绍分类任务的常用评断标准—— ROC 和 PRC 曲线。之后介绍了两个曲线下面积 ROC AUC 和 PRC AUC。指出 ROC 及其下面积在极端不均衡分类问题中，表现的有些过于乐观
---

绝大多数不均衡分类问题可以归结为：负样本太多，正样本太少。

ROC 和 PRC（Precision-Recall curves）曲线是在评估二分类模型效果时常用的两个诊断工具。

探索预测效果的时候可以画出曲线图权衡不同阈值下的模型表现。每幅图也可以直接用曲线下方面积表示，并直接进行比较。

本文主要内容有：

- 介绍作为二分类模型诊断工具的 ROC 曲线和 PRC 曲线
- 浓缩曲线信息，直接用于模型间比较的两个曲线下方面积（AUC），ROC AUC 和 PRC AUC
- ROC 与 ROC AUC 在少数类别样本很少的极端不均衡分类问题中，表现的有些过于乐观

本文所有示例代码在[这里](https://github.com/LibertyDream/deep_learning/blob/master/ROC_PRC_AUC.ipynb)

### 混淆矩阵

谈论 ROC 和 PRC 曲线前，需要介绍下混淆矩阵。

对于不均衡分类问题，多数类通常指结果消极的那一类（比如”无变化“，”测试结果不佳“），少数类则代表积极结果（比如”变化“，”测试结果优良“）。

混淆矩阵能带给我们对预测结果更深刻的体察，能分门别类的呈现哪些预测对了，哪些错了，错了的都犯了什么类型的错误。

最简单的混淆矩阵就是二分类问题的了，分为正类（class 1）和负类（class 2）两种。

这种混淆矩阵，每个单元格都有一个特定而好理解的名字

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-01-11-confusion_matrix.png)

构造 ROC 和 PRC 曲线的混淆矩阵就是由图中四个单元格组成的。有了对混淆矩阵的直观认识，就先来看看 ROC 曲线

### ROC 曲线与 ROC AUC

ROC（receiver operating characteristic）曲线是一种评定二分类模型对正类预测效果的曲线图。x 轴是假阳率（False Positive Rate, FPR），y 轴是真阳率（True Positive Rate, TPR）

- **ROC 曲线**：假阳（x）- 真阳（y）图

真阳率是真正例与真正例和假反例和（所有为正的样本）的比值

- **真阳率** = 真正例 / （真正例 + 假反例）

假阳率是假正例与假正例和真返例和（所有为负的样本）的比值

- **假阳率** = 假正例 / （假正例 + 真反例）

所以，ROC 曲线可以理解为正例里预见了多少（y 轴）对上反例说错了多少（x 轴）

理想情况下，当然希望是正例全都判断对的比例为 1（图像顶部），说错的反例占比为 0（图像左部）。这说明性能最好的最优分类器是在图像左上角（坐标 0，1）

- **性能优异（Perfect Skill）**：图像左上角的点

阈值是指判断归于正例还是反例的概率分割点，不论什么分类器默认是 0.5，介于输出半程（0 和 1 中间）。

因为阈值的存在，真阳率和假阳率之间存在着权衡，调节阈值基本是牺牲假阳率偏向真阳率，或是相反

选择不同阈值探求真正例和假正例分布效果，画在图上就是从左下角向右上角延伸，同时偏向左上角的曲线，即 ROC 曲线。

纯随机无分别能力的分类器在图像中是对角线，左起假阳率为 0，真阳率为 0（坐标 (0,0) 或者说全预判为假），右至假阳率为 1，真阳率为 1（坐标 (1,1) 或全预判为真）。如果绘制曲线在对角线以下，直观上性能比随机还差，表现为总说反话，这时可以对这种分类器结果取反。

ROC 曲线为我们检查不同阈值下分类器的真阳率和假阳率带来了便利。有人也许会为了修改分类模型的预测行为专选某个阈值。

总的来说， ROC 是很流行的分类器诊断工具，无论是平衡还是不平衡二分类问题，因为它不会偏向多数类或少数类。

可以用 Python 借助 sklearn 方法 [roc_curve()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html) 绘制 ROC 曲线。该方法接收两个参数，测试集的真值列表和对 class 1 的预测结果，按阈值返回假阳率、真阳率。

```python
# 计算 ROC
fpr, tpr, thresholds = roc_curve(testy, pos_probs)
```

绝大部分 scikit-learn 模型预测概率都是通过 `predict_proba()` 方法。

该方法会对测试集中的每个样本计算其从属各个类别的概率。正例概率预测值位于概率数组第二列，可以检索获取。

```python
# 预测概率
yhat = model.predict_proba(testX)
# 抽出预测为正的概率
pos_probs = yhat[:, 1]
```

可以手工做个数据集看一下随机分类器和逻辑回归模型的 ROC 曲线。

[make_classification()](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) 方法可以构造该分类场景下的数据集，这里我们针对二分类问题生产 1000 个样本（二分类，各类 500），然后将数据集分割为等大的训练集和测试集，方便拟合、评估模型

```python
# 构造二分类数据集
X, y = make_classfication(n_samples=1000, n_classes=2, random_state=1)
# 拆解为训练/测试集
trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)
```

逻辑回归模型利于演示的原因在于其预测概率值可以计量，不像其他非概率模型得先量化成数字。

```python
model = LogisticRegression(solver='lbfgs')
model.fit(trainX, trainy)
```

完整案例如下

```python
# 预测模型 ROC 曲线示例
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt

# 制作二分类数据集
X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)

# 分割为训练集和测试集
trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)

# 训练模型
model = LogisticRegression(solver='lbfgs')
model.fit(trainX, trainy)

# 预测概率
yhat = model.predict_proba(testX)

# 抽取正例预测概率
pos_pred = yhat[:,1]

# 画随机模型的 ROC
plt.plot([0,1], [0, 1], linestyle='--', label='No Skill')
# 计算模型 ROC
fpr, tpr, _ = roc_curve(testy, pos_pred)
# 画模型的 ROC
plt.plot(fpr, tpr, marker='.', label='Logistic')
# 坐标轴标签
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')

# 加上图例
plt.legend()
# 呈现图像
plt.show()
```

运行样例代码制作人工数据集，划分为训练集和测试集，之后训练逻辑回归模型并对测试集做预测

逻辑回归模型的 ROC 曲线如下所示（橘色带点），随机分类器是对角线

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-01-11-logistic_ROC.png)

知道了 ROC 曲线，就进一步研究一下曲线下方面积吧。

#### 曲线下方面积（AUC）

尽管 ROC 曲线作为诊断工具来讲很不错了，但如果要比对两类以上的曲线就变得有些麻烦了。

而曲线下方面积就很巧妙的通过一个值表示了所有阈值下的分类效果，这叫 ROC 曲线下面积或 ROC AUC 或 ROCAUC

面积值介于 0，1 之间。AUCROC 可以被理解为给定分类器，随机抽到正例排在反例前的概率。

该分数值可直接用于二分类分类器的比较。这一指标广泛用于不均衡问题下分类模型间的比较。

AUC 值可以通过 scikit-learn 里的 [roc_auc_score()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) 方法计算。和 `roc_cure()`方法一样， AUC 方法接收测试集真值列表与模型对正类的预测结果两个参数

```python
# 计算 ROC AUC
roc_auc = roc_auc_score(testy, pos_probs)
```

用同样的数据和逻辑回归模型做个展示样例

```python
# ROC AUC 示例
from sklearn.datasets import make_classification
from sklearn.dummy import DummyClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
# 制作二分类数据集
X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)
# 分割为训练集和测试集
trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)
# 随机模型，分层随机预测
model = DummyClassifier(strategy='stratified')
model.fit(trainX, trainy)
yhat = model.predict_proba(testX)
pos_probs = yhat[:, 1]
# 计算 ROCAUC
roc_auc = roc_auc_score(testy, pos_probs)
print('No Skill ROC AUC %.3f' % roc_auc)
# 训练模型
model = LogisticRegression(solver='lbfgs')
model.fit(trainX, trainy)
yhat = model.predict_proba(testX)
pos_probs = yhat[:, 1]
# 计算 ROCAUC
roc_auc = roc_auc_score(testy, pos_probs)
print('Logistic ROC AUC %.3f' % roc_auc)
```

运行示例，创建并分割数据集，拟合模型并对测试集做预测。从该示例中可以看到逻辑回归模型在人工数据集上的表现碾压随机分类器

```
No Skill ROC AUC 0.509
Logistic ROC AUC 0.903
```

用的虽多， ROC AUC 也不是没问题。

少数类样本极少的极端不均衡分类问题中，ROC AUC 很容易被误导，预测结果正确数多一点或少一点都会带来 ROC 曲线和 ROC AUC 值的巨大变动

此时的替代方案是准确召回曲线（precision-recall curve）及其下方面积。

### 准确-召回曲线与AUC

准确率量化了预测与事实相匹配的比例。计算方式是真正例除以真正例和假正例的和。

- **准确率**：真正例 / （真正例 + 假正例）

结果介于 0 （没准头）和 1 （完美预测）之间。

召回率量化了从所有实际为正的样本中尽可能多的找出正样本的能力。计算方式是真正例除以真正例和假反例（也就是真阳率）。

- **召回率**：真正例 / （真正例 + 假反例）

结果介于 0 （没找到一个）和 1 （全部找出）之间。

准确度和召回都聚焦在正类（少数类）上，不关心真假例（多数类），让我们可以鉴定分类器对少数类的分类表现。

准确-召回曲线（PR Curve）以准确率为 y 轴，召回率为 x 轴，根据概率阈值的取值变动画线。

- **PR Curve**：准确-召回图

理想中的模型应该在（1，1）坐标点上。性能优异的模型表现为尽量向该点靠近。随机模型则会呈现为一条水平线，取值为数据集内正例比例。平衡数据集是 0.5。

PR 曲线对少数类的关照使其成为很优秀的不均衡二分类模型诊断工具，在 ROC 过分乐观，数据集极端不均衡的条件下可以入药。

可以通过 scikit-learn 方法 [precision_recall_curve()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html) 计算曲线值，接收两个参数，测试集结果标签列表和模型对少数类的预测概率列表，返回准确率，召回率和划界概率阈值

```python
# 计算PRC
precision, recall, _ = precision_recall_curve(testy, pos_probs)
```

还是构造点数据举个例子看一下

```python
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_curve
import matplotlib.pyplot as plt

# 生成二分类数据集
X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)

# 划分训练集、测试集
trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)

# 训练模型
model = LogisticRegression(solver='lbfgs')
model.fit(trainX, trainy)

# 概率预测
yhat = model.predict_proba(testX)
# 取出正例概率
pos_pred = yhat[:,1]
# 计算随机模型的正例比例
no_skill = len(y[y==1]) / len(y)

# 绘制随机模型 PR 曲线
plt.plot([0,1], [no_skill, no_skill], linestyle='--', label='No Skill')
# 计算模型 PR 曲线值
precision, recall, _ = precision_recall_curve(testy, pos_pred)
# 绘制模型预测召回曲线
plt.plot(recall, precision, marker='.', label='Logistic')

# 坐标轴标签
plt.xlabel('Recall')
plt.ylabel('Precision')

# 图例与成像
plt.legend()
plt.show()
```

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-01-11-logistic_PRC.png)

知道了准确-召回曲线，再进一步看一下它的 AUC

#### 准确-召回 AUC

和 ROC AUC 类似，PR AUC 通过一个值对曲线所包含信息进行了凝练。

面积值可用于对二分类问题下不同模型间的比较，性能越好值越接近 1。

PR AUC 的值通过 scikit-learn 的 [auc()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html) 方法进行计算，召回率和准确率作为传入参数。

```python
# 计算 PR AUC
auc_score = auc(recall, precision)
```

来看个例子

```python
# PR AUC 计算 demo
from sklearn.datasets import make_classification
from sklearn.dummy import DummyClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import auc
# 构造二分类数据集
X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)
# 分割训练集与测试集
trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)
# 随机模型，分类随机预测
model = DummyClassifier(strategy='stratified')
model.fit(trainX, trainy)
yhat = model.predict_proba(testX)
pos_probs = yhat[:, 1]
# 计算 PR AUC
precision, recall, _ = precision_recall_curve(testy, pos_probs)
auc_score = auc(recall, precision)
print('No Skill PR AUC: %.3f' % auc_score)
# 训练模型
model = LogisticRegression(solver='lbfgs')
model.fit(trainX, trainy)
yhat = model.predict_proba(testX)
pos_probs = yhat[:, 1]
# 计算模型 PR AUC
precision, recall, _ = precision_recall_curve(testy, pos_probs)
auc_score = auc(recall, precision)
print('Logistic PR AUC: %.3f' % auc_score)
```

运行示例代码，创建分割数据集，训练模型，对测试集进行概率预估

这里逻辑回归的 PR AUC 在自己构造的数据集上达到了 0.898，随机模型得分 0.632

### 极端不均衡下的 ROC 与 PRC

这一部分，我们以一个例子看一下极端不均衡二分类问题下 ROC 和 PRC 的表现

首先还是使用 `make_classfication()` 方法创建 1000 个待分类样本，少数类与多数类的样本比例 1：100。这可以通过 `weights` 参数对各类样本比例进行设置。

这里分别设为 0.99 与 0.1，意味着 990 个 0 类样本，10 个 1 类样本。

```python
# 制作二分类数据集
X, y = make_classfication(n_samples=1000, n_classes=2, weights=[0.99, 0.01], random_state=1)
```

下一步分割训练集和测试集的时候，通过将 `stratify` 参数设为目标变量数组保证数据集的样本比例不变

```python
# 相同类别比例划分训练集，测试集
trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)
```

整合在一起，不均衡数据集的构建就完成了

```python
# 制备不均衡数据集
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
# 普通二分类数据集
X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.99, 0.01], random_state=1)
# 等比例划分数据集
trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)
# 数据摘要
print('Dataset: Class0=%d, Class1=%d' % (len(y[y==0]), len(y[y==1])))
print('Train: Class0=%d, Class1=%d' % (len(trainy[trainy==0]), len(trainy[trainy==1])))
print('Test: Class0=%d, Class1=%d' % (len(testy[testy==0]), len(testy[testy==1])))
```

运行示例代码，确保等比例划分数据集

```python
Dataset: Class0=985, Class1=15
Train: Class0=492, Class1=8
Test: Class0=493, Class1=7
```

下一步就和前文一样，训练一个逻辑回顾模型，看一下 ROC 和 ROC AUC，并与随机模型进行比较

```python
# 不均衡数据集上的 ROC 和 AUC
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.dummy import DummyClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from matplotlib import pyplot
 
# 绘制 ROC
def plot_roc_curve(test_y, naive_probs, model_probs):
    # 随机模型 ROC
	fpr, tpr, _ = roc_curve(test_y, naive_probs)
	pyplot.plot(fpr, tpr, linestyle='--', label='No Skill')
	# 逻辑回归 ROC
	fpr, tpr, _ = roc_curve(test_y, model_probs)
	pyplot.plot(fpr, tpr, marker='.', label='Logistic')
    
	# 坐标轴
	pyplot.xlabel('False Positive Rate')
	pyplot.ylabel('True Positive Rate')
	
    # 图例与成像
	pyplot.legend()
	pyplot.show()
 
# 普通二分类数据集
X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.99, 0.01], random_state=1)
# 等比例划分出训练集与测试集
trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)

# 随机模型，分类随机预测
model = DummyClassifier(strategy='stratified')
model.fit(trainX, trainy)
yhat = model.predict_proba(testX)
naive_probs = yhat[:, 1]
# 计算 AUC
roc_auc = roc_auc_score(testy, naive_probs)
print('No Skill ROC AUC %.3f' % roc_auc)

# 逻辑回归
model = LogisticRegression(solver='lbfgs')
model.fit(trainX, trainy)
yhat = model.predict_proba(testX)
model_probs = yhat[:, 1]
# 计算 AUC
roc_auc = roc_auc_score(testy, model_probs)
print('Logistic ROC AUC %.3f' % roc_auc)

# 绘制图像
plot_roc_curve(testy, naive_probs, model_probs)
```

运行示例代码，首先如前文所讲构建数据集，然后训练集上训练逻辑回归模型，在测试集上评估效果。随机模型作为对照。

ROC AUC 值也都计算给出，随机模型以 0.498 的结果落后于逻辑回归模型 0.869 的性能表现

```
No Skill ROC AUC 0.498
Logistic ROC AUC 0.869
```

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-01-11-logistic_no_skill_roc.png)

如法炮制，来看一下 PRC 与 PRC AUC

```python
# 不均衡数据集上的 PRC 与 PRC AUC
from sklearn.datasets import make_classification
from sklearn.dummy import DummyClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import auc
from matplotlib import pyplot
 
# 绘制 PRC
def plot_pr_curve(test_y, model_probs):
    # 随机模型 PRC
	no_skill = len(test_y[test_y==1]) / len(test_y)
	pyplot.plot([0,1],[no_skill, no_skill], linestyle='--', label='No Skill')
	# 逻辑回归 PRC
    precision, recall, _ = precision_recall_curve(testy, model_probs)
	pyplot.plot(recall, precision, marker='.', label='Logistic')
    
	# 坐标轴
	pyplot.xlabel('Recall')
	pyplot.ylabel('Precision')
	
    # 图例与成像
	pyplot.legend()
	pyplot.show()
 
# 普通二分类数据集
X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.99, 0.01], random_state=1)
# 等比例划分出训练集与测试集
trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)

# 随机模型，分类随机预测
model = DummyClassifier(strategy='stratified')
model.fit(trainX, trainy)
yhat = model.predict_proba(testX)
naive_probs = yhat[:, 1]
# 计算 PRC AUC
precision, recall, _ = precision_recall_curve(testy, naive_probs)
auc_score = auc(recall, precision)
print('No Skill PR AUC: %.3f' % auc_score)

# 逻辑回归
model = LogisticRegression(solver='lbfgs')
model.fit(trainX, trainy)
yhat = model.predict_proba(testX)
model_probs = yhat[:, 1]
# 计算 PRC AUC
precision, recall, _ = precision_recall_curve(testy, model_probs)
auc_score = auc(recall, precision)
print('Logistic PR AUC: %.3f' % auc_score)

# 绘制图像
plot_pr_curve(testy, model_probs)
```

这里我们能看到逻辑回归 PRC AUC 有 0.228，而随机模型只有 0.007

```
No Skill PR AUC: 0.007
Logistic PR AUC: 0.228
```

如果画出 PRC 会发现一些有趣的事，随机模型的表现如预期一样水平一条，而逻辑回归的之字形曲线最后趋近于随机模型，这和 ROC 讲的不一样啊

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-01-11-logistic_no_skill_prc.png)

要理解其中缘由，回想一下，PRC 关注的是少数类，ROC 关心的是全局，即少数类和多数类它都考虑

如果选定 0.5 作为分类阈值，并用逻辑回归模型对所有测试集样本进行预测，我们会看到它会将所有样本归为 0 类或多数类。这很容易验证，首先用模型对测试集打标签，然后统计一下类别标记分布

```python
yhat = model.predict(testX)
print(Counter(yhat))
```

画张正类的预测概率直方图，可以看到大多数概率值低于 0.5，所以被归为 0 类。

```python
pyplot.hist(pos_probs, bin=100)
pyplot.show()
```

整合一下，完整代码如下

```python
# 预测概率分布统计
from collections import Counter
from matplotlib import pyplot
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
# 普通二分类数据集
X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.99, 0.01], random_state=1)
# 等比例分割出训练集和测试集
trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)
# 训练模型
model = LogisticRegression(solver='lbfgs')
model.fit(trainX, trainy)
# 概率预测
yhat = model.predict_proba(testX)
# 抽取正类预测结果
pos_probs = yhat[:, 1]
# 标签预测
yhat = model.predict(testX)
# 统计标签分布
print(Counter(yhat))
# 预测概率直方图
pyplot.hist(pos_probs, bins=100)
pyplot.show()
```

运行示例代码，如我们所想，所有实例都被判定为主类

```
Counter({0: 500})
```

画出的 1 类预测概率直方图如下所示，绝大部分预测概率都小于 0.5，实际上更是接近 0。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-01-11-logistic_hist.png)

这意味着，除非精心挑选概率阈值，所有模型预测结果间的细微差别都会被抹平。如何选择阈值是一个重要课题。