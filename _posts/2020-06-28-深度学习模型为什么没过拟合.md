---
layout:		post
title:  	深度学习模型没有过拟合的秘密
subtitle:   
date:       2020-06-28
author:     一轩明月
header-img: img/post-bg-universe.jpg
catalog:    true
tags:
    - opinions
excerpt:    如果你也曾好奇，为什么深度神经网络能泛化应用到外部数据上，却没有出现过度拟合，读下去。
---

> 编译自：Are Deep Neural Networks Dramatically Overfitted，[Lilog](https://lilianweng.github.io/lil-log/)

如果你像我一样，带着传统机器学习的经验进入深度学习领域，可能会经常沉思这一问题：既然经典深度神经网络有这么多参数并且训练误差很容易臻至完美，它应该不无意外地出现严重的过拟合才对，它又怎么能对样本外的数据点具备泛化能力的呢？

思考为什么深度神经网络具备泛化能力的过程不知怎得使我想起 System Biology 上一篇有趣的论文——[“生物学家能修收音机吗？”](https://www.cell.com/cancer-cell/pdf/S1535-6108(02)00133-2.pdf)。如果一名生物学家打算像她研究生物系统一样去修理无线电机器，日子可能会很难过。因为整个无线电系统的机理没有显露出来，外露的局部小功能可能会给点提示但没什么可能呈现所有系统内部的交互与连接，更别提整体工作流了。无论你是否认为它和 DL 相关，都值得一读。

本文会介绍一些深度学习模型泛化能力和复杂度测定相关的研究工作。希望这有助于你理解为什么 DNN 能泛化。

# 压缩和模型选择的经典定理

假定我们手头有个分类问题和一个数据集，自然可以写很多模型来进行解决，从用线性回归的简单拟合到占用磁盘空间记忆整个数据集。哪个更好？如果只关心训练数据上的准确率（尤其是当测试数据大概率未知的时候），记忆法似乎最好——好吧，听起来有点不对。

实际在这种情境下，一个好模型要具备哪些类型的品质有很多经典定理可以给予指导。

## 奥卡姆剃刀

[奥卡姆剃刀](https://zh.wikipedia.org/wiki/奥卡姆剃刀)是一个寻求答案时的非正式原则，由[奥卡姆](https://zh.wikipedia.org/wiki/奥卡姆的威廉)在 14 世纪提出：

> 简洁的解决方案大概率比复杂的更好

当我们有众多解释世界的候选底层理论而必须从中选取一个时，该表述强而有力。对某个问题而言太多假设可能看似合理，但很难泛化到其它复杂情景，乃至最终通向宇宙基本法则。

想想看，人们花了数百年时间才明白白天天空是蓝色，落日时却是红色完全是因为同样的原因（[瑞利散射](https://en.wikipedia.org/wiki/Rayleigh_scattering)），尽管直观上两个现象看起来是那么不同。人们为此独立提出了很多其他解释，简洁版最终胜出。

## 最短描述长度原则

相应的奥卡姆剃刀同样能用在机器学习模型上，该理念正式化地说法是 _最短描述长度（Minimum Description Length，MDL）_ 原则，用来在给定观测数据的时候对模型/解释进行比较。

>理解就是压缩

MDL 的基本思想是 _把学习看作是数据压缩过程_ 。通过压缩数据，我们需要从数据中找到规律性或者模式，而且大概率能将他们用到未知数据上。[信息瓶颈理论](https://lilianweng.github.io/lil-log/2017/09/28/anatomize-deep-learning-with-information-theory.html)认为深度神经网络先是通过最小化泛化误差进行学习表示数据，然后通过去除噪声凝练这种表示。

与此同时，MDL 认为模型描述也是压缩交付的一部分，所以模型不能太大。

二分版 MDL 原则描述为： $$\mathcal{H}^{(1)}, \mathcal{H}^{(2)}, \dots$$ 是一组能解释数据集 $$\mathcal{D}$$ 的模型，其中最好的假设应当最小化求和值：
$$
\mathcal{H}^\text{best} = \arg\min_\mathcal{H} [L(\mathcal{H}) + L(\mathcal{D}\vert\mathcal{H})]
$$

- $$L(\mathcal{H})$$ 是描述模型 $$\mathcal{H}$$ 的比特长度
- $$L(\mathcal{D}\vert\mathcal{H})$$ 是用 $$\mathcal{H}$$ 对数据 $$\mathcal{D}$$  进行编码描述时的比特长度

简而言之，*最好* 的模型是包括编码数据和其自身的 *最小* 模型。照此来讲，不管在训练集上达到的效果如何，章节开头提到的记忆法听起来都有点恐怖了。

有人可能会说奥卡姆剃刀不对，毕竟真实世界的复杂度飘忽不定，为什么必须找到简洁模型呢？ MDL 的一个有趣视角是将模型看作是**“语言”**而不是基础性的生成原理。我们是想找到好的压缩策略来描述小样本集中的规律性，同时为了解释现象**他们并不非得是“真正”的生成模型**。模型可能是错的但仍旧有用（想想贝叶斯先验）。

## 柯氏复杂性

[柯氏复杂性](https://zh.wikipedia.org/wiki/柯氏复杂性)借助现代计算机的概念来定义一个对象的算法（描述性的）复杂度：*描述对象的二进制计算机程序的最短长度*。按照 MDL 的观点，计算机本质上就是数据解码器最一般的形式。

柯氏复杂度的正式定义表述为：给定通用计算机 $$\mathcal{U}$$ 和程序  $$p$$ ，令 $$\mathcal{U}(p)$$ 为计算机处理程序的输出，而 $$L(p)$$ 是程序的描述长度。那么就计算机 $$\mathcal{U}$$ 来说，字符串 $$s$$ 的柯氏复杂性  $$K_\mathcal{U}$$ 为：
$$
K_\mathcal{U}(s) = \min_{p: \mathcal{U}(p)=s} L(p)
$$
注意通用计算机是说能模仿任意其他计算机行为的计算设备。现代计算机都是共同的，因为它们全都可以叫做图灵机。无论用的是哪台计算机，该定义都是适用的，因为另一台通用计算机总能编程克隆 $$\mathcal{U}$$ 的行为，而克隆程序的编码是静态不变的。

柯氏复杂性和香农信息论之间有很多关联，因为他们都和通用编码相关。令人惊讶的是一个随机变量的柯氏复杂性近乎等于它的信息熵（见[报告](https://homepages.cwi.nl/~paulv/papers/info.pdf) 2.3 节），有关于此的更多内容超出了本文范围，但网上有很多有趣的内容，请自便。

## 所罗门诺夫推断

奥卡姆剃刀的另一数学形式是所罗门诺夫的普适归纳推理理论（[Solomonoff](https://www.sciencedirect.com/science/article/pii/S0019995864902232)，[1964](https://www.sciencedirect.com/science/article/pii/S0019995864901317)）。该理论认为，基于柯氏复杂度应由“程序最短”的模型生成训练数据。

# DL 模型的表达能力

相较传统统计模型来说，深度神经网络有着数量众多的参数。如果用 MDL 衡量深度神经网络的复杂度，并将参数数量视为模型描述长度，那模型看起来可会惨不忍睹。模型描述  $$L(\mathcal{H})$$  很容易失控性疯涨。

但为了获取高表达能力，对神经网络而言这许许多多的参数 _必不可少_。正因为神经网络对灵活多样的数据表示的出色捕获能力，它才能在许多应用中取得功绩，出尽风头。

## 通用逼近定理

通用逼近定理指出一个前馈网络具备下列特征：

1）有一个线性输出层

2）至少有一个神经元个数有限的隐层

3）存在激活函数能以任意精确度近似**任何**定义在 $$\mathbb{R}^n$$ 紧凑子集上的连续函数

定理首先在 sigmoid 激活函数上得到证实（[Cybenko, 1989](https://pdfs.semanticscholar.org/05ce/b32839c26c8d2cb38d5529cf7720a68c3fab.pdf)）。随后被证实通用近似性并不取决于激活函数的选择（[Hornik, 1991](http://zmjones.com/static/statistical-learning/hornik-nn-1991.pdf)），而是跟多层前馈框架相关。

尽管单层前馈网络足以表示任意函数，但网络规模也会飞速扩大。通用逼近定理并不能保证模型能进行适当地学习或概括。通常多加几层有助于减少浅层网络中的隐元数量。

依靠通用逼近定理，我们总能找到一个神经网络表示目标函数，并保证误差处于任意期望阈值之内，当然也要为此付出代价——网络可能会变得非常大。

## 证明：双层 NN 的有限样本表达性

目前为止我们所讲的通用逼近定理并没有考虑有限样本集。 [Zhang, et al. (2017)](https://arxiv.org/abs/1611.03530) 倒是对两层神经网络的有限样本表达性给出了利落的证明。

给定维数为 $$d$$ 大小为 $$n$$ 的样本，神经网络 $$C$$ 在满足如下条件时能表示任意函数：对每个有限样本集 $$S \subseteq \mathbb{R}^d$$ ，$$\vert S \vert = n$$ 以及每个定义在样本集上的函数  $$f: S \mapsto \mathbb{R}$$ ，都能为 $$C$$ 找到一组权重使得 $$C(\boldsymbol{x}) = f(\boldsymbol{x}), \forall \boldsymbol{x} \in S$$

论文提出了一个定理：

>  任意定义在大小为 $$n$$ 维数为 $$d$$ 的样本集上的函数，都存在以 ReLU 进行激活，带 $$2n + d$$ 个权重参数的双层神经网络能对其进行表示

*证明*：首先我们希望构造一个双层神经网络 $$C: \mathbb{R}^d \mapsto \mathbb{R}$$ 。输入的是 $$d$$ 维向量 $$\boldsymbol{x} \in \mathbb{R}^d$$  。隐层有 $$h$$ 个隐藏单元，相应有权重矩阵 $$\mathbf{W} \in \mathbb{R}^{d\times h}$$，偏置向量 $$-\mathbf{b} \in \mathbb{R}^h$$ 和 ReLU 激活函数。第二层输出一个权重向量为  $$\boldsymbol{v} \in \mathbb{R}^h$$ 而无偏置的标量。

网络 $$C$$ 对输入向量 $$\boldsymbol{x}$$ 给出的结果可以表示为：
$$
C(\boldsymbol{x}) 
= \boldsymbol{v} \max\{ \boldsymbol{x}\mathbf{W} - \boldsymbol{b}, 0\}^\top
= \sum_{i=1}^h v_i \max\{\boldsymbol{x}\boldsymbol{W}_{(:,i)} - b_i, 0\}
$$
其中 $$\boldsymbol{W}_{(:,i)}$$是 $$d \times h$$ 矩阵的第 $$i$$ 列

给定样本集 $$S = \{\boldsymbol{x}_1, \dots, \boldsymbol{x}_n\}$$ 和目标值  $$\boldsymbol{y} = \{y_1, \dots, y_n \}$$，想要找到合适的权重  $$\mathbf{W} \in \mathbb{R}^{d\times h}$$, $$\boldsymbol{b}, \boldsymbol{v} \in \mathbb{R}^h$$ 使得 $$C(\boldsymbol{x}_i) = y_i, \forall i=1,\dots,n$$

不妨将所有样本点整成一批，即输入矩阵 $$\mathbf{X} \in \mathbb{R}^{n \times d}$$。如果令 $$h=n$$, $$\mathbf{X}\mathbf{W} - \boldsymbol{b}$$ 会是一个  $$n \times n$$ 的方阵。
$$
\mathbf{M}_\text{ReLU} 
= \max\{\mathbf{X}\mathbf{W} - \boldsymbol{b}, 0 \} 
= \begin{bmatrix}
\boldsymbol{x}_1\mathbf{W} - \boldsymbol{b} \\
\dots \\
\boldsymbol{x}_n\mathbf{W} - \boldsymbol{b} \\
\end{bmatrix}
= [\boldsymbol{x}_i\boldsymbol{W}_{(:,j)} - b_j]_{i \times j}
$$
可以简化 $$\mathbf{W}$$ 使所有列的列向量相同：
$$
\mathbf{W}_{(:,j)} = \boldsymbol{w} \in \mathbb{R}^{d}, \forall j = 1, \dots, n
$$
![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/20200804_nn-expressivity-proof.png)

令 $$a_i = \boldsymbol{x}_i \boldsymbol{w}$$，我们是要找合适的 $$\boldsymbol{w}$$ 和 $$\boldsymbol{b}$$ 保证 $$b_1 < a_1 < b_2 < a_2 < \dots < b_n < a_n$$ 。这总是能做到的，因为我们是要求 $$n+d$$ 个未知量，带有 $$n$$ 个约束，同时 $$\boldsymbol{x}_i$$ 是独立的（即选择随机一个 $$\boldsymbol{w}$$, 对 $$\boldsymbol{x}_i \boldsymbol{w}$$ 排序然后令 $$b_j$$ 的值夹在中间）。然后 $$\mathbf{M}_\text{ReLU}$$ 就变成了下三角矩阵：
$$
\mathbf{M}_\text{ReLU} = [a_i - b_j]_{i \times j}
= \begin{bmatrix}
a_1 - b_1 & 0        & 0  & \dots & 0 \\
\vdots &  \ddots  & &  & \vdots \\
a_i - b_1 & \dots & a_i - b_i & \dots & 0\\
\vdots &    & & \ddots & \vdots \\
a_n - b_1 & a_n - b_2 & \dots & \dots & a_n - b_n \\
\end{bmatrix}
$$

因为行列式 $$\det(\mathbf{M}_\text{ReLU}) \neq 0$$ 所以是非奇异方阵，所以总能找到合适的 $$\boldsymbol{v}$$ 使 $$\boldsymbol{v}\mathbf{M}_\text{ReLU}=\boldsymbol{y}$$ （换句话话说，$$\mathbf{M}_\text{ReLU}$$ 的列空间都是 $$\mathbb{R}^n$$ 的，可以找个列向量的线性组合方式囊括所有的 $$\boldsymbol{y}$$）

## DNN 能学习随机噪声

既然已知双层神经网络是通用近似器，了解到它们能完美学习非结构化随机噪声也就没那么惊讶了，如 [Zhang 等人 (2017)](https://arxiv.org/abs/1611.03530) 所示。如果随机打乱图像分类数据集的标签，深度神经网络强大的表达能力仍能使它们的训练损失近乎为零。加上正则化项也不会影响到结果。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_fit-random-labels.png)

*图1  用随机标签或像素在 CIFAR10 上训练模型：(a) 学习曲线；(b-c) 标签混淆率是随机打乱标签的百分比表示（图片源：[Zhang 等的论文](https://arxiv.org/abs/1611.03530)）*

# 深度学习模型过分过拟合了？

深度学习模型过度参数化倾向严重，同时又经常在训练数据上得到完美结果。从传统视角来看，如偏差-方差权衡，这可能就是灾难，对未知测试数据没有一丝泛化能力。但通常情况是，这些“过拟合”（训练误差为 0）的深度学习模型在样本外测试数据上的表现仍旧出色……有意思，这是为什么？

## 深度学习的现代风险曲线

传统机器学习使用下面的 U 型风险曲线衡量偏差-方差间的取舍，并对模型泛化能力进行量化。如果我被问到怎么判明一个模型过拟合了，这就是我脑海中首先浮现的东西。

随着模型变得越来越大（参数不断增多），训练误差不断降低趋近于零，但一旦模型复杂度的增长超过了“欠拟合”和“过拟合”的临界值，测试误差（泛化误差）会开始增长。某种程度上讲，这很符合奥卡姆剃刀原理。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_bias-variance-risk-curve.png)

*图 2  U型偏差-方差风险曲线（图片来源：[左](https://arxiv.org/abs/1812.11118)，[右](http://scott.fortmann-roe.com/docs/BiasVariance.html)）*

很不幸，这对深度学习模型而言并不适用。[Belkin 等人 (2018)](https://arxiv.org/abs/1812.11118) 的研究调和了传统的偏差-方差损益，并为深度神经网络提出了新型双 U 风险曲线。一旦网络参数足够多，风险曲线就会落入另一个区间

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_new-bias-variance-risk-curve.png)

*图 3  深度神经网络的双 U 型偏差-方差风险曲线（图片来源：[原论文](https://arxiv.org/abs/1812.11118)）*

研究认为大概率是两个因素造成了这一现象：

- 参数数量并不是衡量 *归纳偏置* 的好方法，归纳偏置是为对未知样本进行预测而给学习算法加上的一组假设。
- 更大的模型可以发掘更广阔的函数空间，进而找到范数更小，“更简单”的插值函数（插值就是用拟合曲线预测未知样本的过程）

正如研究所述，双 U 型风险曲线是经验观察，但我为了复现成果可费了不少劲。的确是有些迹象，但为了能得到近乎满足理论的足够光滑的曲线，需要考虑很多[实验细节](# 实验)。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_new-risk-curve-mnist.png)

*图 4  单隐层全连接网络在不同隐藏单元个数下的训练与测试误差，模型在从 MNIST 采样的 4000 个样本上进行训练（图片来源：[原论文](https://arxiv.org/abs/1812.11118)）*

## 正则化并不是泛化能力的关键

正则化是控制过拟合，改善模型泛化性能的常见方法。有趣的是有研究（[Zhang 等 2017](https://arxiv.org/abs/1611.03530)）证实明晰的正则化手段（数据增强，权重衰减和 dropout）对减少泛化误差来说既不必要又不充分。

以 CIFAR10 上训练的原始模型为例（见图 5）。正则化对样本外数据确有帮助但不太大，没哪个正则化手段特别凸出要额外重视。所以正则化不太可能是泛化能力的本源。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_regularization-generalization-test.png)

*图 5  开关数据增强或权重衰减的不同组合下原始模型的准确率（图片来源：[原论文](https://arxiv.org/abs/1611.03530)表一）*

## 固有尺度

对深度学习来说，参数个数与模型过拟合不存在相关关系，也就是说光数参数并不能如实反映深度神经网络的复杂度。

而除开参数量，研究人员为量化模型复杂度也提出了很多方法，比如模型自由度([Gao & Jojic, 2016](https://arxiv.org/abs/1603.09260))，或先验码 ([Blier & Ollivier, 2018](https://arxiv.org/abs/1802.07044))。我想说的是一个近期发表的方法，[Li 等, 2018](https://arxiv.org/abs/1804.08838) 提出的**固有尺度（intrinsic dimension）** 。固有尺度直观易懂，好测量，同时揭露了不同大小模型的很多有趣属性。

设想一个参数量巨大的神经网络，有着高维参数空间，学习就在这高维 *目标地貌（ objective landscape）* 上进行。参数空间流形形状至关重要，比如说，更光滑的流形凭借前瞻性的梯度和更大的学习率更利于优化——这也是批归一化促成训练稳定的原因（[Santurkar 等, 2019](https://arxiv.org/abs/1805.11604)）。

尽管参数空间很大，幸运的是不必过于担心优化过程会陷入局部最优点，经[证实](https://arxiv.org/abs/1406.2572)目标地貌的局部最优点几乎总是落于鞍点而不是谷上。换句话讲，总能找到一个尺度子集离开局部最优继续探索。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_optimization-landscape-shape.png)

*图 6  参数优化地貌上各类临界点图示（图片来源：[网络](https://www.offconvex.org/2016/03/22/saddlepoints/)）*

固有尺度背后的一个思想是，既然参数空间的维数那么高，为了高效学习而探索所有尺度可能就没什么必要。如果只遍历目标地貌的一个切片还依旧能得到一个好结果，最终模型的复杂度大概率要比参数计数方式来的低，这也正是固有尺度实质上想竭力做到的。

现有一 $$D$$ 维模型，参数记为 $$\theta^{(D)}$$ 。为了学习，随机采样出一个更小的 $$d$$ 维子空间， $$\theta^{(d)}$$, 有 $$d < D$$。在一次优化更新的过程中，不从整体 $$D$$ 维出发选择梯度，而只用更小的子空间 $$\theta^{(d)}$$ 重新映射更新模型参数。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_intrinsic-dimension-illustration.png)

*图 7  $$D=3$$ 时直接优化的参数向量图示（图片来源：[原论文](https://arxiv.org/abs/1804.08838)）*

梯度更新公式看起来是下面这个样子：
$$
\theta^{(D)} = \theta_0^{(D)} + \mathbf{P} \theta^{(d)}
$$
其中 $$\theta_0^{(D)}$$ 是初始值， $$\mathbf{P}$$ 是训练前随机采样得到的 $$D \times d$$ 映射矩阵。 $$\theta_0^{(D)}$$ 和 $$\mathbf{P}$$ 不参与训练固定不变。 $$\theta^{(d)}$$ 全初始化为 0 。

遍历 $$d = 1, 2, \dots, D$$，成功方案出现时的 $$d$$ 定为 *固有尺度*

结果显示很多问题相较参数个数而言固有尺度都要少很多。比如，基于 CIFAR10 的图像分类问题，一个带 65w+ 个参数的全连接网络只有 9000 个固有尺度，而一个带 62,000 个参数的卷积网络的固有尺度更少，只有 2900 个。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_intrinsic-dimension.png)

_图 8  达到 90% 性能的各个模型的固有尺度数 $$d$$ (图片来源：[原论文](https://arxiv.org/abs/1804.08838))_

固有尺度的测算展示出深度学习模型可能要比他们看起来的样子简单得多。

## 异构层鲁棒性

 $$\ell$$ , $$\ell = 1, \dots, L$$,  $$t$$, $$\theta^{(\ell)}_t$$ 

-  $$\theta^{(\ell)}_t \leftarrow \theta^{(\ell)}_0$$. $$\ell$$.
- $$\theta^{(\ell)}_t \leftarrow \tilde{\theta}^{(\ell)} \sim \mathcal{P}^{(\ell)}$$.  $$\ell$$.

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_layer-robustness-results.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_layer-robustness-resnet.png)

1.  $$\theta_0$$;
2.  $$\theta$$;
3.  $$\theta$$  $$m$$.
4.  $$m \odot \theta_0$$. 

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_risk_curve_loss-mse_sample-4000_epoch-500.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/20200804_layer_equality_256x3.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/20200804_layer_equality_128x4.png)

 $$d$$  $$\mathbf{P}$$  $$\mathbf{P}\theta^{(d)}$$  $$\mathbf{P}$$  $$d$$  $$\sum_{i=1}^d \theta^{(d)}_i \mathbf{P}^\top_{(:,i)}$$,  $$\mathbf{P}$$.

 $$d$$, 

 $$d$$

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/20200804_intrinsic-dimension-net-64-64-and-128.png)