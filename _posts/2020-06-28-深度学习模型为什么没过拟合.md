---
layout:		post
title:  	深度学习模型有没有过拟合？
subtitle:   
date:       2020-06-28
author:     一轩明月
header-img: img/post-bg-universe.jpg
catalog:    true
tags:
    - opinions
excerpt:    深度神经网络借助数量繁多的参数经常能在训练集上逼近零预测误差，这难道不是过拟合吗？模型选择的经典原理仍旧适用，但传统模型复杂度测试定方式已不适合深度神经网络，DNN 有自己的风险曲线，固有尺度和彩票假说都是解释其泛化能力的不错视角
---

> 编译自：Are Deep Neural Networks Dramatically Overfitted，[Lilog](https://lilianweng.github.io/lil-log/)

如果你像我一样，进入深度学习领域前有传统机器学习经历，可能会经常疑惑：既然经典深度神经网络有这么多参数并且训练误差很容易臻至完美，它应该不无意外地出现严重的过拟合才对，它又怎么能泛化应用于样本外的数据呢？

思考“为什么深度神经网络具备泛化能力”的过程不知怎得使我想起 System Biology 上一篇有趣的论文——[“生物学家能修收音机吗？”](https://www.cell.com/cancer-cell/pdf/S1535-6108(02)00133-2.pdf)。如果一名生物学家打算像她研究生物系统一样去修理无线电机器，道路可能会曲折而坎坷。因为整个无线电系统的机理并没有暴露在外，拨弄局部的小功能可能会得到点启发，但系统内部的交互与连接几乎不会展示出来，更别提整体工作流了。无论你是否认为该文章和 DL 相关，都值得一读。

本文会介绍一些深度学习模型泛化能力和复杂度测定相关的研究工作。希望这有助于你理解为什么 DNN 能泛化。

# 压缩和模型选择的经典理论

假定我们手头有个分类问题和一个数据集，自然可以写很多模型来进行解决，从用线性回归的简单拟合到占用磁盘空间记住整个数据集。哪个更好？如果只关心训练集上的准确率（尤其是当测试数据大概率未知的时候），记忆法似乎最好——好吧，听起来有点不对。

实际在这种情境下，一个好模型要具备哪些特点有很多经典定理可以给予指导。

## 奥卡姆剃刀

[奥卡姆剃刀](https://zh.wikipedia.org/wiki/奥卡姆剃刀)是一个寻求答案时的非正式原则，由[奥卡姆](https://zh.wikipedia.org/wiki/奥卡姆的威廉)在 14 世纪提出：

> 简洁的解决方案大概率比复杂的好

当我们有许多候选的底层理论能用来解释世界，而且必须从中选一个的时候，该表述强而有力。对某个问题来说假设太多可能看似合理，但很难泛化到其它复杂情景，乃至最终通向宇宙基本法则。

想想看，人们花了数百年时间才明白白天天空是蓝色，落日时却是红色完全是因为同样的原因（[瑞利散射](https://en.wikipedia.org/wiki/Rayleigh_scattering)），尽管直观上两个现象看起来是那么不同。人们为此独立提出了很多其他解释，简洁版最终胜出。

## 最短描述长度原则

奥卡姆剃刀当然同样能用在机器学习模型上，该理念正式化地说法是 _最短描述长度（Minimum Description Length，MDL）_ 原则，用来在给定观测数据的时候对模型/解释进行比较。

>理解就是压缩

MDL 的基本思想是 _把学习看作是数据压缩过程_ 。通过压缩数据，我们需要从数据中找到规律性或者模式，而且大概率能将他们用到未知数据上。[信息瓶颈理论](https://lilianweng.github.io/lil-log/2017/09/28/anatomize-deep-learning-with-information-theory.html)认为深度神经网络先是通过最小化泛化误差进行学会表示数据，然后通过去除噪声学习凝练表示。

与此同时，MDL 认为模型描述也是压缩传输的一部分，所以模型不能太大。

二分版 MDL 原则描述为： $$\mathcal{H}^{(1)}, \mathcal{H}^{(2)}, \dots$$ 是一组能解释数据集 $$\mathcal{D}$$ 的模型，其中最好的假设应当最小化描述长度：
$$
\mathcal{H}^\text{best} = \arg\min_\mathcal{H} [L(\mathcal{H}) + L(\mathcal{D}\vert\mathcal{H})]
$$

- $$L(\mathcal{H})$$ 是描述模型 $$\mathcal{H}$$ 的比特长度
- $$L(\mathcal{D}\vert\mathcal{H})$$ 是用 $$\mathcal{H}$$ 对数据 $$\mathcal{D}$$  进行编码描述时的比特长度

简而言之，*最好* 的模型是 *最小* 模型，其中包括编码数据和模型自身。照此来讲，不管在训练集上达到的效果如何，章节开头提到的记忆法听起来都有点恐怖了。

有人可能会说奥卡姆剃刀不对，毕竟真实世界的复杂度飘忽不定，为什么必须找到简洁模型呢？ MDL 有个有趣的视角，将模型看作是**“语言”**而不是根本的生成原理。我们是想找到好的压缩策略来描述小样本集中的规律性，同时为了解释现象**他们并不非得是“真正”的生成模型**。模型可能是错的但仍旧有用（想想贝叶斯先验）。

## 柯氏复杂性

[柯氏复杂性](https://zh.wikipedia.org/wiki/柯氏复杂性)借助现代计算机的概念来定义一个对象的算法（描述性）复杂度：*能描述对象的二进制计算机程序的最短长度*。按照 MDL 的观点，计算机本质上就是数据解码器最一般的形式。

柯氏复杂度的正式定义表述为：给定通用计算机 $$\mathcal{U}$$ 和程序  $$p$$ ，令 $$\mathcal{U}(p)$$ 为计算机处理程序的输出，而 $$L(p)$$ 是程序的描述长度。那么就计算机 $$\mathcal{U}$$ 来说，字符串 $$s$$ 的柯氏复杂性  $$K_\mathcal{U}$$ 为：
$$
K_\mathcal{U}(s) = \min_{p: \mathcal{U}(p)=s} L(p)
$$
注意这里的通用计算机是指能模仿任意其他计算机行为的计算设备。现代计算机都一样，它们全都可以叫做图灵机。无论是哪台计算机，该定义都是适用的，因为另一台通用计算机总能通过编程克隆 $$\mathcal{U}$$ 的行为，而克隆程序的代码是静态不变的。

柯氏复杂性和香农信息论之间有很多关联，因为他们都和通用编码相关。令人惊讶的是一个随机变量的柯氏复杂性近乎等于它的信息熵（见[报告](https://homepages.cwi.nl/~paulv/papers/info.pdf) 2.3 节），有关于此的更多内容超出了本文范围，但网上有很多有趣的阅读材料，请自便 :)

## 所罗门诺夫推断

奥卡姆剃刀的另一数学形式是所罗门诺夫的普适归纳推理理论（[Solomonoff](https://www.sciencedirect.com/science/article/pii/S0019995864902232)，[1964](https://www.sciencedirect.com/science/article/pii/S0019995864901317)）。该理论认为，考虑到柯氏复杂度应由“程序最短”的模型生成训练数据。

# DL 模型的表达能力

相较传统统计模型来说，深度神经网络有着数量众多的参数。如果用 MDL 衡量深度神经网络的复杂度，并将参数数量视为模型描述长度，那模型看起来可会惨不忍睹。模型描述  $$L(\mathcal{H})$$  很容易失控性疯涨。

但为使表达能力够强，对神经网络而言这许许多多的参数 _必不可少_。正因为神经网络对灵活多样的数据表示具备出色的捕获能力，它才能在许多应用中取得辉煌战绩。

## 普适逼近定理

普适逼近定理指出一个前馈网络具备下列特征：

1）有一个线性输出层

2）至少有一个神经元个数有限的隐层

3）存在激活函数能以任意精确度近似**任何**定义在 $$\mathbb{R}^n$$ 紧凑子集上的连续函数

定理首先在 sigmoid 激活函数上得到证实（[Cybenko, 1989](https://pdfs.semanticscholar.org/05ce/b32839c26c8d2cb38d5529cf7720a68c3fab.pdf)）。随后被证实普适近似性并不取决于激活函数的选择（[Hornik, 1991](http://zmjones.com/static/statistical-learning/hornik-nn-1991.pdf)），而是跟多层前馈结构相关。

尽管单层前馈网络足以表示任意函数，但网络规模也会飞速增大。普适逼近定理并不保证模型能恰当地学习或概括。通常多加几层有助于减少浅层网络中的隐元数量。

利用普适逼近定理，我们总能找到一个神经网络表示目标函数，并保证误差处于任意期望阈值之内，当然也要为此付出代价——网络可能会变得非常大。

## 证明：双层 NN 的有限样本表达性

目前为止我们所讲的普适逼近定理并没有考虑有限样本集。 [Zhang, 等 (2017)](https://arxiv.org/abs/1611.03530) 倒是对双层神经网络对有限样本的表达能力给出了利落的证明。

给定维数为 $$d$$ 大小为 $$n$$ 的样本集，神经网络 $$C$$ 在满足如下条件时能表示任意函数：对每个有限样本集 $$S \subseteq \mathbb{R}^d$$ ，$$\vert S \vert = n$$ 以及每个定义在样本集上的函数  $$f: S \mapsto \mathbb{R}$$ ，都能为 $$C$$ 找到一组权重使得 $$C(\boldsymbol{x}) = f(\boldsymbol{x}), \forall \boldsymbol{x} \in S$$

论文提出了一个定理：

>  定义在大小为 $$n$$ 维数为 $$d$$ 的样本集上任何函数，存在能表示该函数的双层神经网络，用 ReLU 激活并带 $$2n + d$$ 个参数

*证明*：首先我们希望构造一个双层神经网络 $$C: \mathbb{R}^d \mapsto \mathbb{R}$$ 。输入的是 $$d$$ 维向量 $$\boldsymbol{x} \in \mathbb{R}^d$$  。隐层有 $$h$$ 个隐藏单元，相应有权重矩阵 $$\mathbf{W} \in \mathbb{R}^{d\times h}$$，偏置向量 $$-\mathbf{b} \in \mathbb{R}^h$$ 和 ReLU 激活函数。第二层输出一个权重向量为  $$\boldsymbol{v} \in \mathbb{R}^h$$ 而无偏置的标量结果。

网络 $$C$$ 对输入向量 $$\boldsymbol{x}$$ 给出的结果可以表示为：
$$
C(\boldsymbol{x}) 
= \boldsymbol{v} \max\{ \boldsymbol{x}\mathbf{W} - \boldsymbol{b}, 0\}^\top
= \sum_{i=1}^h v_i \max\{\boldsymbol{x}\boldsymbol{W}_{(:,i)} - b_i, 0\}
$$
其中 $$\boldsymbol{W}_{(:,i)}$$ 是 $$d \times h$$ 矩阵的第 $$i$$ 列

给定样本集 $$S = \{\boldsymbol{x}_1, \dots, \boldsymbol{x}_n\}$$ 和目标值  $$\boldsymbol{y} = \{y_1, \dots, y_n \}$$，想要找到合适的权重  $$\mathbf{W} \in \mathbb{R}^{d\times h}$$, $$\boldsymbol{b}, \boldsymbol{v} \in \mathbb{R}^h$$ 使得 $$C(\boldsymbol{x}_i) = y_i, \forall i=1,\dots,n$$

不妨将所有样本点整成一批，即输入矩阵 $$\mathbf{X} \in \mathbb{R}^{n \times d}$$。如果令 $$h=n$$, $$\mathbf{X}\mathbf{W} - \boldsymbol{b}$$ 会是一个  $$n \times n$$ 的方阵。
$$
\mathbf{M}_\text{ReLU} 
= \max\{\mathbf{X}\mathbf{W} - \boldsymbol{b}, 0 \} 
= \begin{bmatrix}
\boldsymbol{x}_1\mathbf{W} - \boldsymbol{b} \\
\dots \\
\boldsymbol{x}_n\mathbf{W} - \boldsymbol{b} \\
\end{bmatrix}
= [\boldsymbol{x}_i\boldsymbol{W}_{(:,j)} - b_j]_{i \times j}
$$
可以简化 $$\mathbf{W}$$ 使所有列的列向量相同：
$$
\mathbf{W}_{(:,j)} = \boldsymbol{w} \in \mathbb{R}^{d}, \forall j = 1, \dots, n
$$
![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/20200804_nn-expressivity-proof.png)

令 $$a_i = \boldsymbol{x}_i \boldsymbol{w}$$，我们是要找合适的 $$\boldsymbol{w}$$ 和 $$\boldsymbol{b}$$ 保证 $$b_1 < a_1 < b_2 < a_2 < \dots < b_n < a_n$$ 。这没问题，因为我们是要求 $$n+d$$ 个未知量，同时有 $$n$$ 个约束条件，而 $$\boldsymbol{x}_i$$ 是独立的（即选个随机的 $$\boldsymbol{w}$$, 对 $$\boldsymbol{x}_i \boldsymbol{w}$$ 排序然后令 $$b_j$$ 的值穿夹其中）。然后 $$\mathbf{M}_\text{ReLU}$$ 就变成了下三角矩阵：
$$
\mathbf{M}_\text{ReLU} = [a_i - b_j]_{i \times j}
= \begin{bmatrix}
a_1 - b_1 & 0        & 0  & \dots & 0 \\
\vdots &  \ddots  & &  & \vdots \\
a_i - b_1 & \dots & a_i - b_i & \dots & 0\\
\vdots &    & & \ddots & \vdots \\
a_n - b_1 & a_n - b_2 & \dots & \dots & a_n - b_n \\
\end{bmatrix}
$$

因为行列式 $$\det(\mathbf{M}_\text{ReLU}) \neq 0$$ 所以是非奇异方阵，所以总能找到合适的 $$\boldsymbol{v}$$ 使 $$\boldsymbol{v}\mathbf{M}_\text{ReLU}=\boldsymbol{y}$$ （换句话话说，$$\mathbf{M}_\text{ReLU}$$ 的列空间都是 $$\mathbb{R}^n$$ 的，可以找出列向量的线性组合表示所有的 $$\boldsymbol{y}$$）

## DNN 能学习随机噪声

既然已知双层神经网络是通用近似器，了解到它们能完美学习非结构化的随机噪声也就没那么惊讶了，如 [Zhang 等人 (2017)](https://arxiv.org/abs/1611.03530) 所示。如果随机打乱图像分类数据集的标签，深度神经网络强大的表达能力仍能使它们的训练损失近乎为零。加上正则化项也不会影响到结果。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_fit-random-labels.png)

*图1  用随机标签或像素在 CIFAR10 上训练模型：(a) 学习曲线；(b-c) 标签混淆率是标签随机打乱的百分比表示（图片源：[Zhang 等的论文](https://arxiv.org/abs/1611.03530)）*

# 深度学习模型过分过拟合了？

深度学习模型过度参数化倾向严重，同时又经常在训练数据上得到完美结果。从传统视角来看，如偏差-方差权衡，这可能就是灾难，对未知测试数据没有一丝泛化能力。但通常情况是，这些“过拟合”（训练误差为 0）的深度学习模型在样本外测试数据上的表现仍旧出色……有意思，但这又是为什么？

## 深度学习的新风险曲线

传统机器学习使用下面的 U 型风险曲线测算偏差-方差间的取舍收益，并对模型泛化能力进行量化。如果我被问到怎么判明一个模型过拟合了，这就是我脑海中首先想到的东西。

随着模型变得越来越大（参数不断增多），训练误差不断降低趋近于零，但一旦模型复杂度的增长超过了“欠拟合”和“过拟合”的临界值，测试误差（泛化误差）便会开始增长。某种程度上讲，这很符合奥卡姆剃刀原理。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_bias-variance-risk-curve.png)

*图 2  U型偏差-方差风险曲线（图片来源：[左](https://arxiv.org/abs/1812.11118)，[右](http://scott.fortmann-roe.com/docs/BiasVariance.html)）*

很不幸，这对深度学习模型并不适用。[Belkin 等 (2018)](https://arxiv.org/abs/1812.11118) 的研究调和了传统的偏差-方差损益，并为深度神经网络提出了新的双 U 型风险曲线。一旦网络参数足够多，风险曲线就会落入另一个区间

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_new-bias-variance-risk-curve.png)

*图 3  深度神经网络的双  U 型偏差-方差风险曲线（图片来源：[原论文](https://arxiv.org/abs/1812.11118)）*

研究认为大概率是两个因素造成了这一现象：

- 参数数量并不是衡量 *归纳偏置* 的好方法，归纳偏置是为了对未知样本进行预测而给学习算法加上的一组假设。
- 更大的模型可以发掘更广阔的函数空间，进而找到范数更小，“更简单”的插值函数（插值就是用拟合曲线预测未知样本的过程）

如论文所讲，双 U 型风险曲线算是经验观察，但我为了复现成果可费了不少劲。的确是有些迹象，但为了能得到近乎满足理论的足够光滑的曲线，需要考虑很多[实验细节](# 实验)。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_new-risk-curve-mnist.png)

*图 4  单隐层全连接网络在不同隐藏单元个数下的训练与测试误差，模型在从 MNIST 采样的 4000 个样本上进行训练（图片来源：[原论文](https://arxiv.org/abs/1812.11118)）*

## 正则化并不是泛化能力的关键

正则化是控制过拟合，改善模型泛化性能的常见方法。有趣的是有研究（[Zhang 等 2017](https://arxiv.org/abs/1611.03530)）证实明晰的正则化手段（数据增强，权重衰减和 dropout）对减少泛化误差来说既不必要又不充分。

以在 CIFAR10 上训练的原始模型为例（见图 5）。正则化对样本外数据确有帮助但不太大，没哪个正则化手段特别凸出要额外重视。所以正则化不太可能是泛化能力的本源。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_regularization-generalization-test.png)

*图 5  开关数据增强或权重衰减的不同组合下原始模型的准确率（图片来源：[原论文](https://arxiv.org/abs/1611.03530)表一）*

## 固有尺度

对深度学习来说，参数个数与模型过拟合不存在相关关系，即光数参数并不能如实反映深度神经网络的复杂度。

而除开参数量，研究人员为量化模型复杂度也提出了很多方法，比如模型自由度([Gao & Jojic, 2016](https://arxiv.org/abs/1603.09260))，或先验码 ([Blier & Ollivier, 2018](https://arxiv.org/abs/1802.07044))。我想说的是一个近期发表的方法，[Li 等, 2018](https://arxiv.org/abs/1804.08838) 提出的**固有尺度（intrinsic dimension）** 。固有尺度直观易懂，好测量，同时揭露了不同大小模型的很多有趣属性。

设想一个参数量巨大的神经网络，有着高维参数空间，学习就在这高维 *目标地貌（ objective landscape）* 上进行。参数空间流形形状至关重要，比如说，更光滑的流形凭借前瞻性的梯度和更大的可用学习率有利于优化——这也是批归一化促成训练稳定的原因（[Santurkar 等, 2019](https://arxiv.org/abs/1805.11604)）。

虽然参数空间很大，所幸不必担心优化过程会陷入局部最优点，经[证实](https://arxiv.org/abs/1406.2572)目标地貌的局部最优点几乎总是落于鞍点而不是谷上。换句话讲，总能找到一个尺度子集离开局部最优继续探索。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_optimization-landscape-shape.png)

*图 6  参数优化地貌上各类临界点图示（图片来源：[网络](https://www.offconvex.org/2016/03/22/saddlepoints/)）*

固有尺度背后的一个思想是，既然参数空间的维数那么高，为了高效学习而探索所有尺度可能就没什么必要。如果只遍历目标地貌的一个切片还依旧能得到一个好结果，最终模型的复杂度大概率要比参数计数方式来的低，这也正是固有尺度实质上想竭力做到的事。

现有 $$D$$ 维模型，参数记为 $$\theta^{(D)}$$ 。为了学习，随机采样出一个更小的 $$d$$ 维子空间， $$\theta^{(d)}$$, 有 $$d < D$$。在一次优化更新的过程中，不从整体 $$D$$ 维出发选择梯度，而只用更小的子空间 $$\theta^{(d)}$$ 重新映射更新模型参数。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_intrinsic-dimension-illustration.png)

*图 7  $$D=3$$ 时直接优化的参数向量图示（图片来源：[原论文](https://arxiv.org/abs/1804.08838)）*

梯度更新公式会是下面这个样子：
$$
\theta^{(D)} = \theta_0^{(D)} + \mathbf{P} \theta^{(d)}
$$
其中 $$\theta_0^{(D)}$$ 是初始值， $$\mathbf{P}$$ 是训练前随机采样得到的 $$D \times d$$ 映射矩阵。 $$\theta_0^{(D)}$$ 和 $$\mathbf{P}$$ 不参与训练，固定不变。 $$\theta^{(d)}$$ 全初始化为 0 。遍历 $$d = 1, 2, \dots, D$$，成功方案出现时的 $$d$$ 定义为 *固有尺度*。

结果显示很多问题相较参数个数而言固有尺度都要少很多。比如，基于 CIFAR10 的图像分类问题，一个带 65w+ 个参数的全连接网络只有 9000 个固有尺度，而一个带 62,000 个参数的卷积网络的固有尺度更少，只有 2900 个。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_intrinsic-dimension.png)

_图 8  达到 90% 性能时各模型的固有尺度数 $$d$$ (图片来源：[原论文](https://arxiv.org/abs/1804.08838))_

固有尺度的测算证明深度学习模型可能要比他们看起来的样子简单得多。

## 异构层鲁棒性

[Zhang 等(2019)](https://arxiv.org/abs/1902.01996) 研究了不同层参数所起的作用。工作提出的根本问题是：“所有层都是平等构建的吗？”简单回答：不是。模型对一些层的变化相较其他层而言会更敏感。

研究提出了两种 $$\ell$$  层参数层面上的操作, $$\ell = 1, \dots, L$$, 在 $$t$$ 时刻，用 $$\theta^{(\ell)}_t$$ 测定它们对模型鲁棒性的影响：

-  **重新初始化**：重置参数为初始值 $$\theta^{(\ell)}_t \leftarrow\theta^{(\ell)}_0$$ 。 $$\ell$$ 层被重置后的网络表现，称为 $$\ell$$ 层的 *重置鲁棒性*
- **重新随机化**：层内参数重新随机采样，$$\theta^{(\ell)}_t \leftarrow \tilde{\theta}^{(\ell)} \sim \mathcal{P}^{(\ell)}$$。对应的网络表现称为 $$\ell$$ 层的 *重随机鲁棒性*

通过两中操作可将各层归为两类：

- **鲁棒层**：重置或重新随机化后，网络没有或只有可忽略不计的性能损失
- **核心层**：其他情况

研究者在全连接和卷积网络上观察到了相似情况。任意层的重新随机化都会 *彻底击溃* 模型，预测立刻会衰退到随机瞎猜的水平。更有趣且令人惊讶的是，进行重置的时候，只有第一或前面的少数几层（最接近输入层）至关重要，更高层的重置所带来的性能衰退 *可忽略不计*。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_layer-robustness-results.png)

*图 9  (a) MNIST 上训练全连接网络，每一行对应网络的一层，第一列是各层的重随机鲁棒性，其余列则是不同训练时间下的重置鲁棒性。(b) CIFAR10 上训练 VGG11 模型（卷积网络），表示类似 (a) 只不过行列转置（图片来源：[原论文](https://arxiv.org/abs/1902.01996)）*

ResNet 能借助非比邻层间的捷径修改整个网络的敏感层分布，而不只是在底部。借助残差块结构，网络 *对重随机有均匀鲁棒性*。仅各残差块的第一层依旧对重置和重随机都敏感，如果将每个残差块看作是局部子网络，体现出的鲁棒性和前面的全连接与卷积网络相似。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_layer-robustness-resnet.png)

*图 10  CIFAR10 上 ResNet-50 模型的重随机（第一行）和重置（其余行）鲁棒性（图片来源：[原论文](https://arxiv.org/abs/1902.01996)）*

鉴于深度神经网络中顶部的很多层在重置后对模型性能影响甚微，论文总结道：

> 随机梯度训练出来的能力过剩的深度网络复杂度低，因为自我约束了核心层数量

可将重置作为减少有效参数个数的一种方式，进而得到与固有尺度一致的观察。

## 彩票假说

彩票假说（[Frankle & Carbin, 2019](https://arxiv.org/abs/1803.03635)）是另一个有趣又有启发的发现，认为仅有一小部分网络参数对模型性能有影响所以网络没有过拟合。彩票假说是说对一个随机初始化了的稠密前馈神经网络来讲，在 *独立训练* 时，其囊括的一众子网络只有一个子集会得“*头彩* ”，取得最佳表现。

该想法受启发于网络修剪技术——删掉不必要的权重（即权重很小几乎可以忽略）而不损害模型性能。尽管最终模型规模会巨幅降低，但想从头成功训练一个修剪过的网络十分困难。感觉为了成功训练一个神经网络，需要配上海量的参数，而一旦模型训练完我们就不需要那么多的参数来使准确率停于高位了。为什么呢？

彩票假说进行了如下实验

1.  以初始值 $$\theta_0$$ 随机初始化一个稠密前馈网络
2.  参数配置为 $$\theta$$，训练网络，多轮迭代后取得好性能
3.  修剪 $$\theta$$ 并创建遮罩 $$m$$
4.  “头彩”的初始配置为 $$m \odot \theta_0$$

只用第一步中的初始值训练“头彩”对应的参数子集，准确水平不次于第二步的模型。结果就是大参数空间对最终方案效果来说不是必须的，但训练的时候需要，因为它为众多子网络提供了许多初始配置。

彩票假说在解释和分析深度神经网络结果上提供了新视角，相信后面能看到有很多有趣的工作。

# 实验

看了这么多成果，复现一下会很有趣。其中一些比其他的好复现些，细则如下。已开放[源代码](https://github.com/lilianweng/generalization-experiment)

## DL 模型的新风险曲线

这个最难复现，原作中有一些值得注意的设置：

- 没有像权重衰减和 dropout 这样的正则化项
- 图 3 中训练集有 4000 个样本，它只采样了一次然后所有模型都用这个。评估时候用的是整个 MINIST 测试集
- 每个网络都花了很长时间达到近乎零训练误差。模型大小不同学习率也不同
- 为了降低模型对欠参数化的初始状态的敏感性，采用了一种“*权重复用* ”方案：训练小网络得到的参数用作训练大网络时的初始值

开放代码中并没有训练或是调试每个模型达到完美水准，但测试误差确实是在插值阈值处出现了特殊形变，这和训练误差不同。比如，对 MNIST 来说阈值是训练样本数乘上类别数（10），也就是 40000。

x 轴是模型参数个数： (28 * 28 + 1) * 单元数 + 单元数 * 10，取对数。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-08-04_risk_curve_loss-mse_sample-4000_epoch-500.png)

## 各层不是生而平等

这个复现简单，见[代码](https://github.com/lilianweng/generalization-experiment/blob/master/layer_equality.py)。

实验一，三层全连接网络，每层 256 个单元，0 层是输入层，3 层是输出层。在 MNIST 上跑了 100 轮。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/20200804_layer_equality_256x3.png)

实验二，四层全连接网络，每层 128 个单元，其余配置同实验一

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/20200804_layer_equality_128x4.png)

## 固有尺度度量

为了准确建立 $$d$$ 维子空间到整个参数空间的映射，映射矩阵 $$\mathbf{P}$$ 应该有正交列，因为乘积 $$\mathbf{P}\theta^{(d)}$$ 是 $$\mathbf{P}$$ 中各列经 $$d$$ 维向量中的标量值缩放后的和， $$\sum_{i=1}^d \theta^{(d)}_i \mathbf{P}^\top_{(:,i)}$$，充分利用$$\mathbf{P}$$ 内有正交列的子空间比较好。

实现就很朴素了，从标准正态分布采样出独立条目组成一个大矩阵，希望列在高维空间中是独立的所以要是正交的，该方法在维数不太大的时候很有效。在探索大 $$d$$ 的时候，有方法构建稀疏映射矩阵，这也是固有尺度原论文建议的。

实验在两个网络上进行：左边是双层全连接网络，每层 64 个单元，右边是单层全连接网络，128 个单元，数据取 MNIST 的 10%。对每个 $$d$$，模型都训练 100 轮，见[代码](https://github.com/lilianweng/generalization-experiment/blob/master/intrinsic_dimensions.py)

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/20200804_intrinsic-dimension-net-64-64-and-128.png)