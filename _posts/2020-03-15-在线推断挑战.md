---
layout:		post
title:  	在线推断挑战
subtitle:   模型部署系列之四
date:       2020-03-15
author:     一轩明月
header-img: img/post-bg-rwd.jpg
catalog: 	 true
tags:
    - opinions
---

上一篇文章我们讨论了批量推断形式的模型部署问题，探讨了哪些场景适用于批量推断，并基于 Python 和 cron 进行了简单实现。此外，还提到了一些工业级批量推断任务规划工具。我们也列举了一些不适于批量推断的案例。这些场景下模型要能根据请求同步提供预测结果，或者说准实时获取反馈。而这就是在线推断的主场了。

一般来讲在线推断比批量离线推断要复杂的多，这主要是因为需要几乎实时地完成预测、输出结果，系统所受延迟约束甚强。而在具体实现和介绍任何工具之前，我认为有必要先说说从业者在部署在线推断模型时会遇到的一些问题。这些问题是对 Uber 为其 UberEats 用户设计预测模型的失败经验的总结，希望你不会重蹈覆辙。

# 部署在线推理模型的难点

在线推断形式的机器学习模型相较于批量推断模型部署时更具挑战。对系统延迟的硬性约束使得模型必须在几百毫秒内返回结果，容错性显著低于每小时、每天或每周才执行预测任务的批量推断系统。

除此之外，更高的延迟要求还为机器学习系统带来了一些意想不到的挑战。这些问题很少在顶会论文和机器学习团队交流会之外的场景被提起，但每个从业者都有义务对其有充分的认识。

## 特征工程优化

数据科学家多数时候都是为他们的机器学习模型构建和测试不同的特征，但是编写和测试代码的环境与实际线上模型运行的环境可是大相径庭。比如，开发探索期间特征工程中的一步操作经常是一次性对一批样本进行处理，但在线推断面临的约束压力可要比开发期间大得多。

这种处理逻辑在实时推断的时候实在是太慢了，必须优化才能使用。但负责特征工程部分的数据科学家们不见得有写这些优化代码的能力，特别是当产品栈用的是不同的编程语言的时候。比如，我知道很多大公司的数据科学家们都在用 Python 开发模型，但这些模型都在使用 Java 或 C 进行部署。

对此，一个可行解是组织化：一个小组专门负责原型设计，另一个小组专门负责模型的高性能实现。原型团队的目标是保证模型的效果最好，至于代码的可扩展性和鲁棒性则是次要的。将实验代码转换成高可用、严格测试过的基准代码是部署团队的工作。所以，部署团队要负责优化那些实验性质的特征生成逻辑。尽管组织化的专业分工充分利用了不同团队的专业知识，但是两团队间的交付环节却又有问题要解决。

比如说，部署团队的特征工程逻辑要和原型团队保持一致，这需要高质量的测试验证。本文不在此深究更多组织化的问题，但足以证实其并不是一剂灵丹妙药。

## 从多源数据中构造特征

实时推断的延迟约束给模型带来的另一个问题，是从不同数据源构造特征时要面对的复杂性。一些特征可以从请求数据中直接获取，试想一个通过 web API 访问的图像分类模型，“特征构造”在这里就很简单，因为 API 请求中已经包含了所有预测要用到的信息，也就是待分类图像。

但是，当模型需要一些额外数据，同时这些数据并不包含在请求报文当中，情况就变得有些复杂了。支持在线推断的模型必须有能力从其他数据源获取这部分数据，而数据源通常是各式各样的关系或非关系型数据库。如果这些数据库并没有对个体记录的查询做特别优化的话（想想一般的大数据系统），团队就需要定好前置计算流程并给必要的模型特征加上索引。

为了让问题更形象化，不妨思考一下 UberEats 应用中的“[预计送达时间](https://eng.uber.com/michelangelo/)”这一特征。每当有饥饿的用户在饭店下单，机器学习模型就要估计什么时候食物会被送到用户手中。援引文章所述

> 模型所用特征除了请求信息（例如时间，收货地址），**还有**历史特征（例如过去七日内每餐平均准备时间）和近期统计特征（例如最近一小时平均每餐备制时间）
>
> .......
>
> 线上模型不能访问存在 HDFS 上的数据，而且很难找到一种理想的方式直接从支撑 Uber 产品服务的在线数据库里计算一些特征。（比如，绝无可能直接通过请求 UberEATS 订单服务计算过去一段时间某家饭店平均每餐的准备时间）
>
> 相反，我们会将在线模型所需特征提前算好并存在 Cassandra 上，这样能保证预测时读取延迟处在低位。

下图展示了该流程详情

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-03-13_ubereat_infrastructure.png)

部署这样一个系统几乎超出了绝大部分数据科学家的能力范围。实际上这需要一整队数据工程师来维护、监控和管理这个管道。如果你在部署在线推理模型，你必须要考虑到构建复杂特征集的开销。

## 在线推断的 A/B 测试模型

怎样才能判定新模型会比之前所部署的模型带来更多价值？离线标准，诸如准确率，F1 得分和均方根误差可能和用户参与度、留存率这些产品指标[没什么关系](https://blog.acolyer.org/2019/10/07/150-successful-machine-learning-models/)。机器学习模型在离线实验中的评估指标很少能直接等同于商业指标。

比如说推荐模型。数据科学家可能会针对某个数据集优化 [k 精度](http://queirozf.com/entries/evaluation-metrics-for-ranking-problems-introduction-and-examples#precision-k)或者全局平均准确度（[MAP](http://queirozf.com/entries/evaluation-metrics-for-ranking-problems-introduction-and-examples#what-about-map-mean-average-precision)）。但产品团队关心的是像用户产品参与度这样的指标。我们可能认为模型在离线标准下性能越来越好，那么在产品侧也会有不俗表现。但情况并非如此（见[教训 2](https://blog.acolyer.org/2019/10/07/150-successful-machine-learning-models/)）

要想评估新模型在商业环境中的作用，数据科学家们必须用统计中的 A/B 测试作为自己的评价策略。用户群被分成统计意义上相同的两组，每组使用不同的算法。经过一段时间，按照产品标准得到的观测差异会诚实地反映出哪个算法的价值更大。所以机器学习模型的离线性能仅仅只是评估流程的第一步，离线性能是后续 A/B 测试时的决策指标（[ppt 46 页](https://www.slideshare.net/xamat/lessons-learned-from-building-practical-deep-learning-systems)）。

下图展示了评估离线和在线环境下模型表现的整体流程

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-03-14_offline_online_test_process.png)

## 实时推断的上线策略

完成前文描述的在线实验挑战绝非易事。这需要额外的基础设施进行辅助，像流量分流，将请求分发到不同计算模块上以及将结果存好以便于后续数据分析。数据科学家们应该负责拟定实验策略和分析试验结果，而不是还要负责构建和维护实验所需的基础设施。

数据科学家要能做到在将新模型推给全体用户前先对一小部分用户进行展示、测验。在[构建智能系统](https://amzn.to/2GaWhLy)一文中，Geoff Hulten 介绍了 4 种面向终端用户的智能部署方式：

1. **单一部署**：一次性将智能系统同时推给所有用户。这是最简单的方式，但一旦系统出问题必然麻烦不断
2. **静默智能**：也叫作“影子模式”，智能系统和现有模型并行使用，但用户见不到新模型的预测内容。这种方式可以进一步检验模型预测性能，缺点是无法获取用户反馈
3. **可控上线**：给一小部分用户推送新模型的结果，多数用户仍使用旧模型结果。两相比对，通过统计数据就可以决定何时让更多的用户使用新模型。这种方式能保证将无效模型的负面影响降到最低，但实现起来较为复杂
4. **Flighting**：该模式允许通过统计检验来评估哪个新模型表现最好。你可以在线进行 A/B 测试

理想情况下，数据科学家应该能快速、便捷的将模型回滚到早先版本。这能预防一些离线环境下没遭遇过的问题。

## 模型监控

一旦模型部署上线就要密切监控其运行状态。一般模型预测性能都会随着时间推移，环境条件发生变化而降低。这一现象被称作[概念飘移](https://mlinproduction.com/model-retraining/)，当输入的特征分布或是目标结果的分布相较模型训练时发生了变动就会出现这种现象。

如果检测到概念正在飘移，重新训练模型一定程度上能进行缓解。但通过监控来判定飘移是否发生比较困难，特别是在预测生成几天，几周或是数月后才能得到真实反馈信号的情况下。

对此，一种监控策略是使用已部署模型的指标，但要求这些指标能随时间动态观测。例如，即使是在不能及时获取结果的情况下，检测输出结果的分布都有助于确认飘移的发生。将观测到的分布与训练中的输出分布进行对比，当二者出现差异时向数据科学家们发送警告消息。

这里的难处自然在于安装和维护所需的基础设施，而可靠工具的缺失无疑又增加了难度。从开源到商业，能用的工具仅有 [Seldon](https://docs.seldon.io/projects/seldon-core/en/latest/analytics/analytics.html) 和 [Amazon SageMaker](https://docs.seldon.io/projects/seldon-core/en/latest/analytics/analytics.html)。期望有更多的人能投身该领域，毕竟能将模型部署上线但却没有合适的监控组件不可谓不是场灾难。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-03-15_seldon_dashboard.png)