---
layout:		post
title:  	神经结构搜索
subtitle:   
date:       2020-11-11
author:     一轩明月
header-img: img/post-bg-blue.jpg
catalog:    true
tags:
    - reinforcement learning
excerpt:    神经结构搜素（NAS）能自动完成网络结构工程，其目的在于能针对特定任务取得最佳效果的网络拓扑。NAS 技术可以分成三块：搜索空间，搜索算法和评价策略，本文由此回顾了很多有意思的想法，它们都是为了实现更好、更快、更经济的自动神经结构搜索
---

> 编译自：Neural Architecture Search， [Lilian Weng](https://lilianweng.github.io/lil-log/)

尽管大多数既成功又流行的模型架构是人类专家设计出来的，但并不意味着我们已经穷尽了网络结构的可能性并找到了最优项。如果采用一种系统化、自动化的方式学习高性能模型架构，我们找到最佳选择的机会会更大些。

自动学习和演化网络拓扑并不是个新思想（[Stanley 和 Miikkulainen, 2002](http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf)）。近些年，[Zoph 和 Le 2017](https://arxiv.org/abs/1611.01578) 和 [Baker 等人, 2017](https://arxiv.org/abs/1611.02167) 在神经结构搜索（Neural Architecture Search，NAS）领域所做的开创性工作引起了人们的广泛关注。也由此推动了许多更好、更快、更经济的 NAS 方法的诞生。

要涉猎 NAS，[Elsken 等人, 2019](https://arxiv.org/abs/1808.05377) 所做的综述非常不错，他们将 NAS 拆解成由三个主要部分组成的系统，简单明了且常为其他 NAS 引用。

1. **搜索空间**：NAS 搜索空间定义了一系列操作（比如卷积、全连接，池化），并指出怎么拼接这些操作形成有效网络结构。搜索空间的设计往往需要人类经验，也就不可避免的会带有人类偏见。
2. **搜索算法**：NAS 搜索算法会在诸多网络结构候选项中进行采样。它以子模型性能标准为回报（比如准度高，延迟小），尽可能找到最佳高性能结构候选。
3. **评价策略**：要测算、估计或预测一众被举荐子模型的性能，这样才能得到搜索算法学习所需的反馈。候选人评估过程可能会开销很大，人们也已经设计了很多新方法节省时间或计算资源。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_NAS-high-level.png)

*图 1  神经结构搜索（NAS）的三个主要部分（图片来源：[Elsken 等, 2019](https://arxiv.org/abs/1808.05377))*

### 搜索空间

NAS 搜索空间定义了一系列网络基础操作，并规定怎么组合操作来构建有效网络结构。

#### 顺次层向操作

构建神经网络结构搜索空间的最原始方式是描绘网络拓扑，要么 CNN 要么 RNN，带着一系列 *顺次层向操作（sequential layer-wise operations）*，可参考早期工作 [Zoph 与 Le 2017](https://arxiv.org/abs/1611.01578) 和 [Baker 等人, 2017](https://arxiv.org/abs/1611.02167)。网络表示的序列需要大量专业知识，因为每个操作都与不同层的参数关联，这样的联结需要硬编码。比如，`conv` 操作之后模型应该输出核大小，步幅等信息；又或者在 `FC` 操作之后我们需要知道下一轮预测的单元数量。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_NAS-search-space.png)

*图 2  （上）CNN 的序列表示（下）循环单元树结构的序列表示（图片来源：[Zoph 和 Le 2017](https://arxiv.org/abs/1611.01578)）*

要保证得到的结构有效，还得加点规则（[Zoph 和 Le 2017](https://arxiv.org/abs/1611.01578)）：

- 如果某层没与任何输入层相连，那就将其作为输入层；
- 在最后一层，把所有没被连接的输出结果连起来；
- 如果某一层有多个输入层，那将所有输入层按深度连接起来
- 如果待连接输入层大小不一，较小的层用 0 填充使尺寸统一

用类似注意力的机制，跳跃连接关系也能预测。在 $$i$$ 层会在锚点上加上 $$i-1$$ 个基于内容的 sigmoid 信息，以此表示与前面哪些层有关联。每个 sigmoid 函数以当前节点 $$h_i$$ 的隐态和之前 $$i-1$$ 个节点 $$h_j,j=1,\dots,i-1$$ 作为输入。


$$
P(\text{j 层是 i 层的输入}) = \text{sigmoid}(v^\top \tanh(\mathbf{W}_\text{prev} h_j + \mathbf{W}_\text{curr} h_i))
$$



顺次搜索空间的表示能力很强，但它太大了，要详尽覆盖搜索空间要花费巨量计算资源。[Zoph 和 Le 2017](https://arxiv.org/abs/1611.01578) 的实验用了 800 块 GPU 并行跑了 28 天，[Baker 等人, 2017](https://arxiv.org/abs/1611.02167) 对搜索空间加了点限制，最多不超过 2 个 `FC` 层。

#### 单元表示

受已有建树的视觉模型架构（如 Inception，ResNet）启发，特别是复用组件这一设计思路影响，*NASNet 搜索空间*（[Zoph 等 2018](https://arxiv.org/abs/1707.07012)）设计了一种卷积网络结构，相同单元重复许多次，每个单元里面包含若干 NAS 算法给出的运算操作。设计良好的组件单元具备数据集间的可迁移性。通过调整单元数量也很容易调小或增大模型。

准确地讲，NASNet 搜索空间要学两类单元来构建网络：

1. *一般单元（Normal Cell）*：输入输出的特征维数相同
2. *缩放单元（Reduction Cell）*：输出特征的宽高减半

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_NASNet-search-space.png)

*图 3  NASNet 搜索空间构建了由一叠重复单元组成的结构。单元框架通过 NAS 算法优化（图片来源：[Zoph 等 2018](https://arxiv.org/abs/1707.07012)）*

每个单元的预测被分组归入 $$B$$  个区块（NASNet 论文里 $$B=5$$），每个区块里有 5 步预测，预测由 5 个互不相同的 softmax 分类器给出，代表区块提供的几种选择。注意 NASNet 搜索空间在单元间不存在残差连接，模型仅在区块内部学习跳跃连接关系。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_cell-prediction-steps.png)

*图 4  （a）每个单元包括 $$B$$ 个区块，每个区块由 5 个独立决策决定（b）每步决策都能选什么操作的具体例子*

实验中人们发现了一个 [*DropPath*](https://arxiv.org/abs/1605.07648) 变种，起名叫 *ScheduledDropPath*，这显著改善了最终 NASNet 实验性能。DropPath 会以固定概率随机丢掉一些路径（也就是 NASNet 里通过操作连接的边）。ScheduledDropPath 会随时间线性增大路径丢弃概率。

[Elsken 等人，2019](https://arxiv.org/abs/1808.05377) 指出 NASNet 搜索空间主要有三大优势：

1. 大幅缩减了空间规模
2. 基于[样式](https://en.wikipedia.org/wiki/Network_motif)的架构很容易用到不同数据集上
3. 证明架构工程中重复堆叠模组这一设计模式确实有用。比如，可以在 CNN 里堆叠残差块，在 Transformer 里堆叠多头注意力块来构建强力模型

#### 层次结构

要想利用已知的精心设计过的网络[样式](https://en.wikipedia.org/wiki/Network_motif)，NAS 搜索空间可以强制转为层次结构，就像在*分层 NAS（Hierarchical NAS，HNAS）*（[Liu 等人，2017](https://arxiv.org/abs/1711.00436)） 中一样。起初是一小撮初始运算，包括卷积，池化，单位阵等在内的单独操作，然后由初始运算构成的小子图（或“样式”）递归地构建上层计算图。

在 $$\ell=1, \dots, L$$  层的计算样式可以表示为 $$(G^{(\ell)}, \mathcal{O}^{(\ell)})$$，其中：

- $$\mathcal{O}^{(\ell)}$$ 是一组操作，$$\mathcal{O}^{(\ell)} = \{ o^{(\ell)}_1, o^{(\ell)}_2, \dots \}$$
- $$G^{(\ell)}$$ 是邻接矩阵，条目 $$G_{ij}=k$$ 表示结点 $$i$$ 和 $$j$$ 间的操作为 $$o^{(\ell)}_k$$，结点索引遵循 DAG 中的[拓扑顺序](https://en.wikipedia.org/wiki/Topological_sorting)，索引从 $$1$$ 开始，最大的索引对应沉寂点

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_hierarchical-NAS-search-space.png)

*图 5  （上）三个 1 级初始运算构成一个 2 级样式（下）将三个 2 级样式插入基础网络集成为一个 3 级样式（图片来源：[Liu 等人，2017](https://arxiv.org/abs/1711.00436)*

要想按层级结构搭个网络，要从最低的 $$\ell=1$$ 级开始，递归地定义 $$\ell$$ 级的第 $$m$$ 个样式：


$$
o^{(\ell)}_m = \text{assemble}\Big( G_m^{(\ell)}, \mathcal{O}^{(\ell-1)} \Big)
$$


层次表示变成 $$\Big( \big\{ \{ G_m^{(\ell)} \}_{m=1}^{M_\ell} \big\}_{\ell=2}^L, \mathcal{O}^{(1)} \Big), \forall \ell=2, \dots, L$$，其中 $$\mathcal{O}^{(1)}$$ 里是一系列初始操作。

$$\text{assemble}()$$ 过程等价于顺次计算结点 $$i$$ 的特征映射，按拓扑顺序把它之前的结点 $$j$$ 的所有特征映射聚集起来：


$$
x_i = \text{merge} \big[ \{ o^{(\ell)}_{G^{(\ell)}_{ij}}(x_j) \}_{j < i} \big], i = 2, \dots, \vert G^{(\ell)} \vert
$$


论文里 $$\text{merge}[]$$ 是按深度连接的。



#### 记忆库表示

### 搜索算法

#### 随机搜索

#### 强化学习

- $$a_{1:T}$$, where $$T$$
- , $$R$$.
-  $$\theta$$ 

$$
\nabla_{\theta} J(\theta) = \sum_{t=1}^T \mathbb{E}[\nabla_{\theta} \log P(a_t \vert a_{1:(t-1)}; \theta) R ]
$$


$$
Q^{(t+1)}(s_t,  a_t) = (1 - \alpha)Q^{(t)}(s_t, a_t) + \alpha (R_t + \gamma \max_{a \in \mathcal{A}} Q^{(t)}(s_{t+1},  a'))
$$
 $$s_t$$ $$a$$

#### 演化算法

 $$1$$,

1.  $$S$$ 

#### 渐进决策过程



> $$f(n)=g(n)+h(n)$$, $$n$$  $$g(n)$$  $$n$$, and $$h(n)$$  $$n$$ 

 $$B$$   $$B=1$$,  $$B$$ 

#### 梯度下降

### 评价策略

#### 从头训练

#### 代理任务性能

$$\nu$$- $$\nu$$-

#### 参数共享

 $$\omega$$   $$\theta$$:

1.  $$\theta$$   $$R(\mathbf{m}, \omega)$$ 
2.  $$\omega$$ 

#### 从预测出发

### 单样本法：搜索+评价

 $$r^{1/k}$$  $$0 < r < 1$$  $$k$$ i

 $$N$$  $$x_i$$  $$(i, j)$$  $$o^{(i,j)} \in \mathcal{O}$$  $$x_j$$  $$x_i$$
$$
x_i = \sum_{j < i} o^{(i,j)}(x_j)
$$
s $$\alpha = \{ \alpha^{(i,j)} \}$$.
$$
\bar{o}^{(i,j)}(x) = \sum_{o\in\mathcal{O}} \frac{\exp(\alpha_{ij}^o)}{\sum_{o'\in\mathcal{O}} \exp(\alpha^{o'}_{ij})} o(x)
$$
 $$\alpha_{ij}$$  $$\vert \mathcal{O} \vert$$, $$i$$ and $$j$$ 
$$
\begin{aligned}
\min_\alpha & \mathcal{L}_\text{validate} (w^*(\alpha), \alpha) \\
\text{s.t.} & w^*(\alpha) = \arg\min_w \mathcal{L}_\text{train} (w, \alpha)
\end{aligned}
$$
 $$k$$,  $$\alpha_{k−1}$$,  $$w_k$$  $$w_{k−1}$$  $$\mathcal{L}_\text{train}(w_{k−1}, \alpha_{k−1})$$ e $$\xi$$.  $$w_k$$ 
$$
J_\alpha = \mathcal{L}_\text{val}(w_k - \xi \nabla_w \mathcal{L}_\text{train}(w_k, \alpha_{k-1}), \alpha_{k-1})
$$
 $$w^∗(\alpha)$$. 
$$
\begin{aligned}
\text{Let }w'_k &= w_k - \xi \nabla_w \mathcal{L}_\text{train}(w_k, \alpha_{k-1}) & \\
J_\alpha &= \mathcal{L}_\text{val}(w_k - \xi \nabla_w \mathcal{L}_\text{train}(w_k, \alpha_{k-1}), \alpha_{k-1}) = \mathcal{L}_\text{val}(w'_k, \alpha_{k-1}) & \\
\nabla_\alpha J_\alpha 
&= \nabla_{\alpha_{k-1}} \mathcal{L}_\text{val}(w'_k, \alpha_{k-1}) \nabla_\alpha \alpha_{k-1} + \nabla_{w'_k} \mathcal{L}_\text{val}(w'_k, \alpha_{k-1})\nabla_\alpha w'_k & \\& \text{; multivariable chain rule}\\
&= \nabla_{\alpha_{k-1}} \mathcal{L}_\text{val}(w'_k, \alpha_{k-1}) + \nabla_{w'_k} \mathcal{L}_\text{val}(w'_k, \alpha_{k-1}) \big( - \xi \color{red}{\nabla^2_{\alpha, w} \mathcal{L}_\text{train}(w_k, \alpha_{k-1})} \big) & \\
&\approx \nabla_{\alpha_{k-1}} \mathcal{L}_\text{val}(w'_k, \alpha_{k-1}) - \xi \nabla_{w'_k} \mathcal{L}_\text{val}(w'_k, \alpha_{k-1}) \color{red}{\frac{\nabla_\alpha \mathcal{L}_\text{train}(w_k^+, \alpha_{k-1}) - \nabla_\alpha \mathcal{L}_\text{train}(w_k^-, \alpha_{k-1}) }{2\epsilon}} & \\
& \text{; apply numerical differentiation approximation}
\end{aligned}
$$
$$w_k^+ = w_k + \epsilon \nabla_{w'_k} \mathcal{L}_\text{val}(w'_k, \alpha_{k-1})$$  $$w_k^- = w_k - \epsilon \nabla_{w'_k} \mathcal{L}_\text{val}(w'_k, \alpha_{k-1})$$.

 $$N=7$$  $$N$$.

 $$G$$ $$G_{ij}$$  $$i$$ and $$j$$ a  $$\vert \mathcal{O} \vert$$   $$\mathcal{O} = \{ o_1, \dots \}$$. 

 $$m_\mathcal{O}(x)$$  $$\alpha$$  $$\vert \mathcal{O} \vert$$. $$\alpha$$
$$
\begin{aligned}
m^\text{one-shot}_\mathcal{O}(x) &= \sum_{i=1}^{\vert \mathcal{O} \vert} o_i(x) \\
m^\text{DARTS}_\mathcal{O}(x) &= \sum_{i=1}^{\vert \mathcal{O} \vert} p_i o_i(x) = \sum_{i=1}^{\vert \mathcal{O} \vert} \frac{\exp(\alpha_i)}{\sum_j \exp(\alpha_j)} o_i(x) \\
m^\text{binary}_\mathcal{O}(x) &= \sum_{i=1}^{\vert \mathcal{O} \vert} g_i o_i(x) = \begin{cases}
o_1(x) & \text{with probability }p_1, \\
\dots &\\
o_{\vert \mathcal{O} \vert}(x) & \text{with probability }p_{\vert \mathcal{O} \vert}
\end{cases} \\
\text{ where } g &= \text{binarize}(p_1, \dots, p_N) = \begin{cases}
[1, 0, \dots, 0] & \text{with probability }p_1, \\
\dots & \\
[0, 0, \dots, 1] & \text{with probability }p_N. \\
\end{cases}
\end{aligned}
$$

1.  $$m^\text{binary}_\mathcal{O}(x)$$. 
2.  $$\alpha$$, $$w$$, $$\alpha$$  $$\partial \mathcal{L} / \partial g_i$$   $$\partial \mathcal{L} / \partial g_i$$ 

$$
\begin{aligned}
\frac{\partial \mathcal{L}}{\partial \alpha_i} 
&= \sum_{j=1}^{\vert \mathcal{O} \vert} \frac{\partial \mathcal{L}}{\partial p_j} \frac{\partial p_j}{\partial \alpha_i} 
\approx \sum_{j=1}^{\vert \mathcal{O} \vert} \frac{\partial \mathcal{L}}{\partial g_j} \frac{\partial p_j}{\partial \alpha_i} 
= \sum_{j=1}^{\vert \mathcal{O} \vert} \frac{\partial \mathcal{L}}{\partial g_j} \frac{\partial \frac{e^{\alpha_j}}{\sum_k e^{\alpha_k}}}{\partial \alpha_i} \\
&= \sum_{j=1}^{\vert \mathcal{O} \vert} \frac{\partial \mathcal{L}}{\partial g_j} \frac{\sum_k e^{\alpha_k} (\mathbf{1}_{i=j} e^{\alpha_j}) - e^{\alpha_j} e^{\alpha_i} }{(\sum_k e^{\alpha_k})^2}
= \sum_{j=1}^{\vert \mathcal{O} \vert} \frac{\partial \mathcal{L}}{\partial g_j} p_j (\mathbf{1}_{i=j} -p_i)
\end{aligned}
$$

 $$\partial \mathcal{L} / \partial g_i$$ $$o_i(x)$$,  $$\vert \mathcal{O} \vert$$ 

 $$\mathbb{E}[\text{latency}] = \sum_j p_j F(o_j)$$,   $$F(.)$$ i

### 未来远景

### 附录：NAS 论文总结

<table class="info">
    <thead>
        <tr>
            <th>Model name</th>
            <th>Search space</th>
            <th>Search algorithms</th>
            <th>Child model evaluation</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td><a href="http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf">NEAT (2002)</a></td>
            <td>-</td>
            <td>Evolution (Genetic algorithm)</td>
            <td>-</td>
        </tr>
        <tr>
            <td><a href="https://arxiv.org/abs/1611.01578">NAS (2017)</a></td>
            <td>Sequential layer-wise ops</td>
            <td>RL (REINFORCE)</td>
            <td>Train from scratch until convergence</td>
        </tr>
        <tr>
            <td><a href="https://arxiv.org/abs/1611.02167">MetaQNN (2017)</a></td>
            <td>Sequential layer-wise ops</td>
            <td>RL (Q-learning with $\epsilon$-greedy)</td>
            <td>Train for 20 epochs</td>
        </tr>
        <tr>
            <td><a href="https://arxiv.org/abs/1711.00436">HNAS (2017)</a></td>
            <td>Hierarchical structure</td>
            <td>Evolution (Tournament selection)</td>
            <td>Train for a fixed number of iterations</td>
        </tr>
        <tr>
            <td><a href="https://arxiv.org/abs/1707.07012">NASNet (2018)</a></td>
            <td>Cell-based</td>
            <td>RL (PPO)</td>
            <td>Train for 20 epochs</td>
        </tr>
        <tr>
            <td><a href="https://arxiv.org/abs/1802.01548">AmoebaNet (2018)</a></td>
            <td>NASNet search space</td>
            <td>Evolution (Tournament selection with aging regularization)</td>
            <td>Train for 25 epochs</td>
        </tr>
        <tr>
            <td><a href="https://arxiv.org/abs/1707.04873">EAS (2018a)</a></td>
            <td>Network transformation</td>
            <td>RL (REINFORCE)</td>
            <td>2-stage training</td>
        </tr>
        <tr>
            <td><a href="https://arxiv.org/abs/1712.00559">PNAS (2018)</a></td>
            <td>Reduced version of NASNet search space</td>
            <td>SMBO; Progressive search for architectures of increasing complexity</td>
            <td>Train for 20 epochs</td>
        </tr>
        <tr>
            <td><a href="https://arxiv.org/abs/1802.03268">ENAS (2018)</a></td>
            <td>Both sequential and cell-based search space</td>
            <td>RL (REINFORCE)</td>
            <td>Train one model with shared weights</td>
        </tr>
        <tr>
            <td><a href="https://arxiv.org/abs/1708.05344">SMASH (2017)</a></td>
            <td>Memory-bank representation</td>
            <td>Random search</td>
            <td>HyperNet predicts weights of evaluated architectures.</td>
        </tr>
        <tr>
            <td><a href="http://proceedings.mlr.press/v80/bender18a.html">One-Shot (2018)</a></td>
            <td>An over-parameterized one-shot model</td>
            <td>Random search (zero out some paths at random)</td>
            <td>Train the one-shot model</td>
        </tr>
        <tr>
            <td><a href="https://arxiv.org/abs/1806.09055">DARTS (2019)</a></td>
            <td>NASNet search space</td>
            <td colspan="2">Gradient descent (Softmax weights over operations)</td>
        </tr>
        <tr>
            <td><a href="https://arxiv.org/abs/1812.00332">ProxylessNAS (2019)</a></td>
            <td>Tree structure architecture</td>
            <td colspan="2">Gradient descent (BinaryConnect) or REINFORCE</td>
        </tr>
        <tr>
            <td><a href="https://arxiv.org/abs/1812.09926">SNAS (2019)</a></td>
            <td>NASNet search space</td>
            <td colspan="2">Gradient descent (concrete distribution)</td>
        </tr>
    </tbody>
</table>








![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_path-level-network-transformations.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_NAS-memory-bank-view-representation.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_NAS.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_MetaQNN.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_NEAT-mutations.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_aging-evolution-algorithm.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_AmoebaNet-mutations.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_progressive-NAS-algorithm.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_EAS-meta-controller.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_ENAS-example.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_SMASH-algorithm.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_SMASH-error-correlation.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_one-shot-model-architecture.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_one-shot-model-accuracy-correlation.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_DARTS-illustration.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_DARTS-algorithm.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_proxylessNAS-training.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_ProxylessNAS-latency.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_AutoML-zero-evaluation.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_AutoML-zero-progress.png)