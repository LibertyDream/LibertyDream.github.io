---
layout:		post
title:  	神经结构搜索
subtitle:   
date:       2020-11-11
author:     一轩明月
header-img: img/post-bg-blue.jpg
catalog:    true
tags:
    - reinforcement learning
excerpt:    神经结构搜素（NAS）能自动完成网络结构工程，其目的在于能针对特定任务取得最佳效果的网络拓扑。NAS 技术可以分成三块：搜索空间，搜索算法和评价策略，本文由此回顾了很多有意思的想法，它们都是为了实现更好、更快、更经济的自动神经结构搜索
---

> 编译自：Neural Architecture Search， [Lilian Weng](https://lilianweng.github.io/lil-log/)

尽管大多数既成功又流行的模型架构是人类专家设计出来的，但并不意味着我们已经穷尽了网络结构的可能性并找到了最优项。如果采用一种系统化、自动化的方式学习高性能模型架构，我们找到最佳选择的机会会更大些。

自动学习和演化网络拓扑并不是个新思想（[Stanley 和 Miikkulainen, 2002](http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf)）。近些年，[Zoph 和 Le 2017](https://arxiv.org/abs/1611.01578) 和 [Baker 等人, 2017](https://arxiv.org/abs/1611.02167) 在神经结构搜索（Neural Architecture Search，NAS）领域所做的开创性工作引起了人们的广泛关注。也由此推动了许多更好、更快、更经济的 NAS 方法的诞生。

要涉猎 NAS，[Elsken 等人, 2019](https://arxiv.org/abs/1808.05377) 所做的综述非常不错，他们将 NAS 拆解成由三个主要部分组成的系统，简单明了且常为其他 NAS 引用。

1. **搜索空间**：NAS 搜索空间定义了一系列操作（比如卷积、全连接，池化），并指出怎么拼接这些操作形成有效网络结构。搜索空间的设计往往需要人类经验，也就不可避免的会带有人类偏见。
2. **搜索算法**：NAS 搜索算法会在诸多网络结构候选项中进行采样。它以子模型性能标准为回报（比如准度高，延迟小），尽可能找到最佳高性能结构候选。
3. **评价策略**：要测算、估计或预测一众被举荐子模型的性能，这样才能得到搜索算法学习所需的反馈。候选人评估过程可能会开销很大，人们也已经设计了很多新方法节省时间或计算资源。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_NAS-high-level.png)

*图 1  神经结构搜索（NAS）的三个主要部分（图片来源：[Elsken 等, 2019](https://arxiv.org/abs/1808.05377))*

### 搜索空间

NAS 搜索空间定义了一系列网络基础操作，并规定怎么组合操作来构建有效网络结构。

#### 顺次层向操作

构建神经网络结构搜索空间的最原始方式是描绘网络拓扑，要么 CNN 要么 RNN，带着一系列 *顺次层向操作（sequential layer-wise operations）*，见于早期工作 [Zoph 与 Le 2017](https://arxiv.org/abs/1611.01578) 和 [Baker 等人, 2017](https://arxiv.org/abs/1611.02167)。网络表示的序列需要大量专业知识，因为每个操作都与不同层的参数关联，这样的联结需要硬编码。比如，`conv` 操作之后模型应该输出核大小，步幅等信息；又或者在 `FC` 操作之后我们需要知道下一轮预测的单元数量。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_NAS-search-space.png)

*图 2  （上）CNN 的序列表示（下）循环单元树结构的序列表示（图片来源：[Zoph 和 Le 2017](https://arxiv.org/abs/1611.01578)）*

要保证得到的结构有效，还得加点规则（[Zoph 和 Le 2017](https://arxiv.org/abs/1611.01578)）：

- 如果某层没与任何输入层相连，那就将其作为输入层；
- 在最终层，把所有没被连接的层输出连起来；
- 如果某一层有多个输入层，那将所有输入层按深度连接起来
- 如果待连接输入层大小不一，较小的层用 0 填充使尺寸统一



#### 单元表示

#### 层次结构

#### 记忆库表示

### 搜索算法

#### 随机搜索

#### 强化学习

#### 演化算法

#### 渐进决策过程

#### 梯度下降

### 评价策略

#### 从头训练

#### 代理任务性能

#### 参数共享

#### 从预测出发

### 单样本法：搜索+评价

### 未来远景

### 附录：NAS 论文总结





![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_NASNet-search-space.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_cell-prediction-steps.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_hierarchical-NAS-search-space.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_path-level-network-transformations.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_NAS-memory-bank-view-representation.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_NAS.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_MetaQNN.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_NEAT-mutations.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_aging-evolution-algorithm.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_AmoebaNet-mutations.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_progressive-NAS-algorithm.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_EAS-meta-controller.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_ENAS-example.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_SMASH-algorithm.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_SMASH-error-correlation.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_one-shot-model-architecture.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_one-shot-model-accuracy-correlation.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_DARTS-illustration.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_DARTS-algorithm.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_proxylessNAS-training.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_ProxylessNAS-latency.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_AutoML-zero-evaluation.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-11-11_AutoML-zero-progress.png)