---
layout:     post
title:      为什么正态分布如此重要?
subtitle:   高斯分布广泛存在的原因解析
date:       2019-08-24
author:     一轩明月
header-img: img/post-bg-snow.jpg
catalog: 	 true
tags:
    - math
excerpt:    机器学习的核心是概率分布，而概率分布的核心是正态分布。本文试图用相对简单的方式阐述什么是概率分布，什么是正态分布，以及正态分布为什么使用的如此广泛。
---

> 文章编译自：
>
> https://medium.com/fintechexplained/ever-wondered-why-normal-distribution-is-so-important-110a482abee3

机器学习的核心是概率分布，而概率分布的核心是正态分布。本文试图用相对简单的方式向数据科学学习和工作者阐述什么是正态分布，以及正态分布为什么使用的如此广泛。

本文主要内容如下：

1. 什么是概率分布
2. 什么是正态分布
3. 什么样的变量服从正态分布
4. Python 里怎么查验数据集分布
5. Python 里如何使一个变量“正态化”
6. 注意事项

### 说在前面

正态分布（normal distribution)也叫高斯分布(Gaussian distribution)，以大数学家高斯之名命名

往往预测模型越简单，就越容易理解，便于解释，通常使用的也就越多。正态分布就很简单，所以它十分常见

### 什么是概率分布

当我们考虑在数据科学项目里用什么预测模型时，常会遇到下面的情景：

* 如果我们想精准预测一个变量，首先要理解目标变量的基本表现形式
* 所以我们得先决定目标变量的可能结果有哪些，结果是连续的还是离散的。比如掷骰子时，通常我们会认为它可能是 1 到 6 的任意离散值
* 随后我们就要给不同的事件（结果值）分配可能性。如果一个事件不会发生，其分得的可能性是 0%。可能性越大，就越可能发生
* 大量重复试验，观察记录每次实验中目标变量呈现的结果
* 给结果分组归类。记录下各个类别出现的次数。比如我们掷骰子 10000 次，每次结果会是 6 个可能值中的一种，结果就分六组，每次实验结束后修改对应类别的值

将最终结果绘制成图像，会看到一条曲线。这条曲线就是概率分布曲线，目标变量取得不同值的可能性就是该变量的概率分布。

知道了值的分布形式，就可以对事件结果的可能性进行估计，甚至可以套公式（称为概率分布函数）。由此进一步了解目标变量的行为。

概率分布依赖于样本的矩，比如均值，标准差，偏度和峰度等。所有可能性加和是 100%。

概率分布有很多，最为广泛使用的概率分布是”正态分布“

### 什么是正态分布

如果你绘制出来的概率分布是一条钟型曲线，且平均值、众数和中位数都是相等的，那么该变量就服从正态分布。

![]( https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-08-24_normal_distribution.png)

理解目标变量并估计其概率分布很重要，下面这些变量近乎于满足正态分布：

1. 人类身高
2. 血压
3. 扩散后的粒子位置
4. 测量误差
5. 回归偏差
6. 人类脚掌大小
7. 雇员下班到家的时间

我们身边大量的事件是置信度为 x% 的正态分布，x < 100

正态分布是只依赖于样本均值和标准差两个参数的分布。

* 平均值：所有样本点的平均值
* 标准差：数据集相对平均值的偏离程度

正是这样的特性使得正态分布不仅便于统计，而且当知悉某变量服从正态分布时，对其估计往往很准。

值得注意的是，你在大自然中发现的绝大多数变量都近乎服从正态分布。正态分布也很好解释：

1. 分布的均值、众数和中位数相同
2. 只要给出均值、标准差就能确定正态分布形式

### 什么样的变量服从正态分布

正态分布这么简单且为我们熟知，但为什么这么多变量遵循这种分布呢？背后的逻辑在哪里？

这一想法其实依赖于这样一个法则：当我们对大量随机变量进行大量重复试验时，这些变量分布加和后会非常趋近于正态分布。比如人类身高是一个随机变量，其依赖于众多其他因素，比如营养水平，居住环境，基因等等。这些变量的分布加和最终呈现为身高这一变量趋近于正态分布。这也被称为**中心极限定理**

这样我们就明白了正态分布其实是相互独立的若干随机变量概率分布加和的结果。如果我们仔细看正态分布的概率密度函数曲线，比如下面这条均值为 100，标准差为 1 的分布曲线。会发现一些特点：

![]( https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-08-24_normal_distribution.png)

* 平均值是曲线中心。也就是取得曲线最高点位置的值，因为大多数点都分布在均值附近
* 曲线两侧可取的点数量相同，中心点数量最多
* 曲线下方覆盖的区域是随机变量取值的所有可能性
* 曲线下方覆盖面积为 100%

![]( https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-08-24_normal_distribution_1.png)

* 接近 68.2% 的点聚集在距离中心点 1 个标准差的范围内
* 接近 95.5% 的点聚集在距离中心点 2 个标准差的范围内
* 接近 99.7% 的点聚集在距离中心点 3 个标准差的范围内

因此可以很方便的估计变量波动水平和置信度，以及它大概率会取什么值。比如对给定样例曲线，我们可以说有 68.2% 的可能性变量取值介于 99 和 101 之间

正态分布的概率密度函数如下：

![]( https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-08-24_normal_distribution_formula.jpg)

概率密度函数本质上是连续型随机变量取得任意值的概率

* 依照概率密度函数绘制概率分布曲线，给定某个范围，曲线下方包围的面积就是随机变量在给定范围中的取值概率
* 概率分布曲线依照概率密度函数绘制，而概率密度函数又是依靠平均值和标准差等其他参数确定的
* 依照概率密度函数可以计算变量取值落在某一范围的相对可能性。比如，可以每天记录股票回报，将它们适当分桶，估计股票未来取得 20%-40% 回报的概率

标准差越大，样本波动性越强

### Python 里怎么识别特征分布

最简单的方式是将数据全部加载进 DataFrame 里并使用如下脚本：

```python
# 制作 DataFrame 的直方图
pandas.DataFrame.hist(bins=10)
```

这样我们就能看到所有变量的概率分布了

知道了中心极限定理，可以选择添加不同分布下的大量随机变量，使新变量遵循正态分布。

呈现正态分布的变量总是遵循正态分布的。比如，假设 A 和 B 是两个遵循正态分布的随机变量：

* $$ A \times B $$ 服从正态分布
* $$ A + B $$ 服从正态分布

这无疑给变量预测和估计其在某范围的概率带来了巨大便利

### 如果样本分布不是正态分布

假如你遇到的样本分布不是正态分布，你可以将其转化为正态分布。你可以使用下列方法：

1. 线性转化

收集到了变量样本后，遵循下列步骤使其标准化

* 计算平均数
* 计算标准差
* 对每个样本计算z值

![]( https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-08-24_z_socre.png)

2. 使用 box-cox 变换

借助 SciPy 包将数据转化为正态分布

```python
scipy.stats.boxcox(x, lmbda=None, alpha=None)
```

3. 使用 Yeo-Johnson 变换

scikit-learn 包里还提供了 Yeo-Johnson 变换方法

```python
sklearn.preprocessing.PowerTransformer(method='yeo-johnson', standardize=True, copy=True)
```

_在使用转换器前最好了解一下。对 box-cox 和 Yeo-Johnson 转换器的介绍及用例超过本文介绍范围_

### 注意事项

正态分布简单好理解，但也会被滥用。预先假设服从正态分布有其自身缺陷。比如我们不能假设股票价格遵循正态分布，因为价格不能为负。所以股价可能会遵循正态分布的对数，以保证非负

而收益率可以为负，所以我们可以假设收益率服从正态分布。但是不加分析就认为变量服从正态分布无疑是不明智的

随机变量可以遵循泊松分布，t 分布或者二项分布，此时假设变量遵循正态分布会导致不准确的结果