---
layout: post
title: 统计学习方法摘要笔记(一)
subtitle: 第一章：统计学习与监督学习概论
date: 2019-08-08
author: 一轩明月
header-img: img/post-bg-ai.jpg
catalog: true
tags:
    - Data Science
    - Math
---

_第一章主要介绍相关概念与定义，比较琐碎，如果用 Chrome浏览器浏览的话，可以添加这个[插件](https://chrome.google.com/webstore/detail/mathjax-plugin-for-github/ioemnmodlmafdkllaclgeombjnmnbima)_

# 1.1 统计学习

所谓学习，就是一个系统能够通过某个过程改善自身的性能。统计学习就是从已有数据上学习规律，再应用到新数据上。

## 统计学习的特点

1. 以计算机和网络为平台
2. 以数据为研究对象
   * 数据类型多样，文本、图像、数字……
   * 基本假设：数据具有共同性质，有一定的统计规律，独立同分布
   * 离散变量和连续变量
3. 学习目的是对数据进行预测与分析
   * 数据能告诉我们新知，改善机器性能。
   * 预测分析靠模型实现，目标转换为选什么模型、怎么构建模型，兼顾效率
4. 以方法为中心，即构建模型与应用模型
   * 统计学习分为监督学习、无监督学习、强化学习等
   * **在给定、有限的训练集（已知的，用于学习构建模型的）上，依靠某个评价标准从所有可能的模型中（假设空间）选取最优模型，使其在训练集和测试集（未知的，用于检验模型质量的）上都有最优表现。这样就凑齐了三要素，模型假设空间——模型，选择标准——策略和模型学习算法——算法**
5. 概率、代数、优化等多领域交叉的混血儿，后自成一派
6. 智能化的道路上，依靠数据的统计学习虽有局限，但目前仍是实现这一目标的最有效手段。

# 1.2 统计学习的分类

##  1.2.1 基本分类

1. 监督学习

监督学习（supervised learning)是从标注数据（往往由人工给出）中学习预测模型，即从有答案的习题本中学习套路。本质是学习输入到输出的映射的统计规律。

**输入空间（input space）**:输入值所有可能的取值集合

**输出空间（output space）**：输出值所有可能的取值集合

**实例（instance）**：每一个具体的输入，通常由特征向量（feature vector)表示

**特征空间（feature space）**：特征向量存在的空间，每一维表示一个特征。**模型都是定义在特征空间上的**

**输入**：定义在输入空间上的随机变量的取值。输入变量通常记作 $$X$$,取值记作 $$x$$

**输出**：定义在输出空间上的随机变量的取值。输出变量通常记作 $$Y$$,取值记作 $$y$$

输入输出都可以是一维到多维，是标量或是向量，默认为列向量。

输入实例的特征向量记作 $$x=\left(x^{(1)}, x^{(2)}, \cdots, x^{(i)}, \cdots, x^{(n)}\right)^{T}$$，注意 $$x^{(i)}$$ 表示 $$x$$ 的第 $$i$$ 个特征，$$x_{i}$$ 表示若干输入变量中的第 $$i$$ 个变量，即 $$x_{i}=\left(x_{i}^{(1)}, x_{i}^{(2)}, \cdots, x_{i}^{(n)}\right)^{\mathrm{T}}$$ 

**样本（sample）**：也称样本点，由输入和输出构成的数据对。表示为 $$\left(x_{i}, y_{i}\right)$$

**训练集（training data)**：用于模型学习的数据集合，通常记作 $$T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}$$

**测试集（test data)**: 用于预测、评估模型质量的数据集合

**回归问题**：输入、输出变量都为连续变量的预测问题

**分类问题**：输出变量为有限离散变量的预测问题

**标注问题**：输入、输出变量均为变量序列

**假设空间（hypothesis space）**：从输入到输出的映射关系由模型来表示，这些模型的集合即为假设空间。模型可以是概率的或是非概率的，由条件概率分布 $$P(Y| X)$$ 或决策函数（decision function）$$Y=f(X)$$  表示，对具体输入的预测记为 $$P(y | x)$$ 或 $$y=f(x)$$

监督学习假设训练集合测试集的数据都是依据联合概率分布 $$P(X,Y)$$ 独立同分布产生的。

监督学习分为学习和预测两个部分，对应于学习系统和预测系统。学习系统会在训练集上学到一个模型，表现为条件概率分布 $$\hat{P}(Y | X)$$ 或决策函数 $$Y=\hat{f}(X)$$ 。对于预测系统中给定的输入 $$x_{N+1}$$，由模型 $$y_{N+1}=\arg \max _{y} \hat{P}\left(y | x_{N+1}\right)$$ 或 $$y_{N+1}=\hat{f}\left(x_{N+1}\right)$$ 给出相应的输出 $$y_{N+1}$$

如果模型预测能力足够好，训练样本中得到的输出 $$y_{i}$$ 和具体模型的输出 $$f(x_{i})$$ 间的差距应该足够小，同时对测试集也能有尽可能好的推广。

![]( https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-08-05_supervised_learning.png)

2. 无监督学习

无监督学习(unsupervised learning)是从无标注数据（有习题没答案）中学习预测模型，模型可以表示数据的类别、转换或概率，实现对数据的聚类、降维或概率估计。无监督学习本质上是学习数据中的统计规律或潜在结构。

学习模型可以表示为函数 $$z = g(x)$$，条件概率分布$$P(z|x)$$，或$$P(x|z)$$，其中$$x \in \mathcal{X}$$，$$z \in \mathcal{Z}$$，$$\mathcal{X}$$ 为输入空间，$$\mathcal{Z}$$ 是隐式结构空间。

无监督学习既可以分析已知数据、也可以预测未来数据。从训练集中学习得到最优模型$$z=\hat{g}(x)$$，或者是条件概率分布 $$\hat{P}(z | x)$$ 或 $$\hat{P}(x | z)$$。预测时给定输入$$x_{N+1}$$，由模型 $$z_{N+1}=\hat{g}\left(x_{N+1}\right)$$ 或 $$z_{N+1}=\arg \max _{z} \hat{P}\left(z | x_{N+1}\right)$$ 给出输出 $$z_{N+1}$$,进行降维或聚类，或由模型 $$\hat{P}(x | z)$$ 给出输入的概率 $$\hat{P}\left(x_{N+1} | z_{N+1}\right)$$，进行概率估计。

![]( https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-08-05_unsupervised_learning.png)

3. 强化学习

强化学习（reinforcement learning）是指智能系统在与环境连续互动中学习最佳行为策略的机器学习问题。假定互动过程遵循当前状态只与前一个状态和动作相关的原则，即是一个马尔科夫决策过程，那么强化学习本质上是要学习最佳行为序列

每一步 $$t$$,智能系统观测到一个环境状态（state) $$s_{t}$$ 与一个奖励（reward）$$r_{t}$$，采取一个动作（action）$$a_{t}$$。环境会因系统的动作产生下一步 $$t + 1$$ 的状态 $$s_{t+1}$$ 与奖励 $$r_{t+1}$$。

强化学习要掌握以下概念：

* S：有限状态（state）集合
* A：有限动作（action）集合
* P：状态转移概率函数（transition function），$$P\left(s^{\prime} | s, a\right)=P\left(s_{t+1}=s^{\prime} |\right. s_{t}=s, a_{t}=a )$$
* $$r$$：奖励函数（reward function），$$r\left(s, a \right)=E\left(r_{t+1} | s_{t}=s, a_{t}=a\right)$$
* $$\gamma$$：衰减系数（discount function），代表奖励会衰减。$$\gamma \in[0,1]$$
* 策略 $$\pi$$：给定状态下的动作函数 $$a = f(x)$$ 或是条件概率分布 $$P(a|s)$$
* 价值函数（value function）：策略 $$\pi$$ 从某个状态 $$s$$ 开始长期积累的数学期望，$$v_{\pi}(s)=E_{\pi}\left[r_{t+1}+\gamma r_{t+2}+\gamma^{2} r_{t+3}+\cdots | s_{t}=s\right]$$
* 动作价值函数（action value function）：策略 $$\pi$$ 从某个状态 $$s$$ 和动作 $$a$$ 开始长期积累的数学期望，$$q_{\pi}(s, a)=E_{\pi}\left[r_{t+1}+\gamma r_{t+2}+\gamma^{2} r_{t+3}+\cdots | s_{t}=s, a_{t}=a\right]$$

![]( https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-08-05_reinforcement_learning.png)

强化学习的目标就是在所有可能策略中选取使价值函数最大的策略，实际操作上通常会从具体策略出发，不断优化已有策略。

强化学习方法有基于策略的（policy-based），基于价值的（value-based），这两个属于无模型（model-free）方法，还有有模型（model-based）方法。有模型方法试图直接学习概率转移函数和奖励函数，通过环境反馈确定最佳策略。

无模型、基于策略的方法试图求解最优策略，从一个策略开始，然后不断搜索更优策略

无模型、基于价值的方法试图求解最优价值函数，特别是最优动作价值函数，从一个价值函数开始，不断搜索更优的价值函数。

4. 半监督学习与主动学习

半监督学习（semi-supervised learning)是在有少量标注数据，大量未标注数据的条件下学习。旨在利用未标注信息辅助标注数据，进行监督学习

主动学习（active learning)是机器主动给出实例要求人们给予标注，然后利用标注数据学习，相比于直接给定标注训练集，显得“主动”些

## 1.2.2 按模型分类

* 概率模型与非概率模型

统计学习模型可以分为概率模型（probabilistic model）和非概率模型（non-probabilistic model），前者取条件概率分布 $$P(y|x)$$ 或 $$P(x|y)$$ ，后者取函数 $$y = f(x)$$，$$x$$ 是输入，$$y$$ 是输出。

条件概率分布和函数形式可以转换，当条件概率分布最大化后得到函数，函数归一化后得到条件概率分布。所以二者区别不在于映射关系差异，而是内在结构不同。概率模型一定能表示为联合概率分布，非概率模型则不一定。

* 线性模型和非线性模型

非概率模型里可以进一步分为线性模型（linear model）和非线性模型（non-linear model），判别标准是函数 $$y = f(x) $$ 是否为线性函数

* 参数化模型和非参数化模型

参数化模型（parametric model）假设模型参数维度固定，模型由有限维参数完全刻画

非参数化模型（non-parametric model）假设模型参数维度不固定或是无穷大，随着训练样本增多而增多

## 1.2.3 按算法分类

在线学习（online learning）指每次接受一个样本，进行预测，然后学习，不断重复

批量学习（batch learning）指一次接受所有数据，学习模型，然后预测

受应用场景限制可能需要选择在线学习，比如时序相关且要及时处理的、数据量过大无法一次处理的或者数据模式会随时间改变而必须重新学习的

在线学习可以是监督学习，也可以是非监督学习。因为每次更新模型能用到的数据有限，预测准确率不会很高。

## 1.2.4 按技巧分类

* 贝叶斯学习

贝叶斯学习（Bayesian learning）又称贝叶斯推理（Bayesian inference），是指利用贝叶斯定理，在给定数据条件下计算模型的条件概率，即后验概率，并以此进行模型估计和预测。

模型估计时，估计整个后验概率分布 $$P(\theta|D)$$ ，如果要给出模型，则取概率最大的

预测时，计算数据对后验概率分布的期望值 $$P(x | D)=\int P(x | \theta, D) P(\theta | D) \mathrm{d} \theta$$，$$x$$ 是新样本。

贝叶斯估计和极大似然估计代表着统计学中的贝叶斯派和频率学派的两种不同观点。可以简单的将两者联系起来，假设先验分布是均匀分布，取后验概率最大，即可从贝叶斯估计得到最大似然估计。

![]( https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-08-06_bayesion_MLE.png)

_勘误：上述贝叶斯估计式当为 $$\hat{P}(\theta | D)=\frac{P(\theta) P(D | \theta)}{P(D)}$$_

* 核方法

核方法（kernel method）是使用核函数表示和学习非线性模型的一种机器学习方法，可用于监督学习或无监督学习。

一些线性模型的学习方法依赖于相似度计算，准确的讲是向量内积计算。有时在输入空间线性不可分，通过核方法，显式的定义从输入空间（低维）到特征空间（高维）的映射，实现线性可分，也就实现了线性模型到非线性模型的扩展。

核方法的技巧在于不显式的定义该映射，而是直接定义核函数，即映射后在特征空间的内积。比如对于输入空间的两个实例 $$x_{1}$$ 和 $$x_{2}$$ ，内积是 $$\left\langle x_{1}, x_{2}\right\rangle$$ ，如果映射为 $$\varphi$$，那么 $$x_{1}$$ 和 $$x_{2}$$ 的映射对象为 $$\varphi\left(x_{1}\right)$$ 和 $$\varphi\left(x_{2}\right)$$，内积为 $$\left\langle\varphi\left(x_{1}\right), \varphi\left(x_{2}\right)\right\rangle$$ 。核方法直接在输入空间定义核函数 $$K\left(x_{1}, x_{2}\right)$$ ，使得 $$K\left(x_{1}, x_{2}\right)=\left\langle\varphi\left(x_{1}\right), \varphi\left(x_{2}\right)\right\rangle$$。

# 1.3 统计学习三要素

## 1.3.1 模型

监督学习下，模型就是要学习的条件概率分布或决策函数。所有可能的概率分布或决策函数构成了假设空间，用 $$\mathcal{F}$$ 表示。给定输入 $$X$$ 和 $$Y$$ 后，此时 $$\mathcal{F}$$ 是由参数向量决定的函数族或概率分布族。

​                                                     $$\mathcal{F}=\left\{f | Y=f_{\theta}(X), \theta \in \mathbf{R}^{n}\right\}$$ 

​                                                     $$\mathcal{F}=\left\{P\left|P_{\theta}(Y | X), \theta \in \mathbf{R}^{n}\right\}\right.$$

## 1.3.2 策略

有了模型就要考虑按什么样的标准学习或选择模型了。

* 损失函数（loss function）：度量模型一次预测的好坏，描述预测值 $$f(X)$$ 与真实值 $$Y$$ 间的偏差程度，是非负实值函数，记作 $$L(Y, f(X))$$

常用的损失函数：

1. 0-1 损失函数。   $$L(Y, f(X))=\left\{\begin{array}{ll}{1,} & {Y \neq f(X)} \\ {0,} & {Y=f(X)}\end{array}\right.$$
2. 平方损失函数。  $$L(Y, f(X))=(Y-f(X))^{2}$$

3. 绝对损失函数。 $$L(Y, f(X))=|Y-f(X)|$$
4. 对数损失函数。 $$L(Y, P(Y | X))=-\log P(Y | X)$$

我们期望损失越小越好，于是对遵循联合概率分布 $$P(X,Y)$$ 的样本 $$(X,Y)$$ ，损失函数期望为：

​                                                               $$\begin{aligned} R_{\mathrm{ exp }}(f) &=E_{P}[L(Y, f(X))] \\ &=\int_{\mathcal{X} \times \mathcal{Y}} L(y, f(x)) P(x, y) \mathrm{d} x \mathrm{d} y \end{aligned}$$

这是理论期望，但因为我们并不知道联合概率分布 $$P(X,Y)$$ ，这也是我们要学习的原因，于是我们想用在训练集上训练得到的平均损失，也叫经验风险（empirical risk）或经验损失（empirical loss），在数据量足够大的情况下逼近理论期望。

​                                                            $$R_{\mathrm{emp}}(f)=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)$$

可通常数据样本有限，二者偏差有些大，于是就要对经验风险进行矫正。于是有了两个策略：经验风险最小化和结构风险最小化。

* 经验风险最小化（empirical risk minimization，ERM）：给定假设空间、损失函数和训练集的条件下，经验风险函数式是确定的，经验风险最小就是模型最优，于是就转换成了求解最优化问题：

​                                                            $$\min _{f \in \mathcal{F}} \frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)$$

样本大时ERM效果很好，但样本容量很小时会发生过拟合现象（over-fitting）。

* 结构风险最小化（structural risk minimization，SRM）：防止过拟合而提出的风险策略，等价于正则化（regularization）。表现为在经验风险上添加正则化项（regularizer）或罚项（penalty term）

​                                                            $$R_{\mathrm{srm}}(f)=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)+\lambda J(f)$$

$$J(f)$$ 代表模型复杂度，模型 $$f$$ 越复杂，$$J(f)$$ 越大，反之亦然，也就是说复杂度代表了模型的惩罚。$$\lambda \geqslant 0$$ 是系数，用来权衡经验风险和模型复杂度。结构风险要小，经验风险和模型复杂度都要小，于是结构风险最小化的策略就是选择结构风险最小的模型，即转为最优化问题：

​                                                             $$\min _{f \in \mathcal{F}} \frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)+\lambda J(f)$$

## 1.3.3 算法

算法就是求解最优模型时的具体计算方法。因为转换成了最优化问题，那么算法就是要找到全局最优解，但通常很难或不存在，只能找到局部最优解。人们可以选择已有最优化算法或独自开发。

# 1.4 模型评估与模型选择

## 1.4.1 训练误差与测试误差

评估学习效果好坏时，在给定损失函数的条件下，基于损失函数的模型的训练误差（training error）和模型的测试误差（test error）自然就是两个评估标准。统计学习方法采用的损失函数未必是评估时的损失函数，如果两者一致是比较理想的。

训练误差是训练集上的平均损失：$$R_{\mathrm{emp}}(\hat{f})=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, \hat{f}\left(x_{i}\right)\right)$$

测试误差是测试集上的平均损失：$$e_{\mathrm{test}}=\frac{1}{N^{\prime}} \sum_{i=1}^{N^{\prime}} L\left(y_{i}, \hat{f}\left(x_{i}\right)\right)$$

训练误差能体现问题是否容易学习，而测试误差更重要，体现了对未知数据的预测能力。

## 1.4.2 过拟合和模型选择

当假设空间拥有复杂度各异（比如，参数数量不同）的若干模型时，就要面临模型选择（model selection）的问题。如果数据真如我们所预料的确实符合一种模型，那么我们要做的就是尽量保证我们得到的模型和真实模型的参数相同，参数向量相近。

而数据通常都是带有“噪音”的，如果一味追求对训练数据的预测能力，以至于将“噪音”也当做特征学习了去，表现为预测模型比真实模型参数更多，即复杂度更高，这就是过拟合现象（over-fitting）。过拟合典型表现就是训练集上预测效果良好，但未知数据预测的很差。模型选择就是要尽力避开过拟合并提高预测能力。

训练误差和测试误差也会随着模型复杂度变化而变化。模型复杂度增大时，训练误差会减小并趋向于0，测试误差会先减小达到最小值后又增大。

![]( https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-08-08_error_complexity.png)

_偏差（bias）：真实值与预测值期望间的差值，方差（variance）：预测值以期望为中心的变化范围_

![]( https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-08-08_bias_variance.png)

下面介绍两种常用的模型选择方法：正则化与交叉验证

# 1.5 正则化与交叉验证

## 1.5.1 正则化

正则化是结构风险最小化策略的展现，是在经验风险后加上一个正则化项(regularizer)，或是罚项(penalty item)。

正则化项一般为关于模型复杂度的单调递增函数。

正则化的一般形式：$$\min _{f \in \mathcal{F}} \frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)+\lambda J(f)$$，$$\lambda \geqslant 0$$用于调整经验风险和结构风险的比例

常见的正则化有两种，以平方损失为例：

* 参数向量的 $$L_{1}$$ 范数：
  $$
  L(w)=\frac{1}{N} \sum_{i=1}^{N}\left(f\left(x_{i} ; w\right)-y_{i}\right)^{2}+\lambda\|w\|_{1}
  $$

* 参数向量的 $$L_{2}$$ 范数:

$$
L(w)=\frac{1}{N} \sum_{i=1}^{N}\left(f\left(x_{i} ; w\right)-y_{i}\right)^{2}+\frac{\lambda}{2}\|w\|^{2}
$$

在所有可能模型中，能很好地解释已知数据并且十分简单才是好模型，也是应该选择的模型。

## 1.5.2 交叉验证

样本数据通常可以分为训练集(training set)，验证集(validation set)和测试集(test set)。

训练集训练模型，验证集选择模型，测试集评估模型

能足量的分成三份的情况比较少见，于是有了交叉验证法：重复地使用数据；将数据切分，组合成训练集和测试集，在此基础上反复训练、测试和选择模型

* 简单交叉验证：随机的切分数据为训练集和测试集
* K 折交叉验证：随机的切分数据为 K 份不相交、大小相同的数据集，留一份做测试，其余的训练，不断重复
* 留一交叉验证：K 折交叉验证当 K 和数据容量 N 相等时的特殊情况

# 1.6 泛化能力

## 1.6.1 泛化误差

泛化能力（generalization ability）是模型对未知数据的预测能力。泛化误差反映了泛化能力，泛化误差就是模型的期望风险，如果学到的模型为 $$\hat{f}$$ ，泛化误差为：
$$
\begin{aligned} R_{\exp }(\hat{f}) &=E_{P}[L(Y, \hat{f}(X))] \\ &=\int_{\mathcal{X} \times \mathcal{Y}} L(y, \hat{f}(x)) P(x, y) \mathrm{d} x \mathrm{d} y \end{aligned}
$$

## 1.6.2 泛化误差上界

泛化误差既然是期望风险，那么当然希望越小越好，同时风险波动范围也越小越小，于是我们可以用波动范围来评定模型泛化能力。那么就有了波动范围的界定问题，具体的，学习方法通常采用泛化误差的概率上界进行界定，简称泛化误差上界（generalization error bound）。

泛化误差上界和样本容量与假设空间容量相关，是二者的函数。随着样本容量增大而趋于0，随着假设空间容量的增大而增加。

假设空间只包含有限函数的情形比较好分析泛化误差上界（一般假设空间的不做介绍）。以二分类问题为例做推导：

**定理：对二分类问题，假设空间是有限个函数 $$\mathcal{F}=\left\{f_{1}, f_{2}, \cdots, f_{d}\right\}$$ 时，对任意一个函数 $$f \in \mathcal{F}$$，至少以概率 $$ 1 - \delta$$，$$0<\delta<1$$，有以下不等式成立：**
$$
R(f) \leqslant \hat{R}(f)+\varepsilon(d, N, \delta)
$$
**其中，**
$$
\varepsilon(d, N, \delta)=\sqrt{\frac{1}{2 N}\left(\log d+\log \frac{1}{\delta}\right)}
$$
$$R(f)$$ 表示期望风险，是理论最优值，$$\hat{R}(f)$$ 表示经验风险，是我们的估计值，$$d$$ 是假设空间函数个数，$$N$$ 为样本容量。

可以看到第二项 $$\varepsilon(d, N, \delta)$$ 是 $$N$$ 的单调递减函数，同时也是$$\sqrt {\log d}$$ 阶的函数

**证明：**这里要用到霍夫丁（Hoeffding）不等式，其作用在于给出随机变量和其期望值间偏差的概率上限。

表示为，对于独立随机变量 $$X_{1} \cdots X_{n}$$，有 $$X_{i} \in\left[a_{i}, b_{i}\right], i=1,2, \cdots, N $$，经验均值 $$\overline{X}=\frac{1}{N} \sum_{i=1}^{N} X_{i}$$，对 $$t > 0$$ 有以下不等式
$$
{P[\overline{X} - E(\overline{X})\geqslant t] \leqslant \exp \left(-\frac{2 N^{2} t^{2}}{\sum_{i=1}^{N}\left(b_{i}-a_{i}\right)^{2}}\right)}
$$

$$
{P[E(\overline{X})- \overline{X}\geqslant t] \leqslant \exp \left(-\frac{2 N^{2} t^{2}}{\sum_{i=1}^{N}\left(b_{i}-a_{i}\right)^{2}}\right)}
$$
$$exp()$$ 表示指数函数，二分类中 $$\overline{X}$$ 为样本均值 $$\hat{R}(f)$$，期望为 $$R(f)$$。如果损失函数取值区间为 [0, 1]，则有
$$
P(R(f)-\hat{R}(f) \geqslant \varepsilon) \leqslant \exp \left(-2 N \varepsilon^{2}\right)
$$
进而
$$
\begin{aligned} P(\exists f \in \mathcal{F} : R(f)-\hat{R}(f) \geqslant \varepsilon) &=P\left(\bigcup_{f \in \mathcal{F}}\{R(f)-\hat{R}(f) \geqslant \varepsilon\}\right) \\ & \leqslant \sum_{f \in \mathcal{F}} P(R(f)-\hat{R}(f) \geqslant \varepsilon) \\ & \leqslant d \exp \left(-2 N \varepsilon^{2}\right) \end{aligned}
$$
也即对任意 $$f \in \mathcal{F}$$ 有
$$
P(R(f)-\hat{R}(f)<\varepsilon) \geqslant 1-d \exp \left(-2 N \varepsilon^{2}\right)
$$
令 $$\delta = d \exp \left(-2 N \varepsilon^{2}\right)$$，则 $$P(R(f)<\hat{R}(f)+\varepsilon) \geqslant 1-\delta$$，并解得 $$\varepsilon = \sqrt{\frac{1}{2 N}\left(\log d+\log \frac{1}{\delta}\right)}$$

所以至少有概率 $$ 1 - \delta$$ 使得 $$R(f)<\hat{R}(f)+\varepsilon$$，由泛化误差上界可知 $$R(f) \leqslant \hat{R}(f)+\varepsilon(d, N, \delta)$$

# 1.7 生成模型与判别模型

监督学习中所学模型一般就是学决策函数 $$Y=f(X)$$，或者概率分布 $$P(Y|X)$$。监督学习又可以分为生成方法（generative approach）和判别方法（discriminative approach）。对应于生成模型和判别模型

生成方法是先学出潜藏的联合概率分布 $$P(X,Y)$$，然后用条件概率 $$P(Y|X)$$预测，即给出了由 $$X$$ 如何生产 $$Y$$ 的方法。生成方法收敛于真实模型速度快，有隐变量也能用

判别方法是直接从数据学条件概率 $$P(Y|X)$$ 或决策函数 $$f(X)$$，给出一 个$$X$$，预测一个 $$Y$$。判别法直接面向预测，准确率更高

# 1.8 监督学习的应用

## 1.8.1 分类问题

当输出变量 $$Y$$ 的取值为有限个离散值时，预测问题成为分类问题，离散值为多个是多分类问题，这里主要讨论二分类问题。

**分类器（classifier）**：要学习的分类模型或决策函数

**分类（classification）**：对新样本的预测

**类别（class）**：可能的输出

评价分类器性能的指标：

* 准确率（accuracy）：正确分类的样本与总样本数的比值
* 查准率（precision）：判定为真且结果确实为真的比例
* 查全率/召回率（recall）：所有真实为真的样本找出了多少

以关注的类为正类，其他为负类，对各类预测的情况进行统计，有四种结果：

**TP**：将正类预测为正类的个数

**FN**：将正类预测为负类的个数

**FP**：将负类预测为正类的个数

**TN**：将负类预测为负类的个数

查准率定义为：$$P = \frac{T P}{TP + F P}$$

召回率定义为：$$R = \frac{T P}{TP + FN}$$

还有结合了二者，调和平均后的 $$F_{1}$$ 值：$$\frac{2}{F_{1}}=\frac{1}{P}+\frac{1}{R}$$，$$F_{1} = \frac{2T P}{2TP + FP + FN}$$

## 1.8.2 标注问题

标注（tagging）也是常见监督学习问题。表现为输入一个观测序列，输出一个标记序列或状态序列。可能的标记个数是有限的，但是其组合成的标记序列的个数是随序列长度增长而指数增加的。

学习问题构建的模型通常表示为条件概率分布：
$$
P\left(Y^{(1)}, Y^{(2)}, \cdots, Y^{(n)} | X^{(1)}, X^{(2)}, \cdots, X^{(n)}\right)
$$
每个 $$X^{i}$$ 取该维度上所有可能的观测，每个 $$Y^{i}$$ 取所有可能的标记。

标注问题的评价指标和分类问题一致，常用的有准确率，查准率和召回率，定义与分类模型相同。

## 1.8.3 回归问题

回归（regression）是监督学习的另一类重要问题。回归就是求解输入变量到输出变量的映射关系，等价于函数拟合。找到一条曲线既能拟合已知数据也能预测未知数据。

回归问题按照变量输入个数可分为一元回归和多元回归，按照模型类型可分为线性回归和非线性回归。

回归学习最常用的损失函数是平方损失函数，此时可以使用最小二乘法求解。

# 习题

**1.1 说明伯努利模型的极大似然估计以及贝叶斯估计中的统计学习方法三要素。伯努利模型是定义在取值为0与1的随机变量上的概率分布。假设观测到伯努利模型n次独立的数据生成结果，其中k次的结果为1，这时可以用极大似然估计或贝叶斯估计来估计结果为1的概率**

解：

模型：随机变量取值为0与1的概率分布

策略：伯努利模型的极大似然估计和贝叶斯估计都是对数损失函数

方法：极大似然估计是求解经验损失最小时的参数值，贝叶斯估计是求解后验概率分布，并得到参数期望值

**极大似然估计：**

假设随机变量为 $$X$$,取值为1或0，我们令 $$P(X=1) = \theta$$，有 $$P(X = 0) = 1 - \theta$$

因为都是独立事件，所以极大似然估计可表示为
$$
f(\theta)=\prod_{i=1}^{n} P\left(X_{i}\right)=\theta^{k}(1-\theta)^{n-k}
$$
取对数损失，得到损失函数 $$L(\theta)$$
$$
\begin{aligned}L(\theta)= -\log f(\theta) &=-\log \prod_{i=1}^{n} P\left(A_{i}\right)=-\log \theta^{k}-\log (1-\theta)^{n-k} \\ &=-k \log \theta-(n-k) \log (1-\theta) \end{aligned}
$$
要最小化损失函数，先对 $$\theta$$ 求导，
$$
\frac{\partial L(\theta)}{\partial \theta}=-k \cdot \frac{1}{\theta}-(n-k) \cdot \frac{-1}{1-\theta}
$$
当 $$\frac{\partial L(\theta)}{\partial \theta} = 0$$，解得 $$\theta = \frac{k}{n}$$，满足 $$\theta=\underset{\theta}{\arg \min} L(\theta)$$

**贝叶斯估计：**
$$
P\left(\theta | X_{1}, X_{2}, \ldots, X_{n}\right)=\frac{P\left(X_{1}, X_{2}, \ldots, X_{n} | \theta\right) \cdot P(\theta)}{P\left(X_{1}, X_{2}, \ldots, X_{n}\right)}
$$
分母部分与 $$\theta$$ 无关，我们期望概率最大，就是找到 $$\theta=\underset{\theta}{\arg \max } P\left(X_{1}, X_{2}, \ldots, X_{n} | \theta\right) \cdot P(\theta)$$

假设 $$\theta$$ 服从 Beta 分布，参数为 $$\alpha$$ 和 $$\theta$$
$$
\begin{aligned} f(\theta ; \alpha, \beta) &=\frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{\int_{0}^{1} u^{\alpha-1}(1-u)^{\beta-1} d u} \\ &=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha) \Gamma(\beta)} \theta^{\alpha-1}(1-\theta)^{\beta-1} \end{aligned}
$$
其中 $$\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha) \Gamma(\beta)}$$ 是常数，所以带入参数估计式可得
$$
\begin{aligned} \theta &=\underset{\theta}{\arg \max } P\left(X_{1}, X_{2}, \ldots, X_{n} | \theta\right) \cdot P(\theta) \\ &=\underset{\theta}{\arg \max } \prod P\left(X_{i} | \theta\right) P(\theta) \\ &=\underset{\theta}{\arg \max } \theta^{k}(1-\theta)^{n-k} \theta^{\alpha-1}(1-\theta)^{\beta-1} \end{aligned}
$$
进而，
$$
f(\theta) = \theta^{k}(1-\theta)^{n-k} \theta^{\alpha-1}(1-\theta)^{\beta-1}\\
L(\theta) = \log f(\theta)
$$
求解 $$\theta=\underset{\theta}{\arg \max} L(\theta)$$ 方法同上，得到 $$\theta=\frac{k+(\alpha-1)}{n+(\alpha-1)+(\beta-1)}$$

**1.2 通过经验风险最小化推导极大似然估计，证明模型是条件概率分布，当损失函数是对数损失函数时，经验风险最小化等价于极大似然估计**

解：

由题意可知，当条件概率分布为 $$P(Y|X)$$，损失函数为 $$L(Y,P(Y|X))=-\log P(Y|X)$$，最小化经验风险，即：
$$
\min  \frac{1}{N} \sum_{i=1}^{N} -\log P(Y_{i}|X_{i},\theta)
$$
$$\theta \in R^{n}$$，是模型参数。假设样本满足独立同分布，则概率分布可表示为：
$$
\begin{aligned}P(Y_{1},Y_{2},\ldots,Y_{n}|X_{1},X_{2},\ldots,X_{n};\theta)&=\frac{P(X_{1},Y_{1},X_{2},Y_{2},\ldots,X_{n},Y_{n}|\theta)}{P(X_{1},X_{2},\ldots,X_{n}|\theta)}\\
&=\frac{\prod_{i=1}^{N} P(X_{i},Y_{i},|\theta)}{\prod_{i = 1}^{N}P(X_{i}|\theta)}\\
&=\prod_{i=1}^{N}P(Y_{i}|X_{i},\theta)
\end{aligned}
$$
于是最小化经验风险可表示为
$$
\begin{aligned} \theta &=\underset{\theta}{\arg \min }\frac{1}{N} \sum_{i=1}^{N} -\log P(Y_{i}|X_{i},\theta) \\
&=\underset{\theta}{\arg \max } \sum_{i=1}^{N} \log  P(Y_{i}|X_{i},\theta)\\ 
&=\underset{\theta}{\arg \max } \prod_{i=1}^{N}P(Y_{i}|X_{i},\theta)\end{aligned}
$$
可见当模型是条件概率分布，当损失函数是对数损失函数时，经验风险最小化等价于极大似然估计







