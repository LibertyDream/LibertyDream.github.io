---
layout:		post
title:  	图解GPT-2
subtitle:   文本生成利器
date:       2019-11-23
author:     一轩明月
header-img: img/post-bg-snow.jpg
catalog: 	 true
tags:
    - Transformer
    - NLP
---

> 文章编译自：
>
>  http://jalammar.github.io/illustrated-gpt2 

今年出了个了不起的应用。[The OpenAI GPT-2](https://openai.com/blog/better-language-models/) 给人以惊喜，证实了机器也能写出连贯有激情的文章。但 GPT-2 本身不是什么新颖架构，更像是只有解码器的 Transformer。只不过是在非常非常大的数据集上训练出的非常非常大的基于 transformer 的语言模型。本文会介绍是怎样的架构使得模型取得了这样好的效果，会深入自关注层内窥探其中奥妙，最后跳出语言模型谈谈只有解码器的 transformer 都有哪些应用。

本文算作是之前[图解 Transformer](https://libertydream.github.io/2019/11/02/图解-Transformer/)一文的补充，更细致地可视化讲解了 transformer 内部工作原理，以及是怎么从原始模型演化至今天这种样子的。

# GPT2 和语言模型

什么是语言模型呢？在[图解 Word2Vec](https://libertydream.github.io/2019/11/09/图解-word2vec/)一文中，将语言模型解释为一种机器学习模型，给定部分语句能预测出下一个词是什么。最知名的语言模型就是智能手机上输入法的输入提示了。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-09_swiftkey-keyboard.png)

从这个意义上讲，当然可以说 GPT-2 就是输入法 app 带的一个挂件，只不过比你手机里带的那个要大得多，也复杂的多。OpenAI 的研究员们从网上爬取了 40 GB 的预料数据，构建出 WebText 数据集，在此基础上训练出了 GPT-2 模型。单说下存储空间的对比，我手机上输入法占 78 MB。最小版本的 GPT-2 存储其参数就要花费 500 MB，最大版本的 GPT-2 更是要花 13 倍于它的存储空间，超过 6.5 GB。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-sizes.png)

急速上手体验 GPT-2 可以借助 [AllenAI GPT-2 Explorer](https://gpt2.apps.allenai.org/?text=Joel%20is)。该应用借助 GPT-2 基于概率得分给出十个可能的候选词。可以选一个词然后看看候选词列表的变化。

## 语言模型中的 Transformer 家族

正如[图解 Transformer](https://libertydream.github.io/2019/11/02/图解-Transformer/)中所展示的，原先的转换模型（transformer model）由编码器组和解码器组两部分构成，各组中的编/解码器又叫做转换块（transformer block）。就机器翻译任务而言该架构是合理的，人们早已证明编码-解码架构对该问题的有效性。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_transformer-encoder-decoder.png)

后续研究中许多都放弃了编码器或解码器，只使用一组转换块，但是尽可能堆的很高，喂以巨量的训练数据，加上庞大的算力（训练其中一些模型需要巨额投入，比如 AlphaStar 需要数百万美金）。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt-2-transformer-xl-bert-3.png)

转换块能叠多高是导致不同 GPT-2 模型大小差异的要素之一。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-sizes-hyperparameters-3.png)

## 与 BERT 的不同

> 机器人第一法则
>
> 机器人不允许伤害人类，也不能看到人类遭遇危险而无动于衷
>
>  *A robot may not injure a human being or, through inaction, allow a human being to come to harm.* 

GPT-2 是使用 transformer 的解码块构建的，而 BERT 用的是编码块，本文稍后会加以对比。但一个关键不同在于 GPT-2 是和传统语言模型一样，每次只输出一个标识。比如一个训练好的 GPT-2 模型“背诵”机器人第一法则：

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt-2-output.gif)

这些模型实际运作方式是将已经输出的标识作为下一轮输入的一部分，这也叫“自回归”（auto-regression）

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt-2-autoregression-2.gif)

GPT-2 和后来的模型比如 TransformerXL 与 XLNet 都是天然自回归的。权衡考量后，BERT 并没这样做。放弃自回归使 BERT 可以结合单词上下文（左右两侧的单词）获取更好的效果。XLNet 找到了某种整合上下文的新方式，所以自回归和上下文关联的特点它都有。

## 转换块演化史

[原始 transformer](https://arxiv.org/abs/1706.03762)给出了两类转换块，一种是编码块（encoder block），另一种是解码块（decoder block）

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_transformer-encoder-block-2.png)

原始论文给出的编码块接收输入序列有上限（比如 512 个标识），如果短于上限可以使用占位符填充

解码器中多插了一层，保证其在解码时能参考编码器中的特定片段。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_transformer-decoder-block-2.png)

这里又是一处关键差异，自关注层（self-attention layer）中遮盖后续标识（future token）并不是像 BERT 显式的用 `[mask]` 将其替换掉，而是阻碍其从右边标识里提取信息。比如我们执行到了第四步，可以看到只有当前和之前出现了的标识能参与计算：

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_transformer-decoder-block-self-attention-2.png)

所以自关注（BERT 使用）和遮盖自关注（GPT-2 使用）间的差异就清楚了。一般自关注块会允许看一眼后面的标识做参考。遮盖自关注从一开始就杜绝了这条路。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_self-attention-and-masked-self-attention.png)

在原始论文提出后，一项[研究](https://arxiv.org/pdf/1801.10198.pdf)提出了另一种能作语言模型的转换块组织方法。该模型扔掉了 Transformer 的编码器，所以可以叫 “Transformer 解码版”。这一早期基于 transformer 的语言模型就是六个解码块捆在了一起。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_transformer-decoder-intro.png)

解码块都是一样的，从图中第一个解码块的内部构造可以看出是遮盖型自关注。另一个值得注意的是模型能处理的序列长度达到了 4000，是一个巨大的进步（开始是 512）。

这些块和初始解码块很像，但没了编码器，也就一并将原来第二层的自关注删掉了。

OpenAI GPT-2 模型用的就是这种解码保留（decoder-only）型组块。

## GPT-2 解构

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt-2-layers-2.png)

GPT-2 可以处理 1024 个标识，每个标识独立经过各级解码器处理。

跑 GPT-2 模型最简单的方式就是让它自己玩，随机生成（技术上讲叫_生成无限制样本（genertating unconditional samples）_），也可以给点提示让它只谈某个话题的内容（亦称_生成交互限制样本（generating interactive conditional samples）_）。如果是随机生成，只需要输入启动标识模型就会开始生成文字了。（`<|endoftext|>`是模型采用的标识，这里用`<s>`代替）

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-simple-output-2.gif)

因为只有一个输入，也就只有一条通路被激活。经各层处理后，由标识得到了一个向量，拿着向量对照模型词表进行打分（GPT-2 有 50,000 大小的词库），比方说我们选择取得最高概率的标识，‘the'。但也有可能出岔子，要知道如果你不断的点击输入法给出的智能提示词，有时会陷入循环怪圈，要跳出来就得点击第二或第三个提示词。此处同理，GPT-2 有一个专门的参数 top-k 用于指定每次给出多少个最优候选词（这里是 top-k = 1）

之后，将第一步的输出添加到输入序列中，进行下一步的预测。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt-2-simple-output-3.gif)

注意此时同样只有第二条通路被激活，各层都保留了对第一个标识的“理解”并将其用于第二个字符的处理上。GPT-2 不会因为第二个字符重新解释第一个。

这么讲还是不够细致，不妨从输入看起。如同之前提到过的其他 NLP 模型，GPT-2 会在自己的嵌入矩阵中查找输入字符的嵌入表示，嵌入矩阵是模型训练结果的一部分。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-token-embeddings-wte-2.png)

图中每一行代表一个词的嵌入——能表征词语内涵的数字列表。GPT-2 模型大小不同列表长度也不同。最小版的每个标识由 768 位长的嵌入表示。

因此我们会先在嵌入矩阵里寻找开始标识`<s>`的嵌入。在将其送入第一个解码器前，需要加上位置编码——指明转换块所接收序列中单词间的顺序关系。模型的一部分就是位置矩阵，包含了 1024 个位置各自的编码向量。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-positional-encoding.png)

至此，单词交给第一个转换块前的流程就说完了。也知道了 GPT-2 模型带有的两个权重矩阵

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-input-embedding-positional-encoding-3.png)

第一个解码块开始接手，先经自关注处理，然后送入神经网络。转换块处理完成后将解析标识得到的向量发给上层解码器。这一过程在每一块中都是一样的，但每一块的自关注和神经网络参数各不相同。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-transformer-block-vectors-2.png)

## 自关注回顾

语言高度依赖语境，比如拿第二法则来说

> 机器人第二法则
>
> 在不违反第一法则的情况下，机器人必须服从人类命令
>
>  *A robot must obey the orders given* **it** *by human beings except where* **such orders**  would conflict with the **First Law**. 

看一下句中加粗的三个地方。如果不结合语境完全不知道三者指代的是什么。模型要处理这个句子，它得明白：

- **it** 指代 robot

- **such orders** 指代法则中前面说的 “the orders given it by human beings"

- **First Law** 指代机器人第一法则 

这也正是自关注所做的事情。它会在处理具体单词前（传入神经网络），将有助于解释单词的词语与上下文信息加进来。具体做法是按相关性给句段里的单词赋予权值，然后将这些单词向量加权求和。

举例来说，自关注层处理 ”it“ 的时候会关注”a robot“。送入神经网络处理的向量就是这三者加权求和的结果。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-self-attention-example-2.png)

句段里的每个词都要经过自关注处理。其中关键是三个向量：

- Query：查询向量是当前单词的表征，用于和其他词（的键）作比对。计算时只关注当前词的查询向量
- Key：键向量好比句段单词的标签。比对时看得就是它
- Value: 值向量是实际词嵌入。当确认相关性后，参与加权计算的就是它

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_self-attention-example-folders-3.png)

举个不恰当的比方，这就像你在翻阅文件柜。查询向量就是你手里的票根。键向量就是文档柜里文件夹上的标签，当标签和票根匹配上了，会从文件夹里取出其中内容，即值向量。不同之处在于你找的不是某一个值，而是这些档案内容某种比例的混合。

查询向量与每个键向量相乘就得到了每个文件夹的权重值（技术上讲，是作点积接 softmax 处理）。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_self-attention-example-folders-scores-3.png)

每个值与权重相乘再求和，就得到了自关注的结果。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-value-vector-sum.png)

加权结果是它会将 50% 的注意力放到 `robot` 上，30% 在 `a` 上，19% 在 `it` 上。稍后还会进一步分析自关注计算过程，但是先跳出来继续我们在转换块间的旅程。

当顶层解码块处理完成，模型会将其输出的向量与嵌入矩阵相乘。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-output-projection-2.png)

回想一下，嵌入矩阵里的每一行都代表模型所带词表中一个词的嵌入表示。乘积结果就是词表中各单词的得分。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-output-scores-2.png)

当然我们可以直接选择最高分的单词（top-k = 1）。但最好还是考虑一下其他的词。所以更好的做法是将得分视为概率对词表进行采样（得分更高的词更有可能被选出来）。折中办法是将 top-k 设置为 40，让模型从 40 个得分最高的词里选。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-output.png)

这样，模型就完成了一次迭代得到了一个单词输出。模型会持续迭代直到得到整个序列（1024 个标识）的输出或者解析出序列截止标识。

## 小结

至此我们已经整体上知道了 GPT-2 的工作方式，如果你想进一步了解自关注层的情况请继续阅读。这里要先做几点声明：

- 上文中交替使用了”单词“和”标识“。实际上 GPT-2 使用字节对编码（Byte Pair Encoding）来对词表创建标识。这意味着标识通常只是单词的一部分。
- 示例中的 GPT-2 运行模式为阻断/评估模式，所以才会每次只处理一个词。训练时模型会面对更长的文本并同时处理多个标识。训练期间模型处理的批大小（512）也超过了评估模式的
- 图中向量出于图片布局考量我都随意做了变换、旋转，实现时一定会精细地多
- Transformer 家族都用了大量层正则化，这十分重要。在[图解 Transformer](https://libertydream.github.io/2019/11/02/图解-Transformer/)中有提到一些，但本文更多的关注于自关注上
- 有时需要用更多的方格表示向量，我称之为”放大“，比如说

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_zoom-in.png)

# 图解自关注（self-attention）

前面用下图展示了自关注处理单词`it`的结果

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-self-attention-1-2.png)

这一部分会详细讲解这一过程。注意，为了显式的展现每个单词经历了什么，我们会展示很多单个的向量。实际实现中这些操作都是通过矩阵相乘实现的。

先来看一下原始编码块中的自关注。以一个把玩性质的转换块为例，其只能每次处理四个标识。

自关注主要包括三步：

1. 为每条通路创建查询、键和值向量
2. 对于每个输入的标识，用其查询向量和其它所有键向量计算相关性
3. 对值向量加权求和

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_self-attention-summary.png)

## 创建查询、键、值向量

以第一条通路为例，将它的查询向量和所有键向量比对。每个键都会得到一个计算结果。自关注的第一步就是计算每个标识通路的三个向量（先忽略掉注意力端口的事）：

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_self-attention-1.png)

## 打分

查询向量和键向量只为这一步。因为看得是第一条通路，所以将第一条通路的查询向量和所有键向量作点积，这样 4 个标识都有了相关系数。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_self-attention-2.png)

## 求和

现在将相关系数和值向量相乘。相关性越高的值在加和后的向量中占比越大。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_self-attention-3-2.png)

相关性越低，图中向量颜色就越浅。以此展示低相关度是怎样稀释掉值向量的。

各条通路都这么走一遍，就可以得到夹带了上下文信息的标识向量，稍后送给块中下一级子层，前馈神经网络。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_self-attention-summary.png)

## 图解遮盖型自关注

既然讲到了 transformer 自关注这一步，就来看看遮盖型自关注吧。遮盖型和原始自关注直到第二层前都是一致的。假定模型有两个输入，我们来看第二个标识。这里，最后两个标识被盖住了，模型在打分这一步遇到了阻碍。基本上后续标识的相关系数都是 0 ，所以模型也就不能”偷看“了。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_masked-self-attention-2.png)

遮挡效果通常是借助名为”注意力面罩“的矩阵实现的。试想现在有一个 4 个词构成的序列（”robot must obey orders"）。对一个语言模型来讲，这个序列会被拆成 4 步处理——每次一词（假定每个词就是一个标识）。同时这些模型都是批处理的工作模式，不妨假设一批 4 个，这样整个序列都会在同一批内接受处理。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_transformer-decoder-attention-mask-dataset.png)

矩阵形式的话，就是将查询矩阵和键矩阵相乘。下图展现了这一过程，不过进行计算的会是词对应的向量而不是单元格里的字符。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_queries-keys-attention-mask.png)

相乘后，为其带上注意力面罩。这样想要遮挡的单元格的值就会是负无穷或是一个非常小的负数（GPT-2 是负十亿）。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_transformer-attention-mask.png)

接着执行 softmax 变换就得到了参与自关注运算的相关系数值。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_transformer-attention-masked-scores-softmax.png)

怎么理解这张表呢？

- 模型处理第一行的时候，因为只有一个词（robot），所有精力都给它
- 到了第二行，就有两个词了，对`must`进行处理，分配 48% 的注意力给 `robot`，52% 留在`must`
- 等等

## GPT-2 版遮盖自关注

我们可以让 GPT-2 完全遵循遮盖自关注的模式工作。只是评估的时候，因为我们的模型每轮只加一个新词，每次都要重新计算之前标识通路的自关注参数就显得不够高效。

这里我们来看处理第一个标识的场景（先略去`<s>`）

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-self-attention-qkv-1-2.png)

GPT-2 握有 `a` 标识的键值向量。每层自关注也都各自保有该标识的键值向量。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-self-attention-qkv-2-2.png)

这样在下一轮处理`robot`的时候就不用在生成一遍`a`的三个向量了。复用存好的就行

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-self-attention-qkv-3-2.png)

假设模型正在处理`it`。从底层区块看起，其接收输入就是 `it` 的嵌入加上 9 号位置的位置编码。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-self-attention-1.png)

transformer 里每个区块都有各自的权重（后面会讲），首先遇到的是用于创建查询、键和值向量的权重矩阵

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-self-attention-2.png)

权重矩阵和输入相乘（还得加上偏置向量，图里没画）。相乘所得向量内同时包含了`it`的三个向量

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-self-attention-3.png)

先前的例子中，我都是直接进入自关注而忽略了“多端”部分。现在该说说了。自关注是不同部分的 Q,K,V 向量的多次乘积。“划分”注意力端口就是简单的把长向量重塑（reshape）成一个矩阵。小版本 GPT-2 有 12 个注意力端口，这也是重塑矩阵的第一维参数

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-self-attention-split-attention-heads-1.png)

之前的示例已经展示了各端内部的情况了。而多端注意力会是下面这个样子（只可视化12 个中的 3 个）

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-self-attention-split-attention-heads-2.png)

来到打分阶段，注意这里我们只看其中一个端口（其他的操作也和这里一样）

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-self-attention-scoring.png)

当前标识和所有其他标识的键（早先迭代中端口1计算好了）计算相似度

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-self-attention-scoring-2.png)

接下来将各标识的值与其相关系数相乘，累加得到注意力端口1的输出。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-self-attention-multihead-sum-1.png)

对于各端口的处理，首先将他们拼接在一起

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-self-attention-merge-heads-1.png)

拼好的向量还不能直接传入神经网络。得先转换成齐次表示。

我们会让机器学习怎么投射最优，把连接好的自关注结果映射成前馈网络能处理的形式。这里就遇到了第二个权重矩阵，负责将端口计算结果映射成自关注层的输出向量。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-self-attention-project-1.png)

有了它，就能得到要送入下一层的向量

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-self-attention-project-2.png)

## 全连接网络

全连接神经网络是模型处理融合上下文信息后的输入的地方。两层结构，第一层是模型四倍大（小版 GPT-2 是 768，第一层就是 768 × 4 = 3072个单元）为什么是 4 倍，只是原始 transformer 就是这么做的而已。这似乎赋予 transformer 模型们足够的能力来解决甩给它们的问题。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-mlp1.gif)

第二层就是把第一层的结果反向映射回模型大小。这一步计算的结果就是当前转换块对当前标识的处理结果。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-mlp-2.gif)

至此我们就算极细致的介绍了转换块工作机理。回想一下，英勇的输入向量邂逅了这些权重矩阵

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-transformer-block-weights-2.png)

这些权重每个区块都有自己的一套。另一方面，模型只有一个标识嵌入矩阵和一个位置编码矩阵

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-weights-2.png)

下图是模型的所有参数

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_gpt2-117-parameters.png)

出于某些原因总参数是 124M 而非 117M。不知道为什么，但发布的代码里就是这么多。

# 语言模型之外

解码保留型 transformer 不断在语言模型外开枝散叶，在许多应用上取得了成功。

- 机器翻译

不需要编码器翻译，解码保留型 transformer 可以解决相同任务

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_decoder-only-transformer-translation.png)

- 摘要

第一个解码保留型 transformer 就是为该任务设计的。顾名思义，该任务就是让机器读 维基百科文章（不含摘要）并对其总结，真实的摘要作为训练集里的比对标签。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-23_wikipedia-summarization.png)

- 迁移学习

该[研究](https://arxiv.org/abs/1905.08836)最先提出了针对语言模型的预训练模型，解码保留结构。后微调用于摘要，结果在有限数据集上表现比编码-解码结构的 transformer 效果好。