---
layout:		post
title:  	笔记本上也能分析 100G 数据
subtitle:   Python 数据分析实践与工具推荐
date:       2019-12-14
author:     一轩明月
header-img: img/post-bg-unix-linux.jpg
catalog: 	 true
tags:
    - trick
    - Big Data
---

> 编译自：
>
> https://towardsdatascience.com/how-to-analyse-100s-of-gbs-of-data-on-your-laptop-with-python-f83363dda94

许多组织都在尽力收集、使用更多的数据改进业务，增加收入或者改造世界。所以面对 50 GB 或 500 GB 规模的数据对数据科学家来说成了家常便饭。

但这类数据集用起来并不那么舒畅。对每个人的笔记本硬盘来讲，这都是“小数据”，但对内存来说就有点大了。打开、浏览数据就很麻烦了，更别提探索与分析了。

这类问题的通常解决方式有三种：

一是对数据采样，取个子集进行分析。这么做缺点很明显，有可能因为恰巧没有采集到相关数据，破坏了多样性和完备性从而挖掘不出什么有价值的信息。更糟糕的是，没有全局视野可能造成误判、误读而蒙受损失。

二是使用分布式计算。这对一些任务确实很有效，但管理和维护一个集群的开销也不会是个小数目。试想一下，只是因为待处理数据超了内存上限多一点，好比30-50GB，就要大费周章搭个集群，开玩笑呢？

三是租台云服务器，内存配置能解决问题为准。比如 AWS 有提供 TB 级内存的实例。但这里你依旧要管理云数据桶，每次启动实例都得花时间导数据进去，还要面对云上数据合规问题，忍受远程操作主机的不便。成本依旧是问题，开始可能便宜，但时间越久开销越大。

这里我会向你展示一种新方案，能更快，更安全，更便利的处理几乎任意大小的数据集，只要你的笔记本，主机或服务器的硬盘能装下。

# Vaex

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_vaex.png)

[Vaex](https://github.com/vaexio/vaex) 是一个开源 DataFrame 库，支持可视化、探索和分析和你硬盘容量一样大的**表格类**数据集。Vaex 专门对此提出了内存映射、高效外存算法和懒评估等概念。所有这些都封装在类似 [Pandas](https://github.com/pandas-dev/pandas) 的 API 里，任何人都能方便上手。

# 十亿出租车数据分析

为了展示 Vaex 的效果，不妨来做个简单的数据分析任务，数据规模和标准笔记本内存容量相当。本文选用纽约出租车数据集（NYC），内含从 2009 年到 2015 年超过 10 亿条的出租记录。数据集以 csv 格式[提供](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page)。完整分析可以看本文适配的 [notebook](https://nbviewer.jupyter.org/github/vaexio/vaex-examples/blob/master/medium-nyc-taxi-data-eda/vaex-taxi-article.ipynb)

案例电脑配置：Mac Pro 15‘’ 2018，2.6GHz Intel Core i7，32GB RAM

> 着重留意每段代码的运行时间，这是10亿量级，普通笔记本

## 数据清洗

首先需要将数据转换成支持内存映射的格式，比如 [Apache Arrow](https://arrow.apache.org/), [Apache Parquet](https://parquet.apache.org/), 或 [HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format#HDF5)，[这里](https://nbviewer.jupyter.org/github/vaexio/vaex-examples/blob/master/medium-airline-data-eda/airline-original-data-conversion.ipynb)有一个 CSV 数据转 HDF5 的例子。转换完毕的数据用 Vaex 打开速度极快，本案例中耗时 0.052 秒，尽管硬盘数据大小超过了 100GB。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_load_data_mappable.png)

怎么这么快？当你用 Vaex 打开内存映射文件时，实际并没有发生读取操作。Vaex 只读取了文件元信息，例如存放位置，数据结构（行数，列数，列名，列数据类型），文本描述等等。想要浏览和数据交互怎么办？使用数据集时会生成标准的 DataFrame，浏览根本不费力：

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_data_view.png)

单元格再一次在极度舒适的时间内运行完毕。这是因为展示 Vaex DataFrame 或列只需要读取前五行或后五行内容。这引出另一要点：Vaex 只在非常必要的时候才会遍历整个数据集，同时会尽力减少数据传输。

不管怎样，先来清洗一下异常值和录入错误的信息。`describe`方法是宏观上了解数据的一个不错的开始，通过它可以获知样本数，缺失值数量和各列数据类型。如果是数值类型，均值、标准差和最大最小值也会同时显示出来。所有这些计算都是在一次数据传输中完成的。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_data_description.png)

DataFrame 实际有 18 列，这里只展示 7 列。`describe`方法很直观的展示出 Vaex 的强大——所有计算在 3 分钟内完成。其他库或方法要么得分布式要么需要超 100GB 容量的云实例才能完成相同计算任务。借助 Vaex，需要的只是数据，和几个 G 的内存空间。

看一下`describe`的输出就会发现数据含有一些极端值。首先我们检查一下上车点。去除极端值最简单的方式是画出上车和下车点，并可视化地在 NYC 上圈定出要分析的区域。因为我们处理的是大数据集，直方图是最有效的呈现方式了。用 Vaex 创建直方图很快，而且是可交互的！

```python
df.plot_widget(df.pickup_longitude, 
               df.pickup_latitude, 
               shape=512, 
               limits='minmax',
               f='log1p', 
               colormap='plasma')
```

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_interactive_graph_NYC.gif)

选定好要分析的区域后就可以过滤 DataFrame 了：

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_aera_filtered.png)

上述代码所需内存出奇的小，过滤 Vaex DataFrame 不会产生数据副本，而是会创建对原始对象的引用，在其上使用二进制掩码。掩码会选出要显示和参与计算的行。相较于其他数据科学工具拷贝数据的做法，这节约了 100 GB 内存

现在来检查一下`passenger_count`列。记录中最大乘客数单程达到了 255，有点夸张了。按乘客数统计出行量，可以使用`value_counts`完成：

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_trips_with_passenger.png)

上图可以看出超过 6 人出行很可能是异常值或只是录入错误。同时有大量 0 乘客的旅程，因为无法辨别其是否合法，先删掉。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_passenger_filtered.png)

对出行距离也进行类似分析。这是连续值，可以画出距离分布。看一下最大最小值（就很离谱～），画个直方图看一下

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_trip_distance_graph.png)

上图可以看出出行量随着里程变长而下降，大约在 100 英里出出现断崖式下跌，将其作为出行距离分割点。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_trip_distance_filtered.png)

里程的异常不禁让人想看一下出行花费时间和平均行驶速度。这些特征数据集里没有，但简单计算就能得到：

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_time_speed_code.png)

上述代码不占内存且几乎没花费时间！这是因为这段代码创建的是**虚拟列**。这些列只是在数学表达式中占个位，只有在调用时才会计算。除此之外虚拟列和一般列别无二致。注意，其他标准库对这一步可能需要 10 GB 内存。

好了，看一下出行时间的分布吧：

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_trip_duration.png)

可以看到 95% 都是 30 分钟以内的短途出行，尽管确实有些旅程超过 4-5 小时。纽约市里憋在出租车中 3 小时令人难以想象。不管怎样，想开点只关注 3 小时内的旅程好了：

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_duration_filtered.png)

再调查一下平均行驶速度，当然也得在合理数据范围内

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_speed_graph.png)

从上图可以推断出平均时速在 60 英里内是合适的

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_speed_filtered.png)

接下来将目光转向出行花费上。`describe`的结果中可以看到票价、总价和小费都存在异常值。这些内容不该有负值，同时也不该有哪个幸运儿跑一次出租就成了百万富翁。在合理范围内查看一下这些值的分布

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_fare_tip_distribution.png)

一台笔记本电脑花了 31 秒就对超 10 亿条出租记录完成了上述计算任务。同时看到三个分布都有很长的长尾分布。有一些可能是合理的，其他的肯能是录入错误。不管怎样，这里保守点只考虑三者数值都在 200$ 以内同时大于 0 的。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_fare_tip_filtered.png)

经简单清洗过后，看一下剩下多少数据

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_data_filtered.png)

还剩下超 11 亿条数据，足够挖出点有意思的内容了。

## 司机视角

假设我们是位出租司机，想利用这批数据最大化收入，最小化损失。

不妨先看一下平均来说哪里接客收入最高。直观上，可能会觉着该按平均收入画出上车点的热力图。但别忘了司机自己也是有开销的，比如燃油费。所以，跑一趟长途单程计费可能很高但油钱也高，时间损失也大。此外，从外地找到要回市中心的乘客可不容易，回程跑空车代价可不低。据此，可以按里程和计价的比值绘制热力图

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_fare_over_price.png)

如果只看计程最大值，那最佳接客区会是机场，并一路沿着主干道和高速走。而如果将距离因素也考虑在内，会发现上述路线接客确实很好但并在地图上并不突出。相反地，西边哈德逊河边似乎很有赚头。

跑出租很灵活，如果能知道什么时候出车想必会很有用。要解决这个问题，先来看一下每天各时段单位里程计费均值。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_fare_over_distance_day_hour.png)

上图和直觉相符。最佳时间段是上班高峰期，特别是工作日正午。而作为司机，一部分收入要上交公司的，所以我们对每天什么时候乘客给小费最慷慨很感兴趣。来画一幅相似的图，只是这次是平均小费百分比

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_tip_percentage.png)

上图很有意思，乘客早上 7-10 点给小费最多，以及每周头几天的晚上。凌晨 3、4点别期望能拿到多少小费。结合两张图来看，早上 8-10 点出车是个不错的选择。

## 换个角度

前文只是单纯的使用里程列，同时洗数据的时候只保留了 100 英里以内的数据。这依旧是很大的临界范围，特别是考虑到黄色出租公司主要业务范围是曼哈顿地区。里程列表示上车点和下车点的间出租走过的距离。但相同起止点，司机很可能为了避免堵车而选择其他路径。所以作为补充，添加`arc_distance`列，值为起止点间最短距离。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_arc_distance_code.png)

相较于 numpy 的复杂表达式，Vaex 借助 Numba，Pythran 甚至 CUDA 采用适时编译大幅提高计算速度。

`arc_distance`计算表达式很复杂，设计很多三角学和数学，同时如果数据量很大的话计算代价也会很高。如果使用纯 Python 和 Numpy 写计算逻辑，Vaex 会使用所有核心进行并行计算。除此之外，Vaex支持适时编译，借助 [Numbda](http://numba.pydata.org/)（使用 LLVM）或者 [Pythran](https://pythran.readthedocs.io/en/latest/)（C++ 加速计算）取得更好效果。如果你恰巧有张 NVIDIA  的图形卡，可以通过`jit_cuda`方法使用 [CUDA](https://developer.nvidia.com/cuda-zone) 计算获取进一步的提升。

不管怎样，来看一下`trip_distance`和`arc_distance`的分布吧

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_arc_distance_trip_distance.png)

可以看出 `arc_distance` 从没超过 21 英里，但计程车会走超过 5 倍的距离。实际上，有数百万条出租记录中的起止点间距在 100 米内。

## 时间视角

我们采用的数据集跨越了 7 年，这其中包含着一些有趣的变化。借助 Vaex 可以实现外存分组聚合运算。来看一下票价、里程在 7 年中的变迁

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_group_by_8_aggregation.png)

笔记本上 2 分钟内完成超 10 条样本带 8 个聚合指标的分组运算。8 个指标中 2 个是虚拟列。这种性能表现令人侧目。下面是不同年份间乘车费用的变化：

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_cost_evoled.png)

随着时间推移，出租车费和消费都稳步上涨。接下来看一看出行里程和起止点最小间距的变化

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_distance_year.png)

可以看出总体上每年人们的出行距离都会变长一点。

## 谈谈钱

最后让我们调查一下乘客的付款方式。数据集包含支付方式列

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_payment_type.png)

从[数据集说明](https://www1.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf)中找到该列中的 6 个有效值

- 1 = credit card payment
- 2 = cash payment
- 3 = no charge
- 4 = dispute
- 5 = Unknown
- 6 =Voided trip

所以得对支付方式列里的内容做个映射，转换成整型数字

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_payment_type_filtered.png)

现在就可以基于年份分组了，看看纽约市民乘车支付习惯的变化

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_habit_change.png)

随着时间推移，信用卡支付慢慢地成了主流，数字时代来临。注意，上述代码块中，完成聚合运算后 Vaex DataFrame 可以便捷的转换成 Pandas DataFrame，方便传入 [Seaborn](http://seaborn.pydata.org/)。不需要重复造轮子。

最后，来看看支付方式是否会因每日时段或星期几不同而不同。为此需要先创建一个过滤器，选出通过信用卡或现金结算的出租记录。其他库需要针对不同方式分别完成聚合计算然后再合并。Vaex 一步到位，聚合函数内部支持选择。这无疑十分便利，需要做的就是传数据。之后就可以遵循标准套路绘制 DataFrame 了。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-12-14_payment_fraction.png)

似乎从上图看到了前文类似图中的模式。对比两图可以看出信用卡结算的人比现金结账的多。