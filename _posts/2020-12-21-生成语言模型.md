---
layout:		post
title:  	生成语言模型
subtitle:   深化总结
date:       2020-12-21
author:     一轩明月
header-img: img/post-bg-code.jpg
catalog:    true
tags:
    - Transformer
    - attention
    - NLP
excerpt:    本文介绍了几种学习情景化词向量的模型，算是对之前 BERT，GPT-2等模型的总结，补充了早先和后继研究的部分细节，探讨了这些在各种语言任务上取得令人惊讶的 SOTA 成果的大型无监督预训练模型身上，透露出了什么新趋势
---

> 编译自：Generalized Language Models， [Lilian Weng](https://lilianweng.github.io/lil-log/)

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-12-09_elmo-and-bert.png)

2018 年对 NLP 领域来说是个不折不扣的转折年。像 OpenAI GPT 和 BERT 这样的大规模预训练语言模型采用通用模型架构，在各种语言任务上都取得了亮眼表现，和  ImageNet 分类预训练对视觉任务所带来的冲击可以等量齐观（×）。前者甚至更胜一筹，NLP 采用的方法简单而强大，预训练时不需要有标签数据，训练规模的增大也不妨碍实验，直至达到我们的极限。

> （×）：[He 等人，2018](https://arxiv.org/abs/1811.08883) 发现预训练可能对图像分割任务来说不是那么必要

在此之前的[词嵌入](https://libertydream.github.io/2020/02/13/embedding-%E5%9B%9E%E9%A1%BE/)，各种 embedding 都是针对特定上下文的——基于共现关系而非顺序语境学习。所以对 “I am eating an apple” 和 “I have an Apple phone”  两句话中的 “apple” 来讲，两个词指代的事物明显不同但还是会有相同的词嵌入向量。

尽管如此，早期解决问题的时候，用词嵌入也是将其作为已有的特定任务模型的附加特征，某种程度上所带来的改进有限。

本文中我们会介绍许多种基于环境做 embedding 的方法，好更简单、更容易的将词向量应用到下游任务上，格式通用。

### CoVe

**语境词向量（Contextual Word Vectors，Cove，[McCann 等人， 2017](https://arxiv.org/abs/1708.00107)）**是一类借助编码器做词嵌入的方法，编码器就是基于[注意力](https://libertydream.github.io/2020/04/26/Attention-%E7%BB%BC%E8%BF%B0/)的 seq-to-seq 机器翻译模型里的那种编码器。不同于传统的词嵌入方法，CoVe 的词表示是关于整个输入序列的函数。

#### NMT 概述

这里的神经机翻译（[NMT](https://github.com/THUNLP-MT/MT-Reading-List)）模型由一个标准的双层双向 LSTM 编码器，和一个额外的基于注意力的双层单向 LSTM 解码器构成，预先在英语-德语翻译任务上训练好。编码器学习并优化英文单词的 embedding 向量，好将其译为德文。直觉上编码器能在将词转为其他语言形式前领悟语义和句法内涵，编码器的输出结果被用做各种下游语言任务的情景化词嵌入。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-12-09_nmt-recap.png)

图 1  CoVe 中的 NMT 基础模型

-  $$n$$  : $$x = [x_1, \dots, x_n]$$.
-  $$m$$   $$y = [y_1, \dots, y_m]$$.
- : $$\text{GloVe}(x)$$.
-  $$z = [z_1, \dots, z_m]$$.
- $$h = [h_1, \dots, h_n] = \text{biLSTM}(\text{GloVe}(x))$$   $$h_t = [\overrightarrow{h}_t; \overleftarrow{h}_t]$$   $$\overrightarrow{h}_t = \text{LSTM}(x_t, \overrightarrow{h}_{t-1})$$   $$\overleftarrow{h}_t = \text{LSTM}(x_t, \overleftarrow{h}_{t-1})$$.
-  $$p(y_t \mid H, y_1, \dots, y_{t-1})$$  $$H$$  s $$\{h\}$$ 

$$
\begin{aligned}
\text{decoder hidden state: } s_t &= \text{LSTM}([z_{t-1}; \tilde{h}_{t-1}], s_{t-1}) \\
\text{attention weights: } \alpha_t &= \text{softmax}(H(W_1 s_t + b_1)) \\
\text{context-adjusted hidden state: } \tilde{h}_t &= \tanh(W_2[H^\top\alpha_t;s_t] + b_2) \\
\text{decoder output: } p(y_t\mid H, y_1, \dots, y_{t-1}) &= \text{softmax}(W_\text{out} \tilde{h}_t + b_\text{out})
\end{aligned}
$$

#### 下游任务中的 CoVe

$$
\text{CoVe}(x) = \text{biLSTM}(\text{GloVe}(x))
$$


$$
v = [\text{GloVe}(x); \text{CoVe}(x)]
$$
![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-12-09_CoVe.png)

### ELMo

#### 双向语言模型

$$
p(x_1, \dots, x_n) = \prod_{i=1}^n p(x_i \mid x_1, \dots, x_{i-1})
$$


$$
p(x_1, \dots, x_n) = \prod_{i=1}^n p(x_i \mid x_{i+1}, \dots, x_n)
$$
 $$\overrightarrow{\mathbf{h}}_{i,\ell}$$ and $$\overleftarrow{\mathbf{h}}_{i,\ell}$$   $$\ell=1,\dots,L$$.  $$\mathbf{h}_{i,L} = [\overrightarrow{\mathbf{h}}_{i,L}; \overleftarrow{\mathbf{h}}_{i,L}]$$   $$\Theta_e$$ and $$\Theta_s$$ 

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-12-09_ELMo-biLSTM.png)


$$
\begin{aligned}
\mathcal{L} = - \sum_{i=1}^n \Big( 
\log p(x_i \mid x_1, \dots, x_{i-1}; \Theta_e, \overrightarrow{\Theta}_\text{LSTM}, \Theta_s) + \\
\log p(x_i \mid x_{i+1}, \dots, x_n; \Theta_e, \overleftarrow{\Theta}_\text{LSTM}, \Theta_s) \Big)
\end{aligned}
$$

#### ELMo 表示

 $$L$$-  $$x_i$$   $$2L+1$$ 
$$
R_i = \{ \mathbf{h}_{i,\ell} \mid \ell = 0, \dots, L \}
$$
 $$\mathbf{h}_{0, \ell}$$   $$\mathbf{h}_{i, \ell} = [\overrightarrow{\mathbf{h}}_{i,\ell}; \overleftarrow{\mathbf{h}}_{i,\ell}]$$.

 $$\mathbf{s}^\text{task}$$,   $$\gamma^\text{task}$$ 
$$
v_i = f(R_i; \Theta^\text{task}) = \gamma^\text{task} \sum_{\ell=0}^L s^\text{task}_i \mathbf{h}_{i,\ell}
$$

#### 下游任务中的 ELMo

### 跨视角训练

#### 模型架构

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-12-09_CVT.png)

#### 多任务训练

#### 下游任务中的 CVT

 $$\mathbf{h}_1^{(i)}$$   $$\mathbf{h}_2^{(i)}$$:
$$
\begin{aligned}
p_\theta(y_i \mid \mathbf{x}_i) 
&= \text{NN}(\mathbf{h}^{(i)}) \\
&= \text{NN}([\mathbf{h}_1^{(i)}; \mathbf{h}_2^{(i)}]) \\
&= \text{softmax} \big( \mathbf{W}\cdot\text{ReLU}(\mathbf{W'}\cdot[\mathbf{h}_1^{(i)}; \mathbf{h}_2^{(i)}]) + \mathbf{b} \big)
\end{aligned}
$$

$$
\begin{aligned}
p_\theta^\text{fwd}(y_i \mid \mathbf{x}_i) &= \text{NN}^\text{fwd}(\overrightarrow{\mathbf{h}}^{(i)}) \\
p_\theta^\text{bwd}(y_i \mid \mathbf{x}_i) &= \text{NN}^\text{bwd}(\overleftarrow{\mathbf{h}}^{(i)}) \\
p_\theta^\text{future}(y_i \mid \mathbf{x}_i) &= \text{NN}^\text{future}(\overrightarrow{\mathbf{h}}^{(i-1)}) \\
p_\theta^\text{past}(y_i \mid \mathbf{x}_i) &= \text{NN}^\text{past}(\overleftarrow{\mathbf{h}}^{(i+1)})
\end{aligned}
$$
![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-12-09_CVT-example.png)

### ULMFiT



-  $$\{\eta^1, \dots, \eta^\ell, \dots, \eta^L\}$$,   $$\eta$$   $$\eta^\ell$$   $$\ell$$-   $$L$$ 

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-12-09_ULMFiT.png)

### BERT

#### 预训练任务

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-12-09_transformer-encoder-2.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-12-09_language-model-comparison.png)

#### 输入嵌入

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-12-09_BERT-input-embedding.png)

#### 下游任务中的 BERT

 $$\mathbf{h}^\text{[CLS]}_L$$, , $$\text{softmax}(\mathbf{h}^\text{[CLS]}_L \mathbf{W}_\text{cls})$$. 

, $$\mathbf{W}_\text{s}$$   $$\mathbf{W}_\text{e}$$,  $$\text{softmax}(\mathbf{h}^\text{(i)}_L \mathbf{W}_\text{s})$$   $$\text{softmax}(\mathbf{h}^\text{(i)}_L \mathbf{W}_\text{e})$$ 

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-16_bert-tasks.png)

### ALBERT

#### 参数化要素嵌入

 $$E$$   $$H$$.   $$H$$)  ($$V$$).

 $$V \times H$$   $$V \times E$$ and $$E \times H$$.   $$H \gt E$$   $$H \gg E$$, 

#### 跨层参数共享

#### 序列次序预测（SOP）

### RoBERTa

### OpenAI GPT

#### 将 Transformer 解码器作语言模型

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-12-09_OpenAI-GPT-transformer-decoder.png)
$$
\mathcal{L}_\text{LM} = -\sum_{i} \log p(x_i\mid x_{i-k}, \dots, x_{i-1})
$$

#### 字节对编码

#### 有监督微调

 $$n$$  , $$\mathbf{x} = (x_1, \dots, x_n)$$,  $$y$$.  $$\mathbf{x}$$  $$x_n$$ is $$\mathbf{h}_L^{(n)}$$.  $$\mathbf{W}_y$$,

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2020-12-09_GPT-classification.png)
$$
\begin{aligned}
\mathcal{L}_\text{cls} &= \sum_{(\mathbf{x}, y) \in \mathcal{D}} \log P(y\mid x_1, \dots, x_n) = \sum_{(\mathbf{x}, y) \in \mathcal{D}} \log \text{softmax}(\mathbf{h}_L^{(n)}(\mathbf{x})\mathbf{W}_y) \\
\mathcal{L}_\text{LM} &= -\sum_{i} \log p(x_i\mid x_{i-k}, \dots, x_{i-1}) \\
\mathcal{L} &= \mathcal{L}_\text{cls} + \lambda \mathcal{L}_\text{LM}
\end{aligned}
$$
![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-11-16_openai-input%20transformations.png)





### OpenAI GPT-2

#### 零尝试 Transfer

#### 字节序列上的 BPE

#### 模型调整

### 总结

### 指标：复杂度


$$
2^{H(p)} = 2^{-\sum_x p(x) \log_2 p(x)}
$$
 $$N$$  $$s = (w_1, \dots, w_N)$$, , $$\frac{1}{N}$$:
$$
H(s) = -\sum_{i=1}^N P(w_i) \log_2  p(w_i)  = -\sum_{i=1}^N \frac{1}{N} \log_2  p(w_i)
$$

$$
\begin{aligned}
2^{H(s)} &= 2^{-\frac{1}{N} \sum_{i=1}^N \log_2  p(w_i)}
= (2^{\sum_{i=1}^N \log_2  p(w_i)})^{-\frac{1}{N}}
= (p(w_1) \dots p(w_N))^{-\frac{1}{N}}
\end{aligned}
$$

### 常见任务和数据集



