---
layout:		post
title:  	机器学习算法调试难点和解决办法
subtitle:   
date:       2021-02-20
author:     一轩明月
header-img: img/post-bg-future.jpg
catalog:    true
tags:
    - math
    - optimization
excerpt:    
---

> 编译自：Why are machine learning algorithms hard to tune and how to fix it， [Jonas Degrave, Ira Korshunova](https://engraved.ghost.io/why-machine-learning-algorithms-are-hard-to-tune/)

机器学习领域中，线性组合起来的损失遍地都是。实际上，这通常就是标准路径，尽管路上全是坑，尤其是考虑到这些线性组合让你的算法有多难调试。由此引出本文如下观点：

- 很多机器学习问题本该当作多目标问题对待，但却没有
- 多目标对待举措的缺失加大了这些机器学习算法超参调试难度
- 这些问题发生的时候几乎无法察觉，也就更难加以解决了
- 有办法可以解决这一问题，用不了几行代码。后文会介绍其中一种

本文没什么新奇内容，你可能早已知晓了我们想说的一切。但我印象中绝大多数机器学习教程并没有深入探讨优化方法（起码我的没有），结果就是梯度下降“一招鲜，吃遍天”。一般的教训在于，如果某个算法对你的问题无效，你需要花费更多的时间为问题调试超参数。

后文会介绍一种基于 NIPS‘88 的论文解决方案，其介绍了修正乘数微分法。希望本文能帮你消除一些疑惑，以更基础和有原则的方式解决问题。
$$
\begin{array}{l}
L(\theta)=L_{0}(\theta)+\lambda \sum|\theta| \\
L(\theta)=L_{0}(\theta)+\lambda \sum \theta^{2}
\end{array}
$$

$$
L(\theta)=\mathbb{E}_{q_{\phi}(z \mid x)}\left[\log p_{\theta}(x \mid z)\right]-\beta D_{K L}\left(q_{\phi}(z \mid x) \| p(z)\right)
$$

$$
\begin{array}{c}
L(\pi)=-\sum_{t} \mathbb{E}_{\left(s_{t}, a_{t}\right)}\left[r\left(s_{t}, a_{t}\right)+\alpha \mathcal{H}\left(\cdot, s_{t}\right)\right] \\
L(\pi)=-\sum_{t} \mathbb{E}_{\left(s_{t}, a_{t}\right)}\left[\mathbb{E}_{\pi}\left(Q\left(s_{t}, a_{t}\right)\right)-\alpha D_{K L}(q \| \pi)\right]
\end{array}
$$

$$
L(\theta)=-\mathbb{E}_{x}\left[\log D_{\theta}(x)\right]-\mathbb{E}_{z}\left[\log \left(1-D_{\theta}\left(G_{\theta}(z)\right)\right]\right.
$$


![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_optimising_a_multi-objective_loss_convex.gif)



```python
def loss(θ):
  return loss_1(θ) + loss_2(θ)
loss_derivative = grad(loss)
for gradient_step in range(200):
  gradient = loss_derivative(θ)
  θ = θ - 0.02 * gradient
```



```python
def loss(θ, α):
  return loss_1(θ) + α*loss_2(θ)
loss_derivative = grad(loss)
for gradient_step in range(200):
  gradient = loss_derivative(θ, α=0.5)
  θ = θ - 0.02 * gradient
```



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_optimising_for_different_alphas_concave.gif)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_optimising_for_different_alphas_convex_pareto.gif)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_optimising_for_different_alphas_concave_pareto.gif)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_loss_optimization.png)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_visualising_the_convex_case.gif)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_visualising_the_concave_case.gif)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_visualising_the_mixed_case.gif)




$$
\text { Minimize } L_{0}(\theta) \text { subject to } L_{1}(\theta)<\epsilon
$$

$$
L(\theta, \lambda)=L_{0}(\theta)-\lambda\left(\epsilon-L_{1}(\theta)\right)
$$


```python
def loss(θ, λ, ε):
  return loss_1(θ) - λ*(ε - loss_2(θ))

loss_derivative = grad(loss)
ε = 0.3 
λ = solve_dual(ε)  # The crux

for gradient_step in range(200):
  gradient = loss_derivative(θ, λ, ε)
  θ = θ - 0.02 * gradient
```





![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_the_solve-the-dual_method_convex_alpha.gif)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_the_solve-the-dual_method_concave_alpha.gif)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_the_solve-the-dual_method_concave_pareto.gif)

```python
def constraint(θ, ε):
  return ε - loss_2(θ)

optimization_derivative = grad(loss_1)
constraint_derivative = grad(constraint)

ε = 0.7

for gradient_step in range(200):
  while constraint(θ, ε) < 0:
    # maximize until the constraint is positive again
    gradient = constraint_derivative(θ, ε)
    θ = θ + 0.02 * gradient
    
  gradient = optimization_derivative(θ)
  θ = θ - 0.02 * gradient
```



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_the_hard_constraint_first_method_concave_pareto.gif)



```python
def lagrangian(θ, λ, ε):
 return loss_1(θ) - λ*(ε - loss_2(θ))

derivative = grad(lagrangian, (0,1))
ε = 0.7
λ = 0.0

for gradient_step in range(200):
  gradient_θ, gradient_λ = derivative(θ,λ,ε)
  θ = θ - 0.02 * gradient_θ  # Gradient descent
  λ = λ + gradient_λ  # Gradient ascent!
  if λ < 0:
    λ = 0
```



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_the_basic_differential_multiplier_method_convex_pareto.gif)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_the_basic_differential_multiplier_method_concave_pareto.gif)

```python
def lagrangian(θ, λ, ε):
 damp = 10 * stop_gradient(ε-loss_2(θ))
 return loss_1(θ) - (λ-damp) * (ε-loss_2(θ))

derivative = grad(lagrangian, (0,1))
ε = 0.7
λ = 0.0

for gradient_step in range(200):
  gradient_θ, gradient_λ = derivative(θ, λ, ε)
  θ = θ - 0.02 * gradient_θ
  λ = λ + gradient_λ
  if λ < 0:
    λ = 0
```





![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_the_modified_differential_method_of_multipliers_convex_pareto.gif)



![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_the_modified_differential_method_of_multipliers_concave_pareto.gif)