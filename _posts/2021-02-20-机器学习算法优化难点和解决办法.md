---
layout:		post
title:  	机器学习算法调试难点和解决办法
subtitle:   
date:       2021-02-20
author:     一轩明月
header-img: img/post-bg-future.jpg
catalog:    true
tags:
    - math
    - optimization
excerpt:    线性组合损失可以说是随处可见，但常伴随着算法不可调试等问题，基于帕累托边界和凹凸性，配合大量图示，本文介绍了问题出现的原因和解决问题的对偶法和改良的乘数微分法
---

> 编译自：Why are machine learning algorithms hard to tune and how to fix it， [Jonas Degrave, Ira Korshunova](https://engraved.ghost.io/why-machine-learning-algorithms-are-hard-to-tune/)

机器学习领域中，损失的线性组合遍地都是。实际上，尽管坑多沟深，它们通常就是标准做法，特别是这些线性组合会让你的算法变得很难调试。由此引出本文观点：

- 很多机器学习问题本该当作多目标问题对待，但却没有
- 没当多目标处理的结果是加大了机器学习算法的超参调试难度
- 这些问题发生的时候几乎无法察觉，使问题更加难解决
- 对偶法和微分乘数法可以解决这一问题，用不了几行代码

本文没什么新内容，你可能早已清楚文中所讲的一切。但我印象中绝大多数机器学习教程并没有深入探讨优化方法（起码我的没有），结果就是梯度下降“一招鲜，吃遍天”。人们一般认为如果某个算法对你的问题无效，那你需要花费更多的时间在调试超参数上。

希望本文能帮你消除一些疑惑，以更根本、更有原则的方式解决该问题。这也可能帮你省下调参时间，专心做研究。

### 无处不在的线性组合损失

单目标问题是存在，但一般也要搭配正则化。我们从整个机器学习领域中选出了一组这样的优化目标。

首先是正规项，权重衰减和 lasso 损失。显然，当你用上这些正则化手段时，也就针对问题创建了一个多目标损失函数。实际上你所在意的是原损失 $$L_0$$ 和正则损失都要够低。为此，你会用参数 $$\lambda$$ 在二者间取得平衡。



$$
\begin{array}{l}
L(\theta)=L_{0}(\theta)+\lambda \sum|\theta| \\
L(\theta)=L_{0}(\theta)+\lambda \sum \theta^{2}
\end{array}
$$



结果就是像 VAE 中的损失那样实质上成了多目标损失形态，首先是要尽可能覆盖数据样本，其次是要尽量贴合先验分布。偶尔还会配上 KL 散度，通过可调参数 $$\beta$$ 处理多目标损失。



$$
L(\theta)=\mathbb{E}_{q_{\phi}(z \mid x)}\left[\log p_{\theta}(x \mid z)\right]-\beta D_{K L}\left(q_{\phi}(z \mid x) \| p(z)\right)
$$



强化学习中，你也能看到这种多目标问题。不仅许多情景任务就是对局部回报的简单求和，策略损失通常也是线性组合的方式。以 PPO，SAC 和 MPO 的策略损失为例，采用带可调参数 $$\alpha$$ 的熵正则法。



$$
\begin{array}{c}
L(\pi)=-\sum_{t} \mathbb{E}_{\left(s_{t}, a_{t}\right)}\left[r\left(s_{t}, a_{t}\right)+\alpha \mathcal{H}\left(\cdot, s_{t}\right)\right] \\
L(\pi)=-\sum_{t} \mathbb{E}_{\left(s_{t}, a_{t}\right)}\left[\mathbb{E}_{\pi}\left(Q\left(s_{t}, a_{t}\right)\right)-\alpha D_{K L}(q \| \pi)\right]
\end{array}
$$



更不用说 GAN 损失，那就是辨别器和生成器损失的和：



$$
L(\theta)=-\mathbb{E}_{x}\left[\log D_{\theta}(x)\right]-\mathbb{E}_{z}\left[\log \left(1-D_{\theta}\left(G_{\theta}(z)\right)\right]\right.
$$



所有这些损失有个共同点，他们实质上都在尝试同时优化多个目标，认为最优解就是在这些常彼此冲突的部分中取得平衡。一些情况下，更特殊一点的求和会带上超参数来调节各部分权重。有时候对于损失为何这样组织有着清晰的理论基础，并且不需要超参数调节平衡。

看过本文后希望你清楚，这种损失组合方法可能听上去诱人，但这种线性组合实际上既不稳定又不可靠，所谓的平衡艺术更像是在走钢丝。

### 玩具样例

来看一个简单例子，试着用全局优化的方式优化一个线性组合损失，全局损失是损失的和。通过梯度下降我们观测到如下结果。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_optimising_a_multi-objective_loss_convex.gif)

*图 1  多目标损失优化*

写成 Jax 代码像这样：

```python
def loss(θ):
  return loss_1(θ) + loss_2(θ)
loss_derivative = grad(loss)
for gradient_step in range(200):
  gradient = loss_derivative(θ)
  θ = θ - 0.02 * gradient
```

和通常一样，我们并没有立刻取得损失上的满意结果，所以我们给第二个损失加了个比例系数 $$\alpha$$ 并运行下列代码：

```python
def loss(θ, α):
  return loss_1(θ) + α*loss_2(θ)
loss_derivative = grad(loss)
for gradient_step in range(200):
  gradient = loss_derivative(θ, α=0.5)
  θ = θ - 0.02 * gradient
```

我们希望看到的是调节 $$ \alpha$$ 后，我们可以在两个损失中取得均衡，并选择那个对应用来讲最满意的点。实际上我们会开启一个超参数调试循环，人工选取一个 $$\alpha$$，执行最优化程序，觉得第二个损失该再小点，相应调大 $$\alpha$$ 并重复整个最优化过程。几轮迭代后，我们敲定了最终方案，继续写我们的论文。

但这种情形并不总会发生，实际观察到的结果有时候会像这样：

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_optimising_for_different_alphas_concave.gif)

*图 2  不同 $$\alpha$$ 下的损失优化表现*

好像不管怎么调 $$\alpha$$，都不能在两个损失间取得较好的平衡。

我们可以看到两组解，一个忽略了第一项损失，另一个忽略了第二项损失。但这两组方案对大多数应用来讲都没啥用，多数情况下更能平衡两种损失的点是我们更偏爱的选择。

实际上，人们几乎从没画过两个损失在训练过程中的变化图，所以动态图里所展示出的现象也就鲜有人提及。我们只看描绘整体损失的训练曲线，可能会得出超参需要进一步调试的结论，因为它看起来很敏感。或者我们可以用早停方法保证论文中的数字有效，毕竟评议员喜欢数据有效性。

是哪里出了岔子呢？**为什么这种方法有时有效，又为什么有时给不了你一个可调参数**？为此，我们需要进一步看下两个图像间的差异。

两个图像是根据同一问题画的，一样的损失，一样的损失优化方法。所以不会是这些方面导致最终的差异。发生变化的是模型，换句话讲，模型参数 $$\theta$$ 对模型结果带来的影响是不同的。

所以，我们 *做个弊*，把一些通常不可见的内容画出来，也就是两个优化方案的帕累托边界。这是我们模型能取得的所有解的集合，换句话讲，这是能达到的损失的集合，不存在使 *所有* 损失更优的点。不论你怎么调整两个损失，首选方案永远落在帕累托边界上。调节损失的超参数，一般只是找到了同一边界上的另一个点。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_optimising_for_different_alphas_convex_pareto.gif)

*图 3  不同 $$\alpha$$ 下损失优化的帕累托边界（凸）*

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_optimising_for_different_alphas_concave_pareto.gif)

*图 4  不同 $$\alpha$$ 下损失优化的帕累托边界（凹）*

两条帕累托曲线的差异在于第一种情况下结果很好，但改变模型后就变得很糟。结果是当帕累托边界是凸的，我们可以通过调节 $$\alpha$$ 参数达到任意均衡点，但是假如帕累托边界是凹的，同样的方法可能就不再有效了。

### 失效原因分析

我们可以画图看下为何梯度下降会对凹帕累托边界失效，以三维视角观察整体损失，损失用梯度下降优化。下图中我们画出了由各损失构成的整体损失平面，尽管我们实际是在按各参数梯度在平面上向下走，在朝平面下方走时的每一步（梯度下降）也都是必要的。你可以将梯度下降优化过程看作是在平面上放了个球形鹅卵石，让其随重力滚落直到停止。

优化过程停下的点就是优化结果，这里用星星表示。正如下图所示，无论你怎么摆动平面，最终都会在最优点停止。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_loss_optimization.png)

*图 5  损失优化图示*

调节 $$\alpha$$，空间仍为一个平面，毕竟改变 $$\alpha$$ 只是改了平面的斜率。如你所见，在凸条件下，帕累托曲线上的任意解都可通过调整 $$\alpha$$ 达到。$$\alpha$$ 大点就将星星拉向左侧，小点则拉到右侧。不管起点选哪里最终都会收敛于相同结果，这对任意 $$\alpha$$ 值都成立。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_visualising_the_convex_case.gif)

*图 6  凸条件下的优化过程*

但是，如果是对凹帕累托曲线的问题建模，我们的问题从何而来也就显而易见了。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_visualising_the_concave_case.gif)

*图 7  凹条件下的优化过程*

想象一下鹅卵石顺着该平面上的梯度进行滚动的场景：有时会滚向左侧，有时是右侧，但总还是向下的。显然它最终会在两个角落之一处停下，要么是红星星，要么是蓝星星。调节 $$\alpha$$ 的时候，平面倾斜情况和凸条件下一模一样，但鉴于帕累托边界的形状，只能达到边界上的两个点，亦即凹曲线的两端。曲线上你实际想达到的 X 点，靠梯度下降法是做不到的。为什么？因为那是个鞍点。

还要多留意一下在我们调节 $$\alpha$$ 的时候发生了什么。可以看到我们调整了针对另一个解而落在一个解上的起点数量，可就是找不到帕累托边界上的其他解。

### 线性组合带来的问题

简单总结一下，损失的线性组合会有如下问题：

- 首先，即使不用超参数平衡损失，**说梯度下降会平衡彼此冲突的力量也不正确**。这要看你模型所能取得的解，随模型初始化的不同，它可能完全忽略某个损失而聚焦于另一个上，反之亦然。
- 其次，即使加上超参数，**超参数也是调的试着看**。完整跑一轮优化，看是否满意，然后再微调超参数，重复该优化循环直到满意为止。这是个费时费力的法子，一般都要跑梯度下降进行多次迭代。
- 第三，**无法调整超参数取得所有最优解**。不论你怎么折腾和微调，你也找不到可能中意的中间结果上，这倒并不是因为它们不存在，多数时候它们确实存在，而是因为选了差劲的损失组合方法。
- 第四，得强调一下对实际应用来讲，**帕累托边界是否是凸的以及由此导致的损失权重是否可调总是未知的**。超参数好不好要看你怎么对模型做的参数化，以及这又怎样影响到了帕累托曲线。但想可视化或分析所有实际应用的帕累托曲线是不可能的。可视化比原优化问题还要难得多。所以如果问题已经发生了，它也不会被注意到。
- 最后，如果你确实想用线性权重来实现均衡，那你需要显式证明**所用模型的整个帕累托曲线是凸的**。所以只是用对模型结果为凸的损失函数并不能避免问题发生。如果参数空间很大，涉及神经网络参数的话常常如此，你可能会忘记去试着证明一下。得强调一下，基于某些中间结果的损失所展示出的帕累托曲线凸性并不足以说明存在可调参数。凸性强烈依赖于参数空间，以及可取得解的帕累托边界的样子。

注意，绝大多数情况下帕累托边界既不凸又不凹，而是二者的混合。这使问题变得更加复杂。举个例子，凹段夹杂在凸段中间，如此一来不仅每个凹段会使梯度下降无解，它还会把参数初始空间分成两部分，一个会在一边的凸段上找到解，一个则只能在另一段上找到解。凹段越多问题越严重，如下图所示。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_visualising_the_mixed_case.gif)

*图 8  混合条件下的优化过程*

所以我们不只是有一个无法找到所有解的超参数 $$\alpha$$，按初始化情况它还可能发现帕累托曲线的又一凸段。参数和初始化的问题相互缠结使问题变得更加复杂。你可能只是想微调参数轻微挪动下解的位置，即便初始化都一样，结果却突然跳到了帕累托边界上的不同凸段上。

### 可调试算法

在讨论解决办法之前，我们得先定义一下“可调试算法”的内涵。什么会令超参调试变得容易呢？想做到这点，需要以下东西：

- **超参最好有语义**。这样可以一次性找到更优解，不需要多次迭代尝试各种参数以缩小目标范围。
- 通过调节参数，**应该可以找到帕累托边界上的任意解**。换句话说，帕累托边界上的每个解都能找到一个参数值与其对应。

为此，我们将待解问题重构为拉格朗日最优化问题。选一个损失为主损失，并给其他损失加上约束。目标是要在次级损失小于 $$\epsilon$$ 的情况下令主损失最小化。



$$
\min L_{0}(\theta) \text { ，cond } L_{1}(\theta)<\epsilon
$$



最终得到的拉格朗日表达式看起来和一开始的线性组合的总体损失比较像。



$$
L(\theta, \lambda)=L_{0}(\theta)-\lambda\left(\epsilon-L_{1}(\theta)\right)
$$



但这里我们可以将其看作是有约束的最优化问题，从而更好地处理总体损失。

举例来讲，在 Karush–Kuhn–Tucker (KKT) 条件下，在该受约束问题上是否收敛，在哪收敛都是有严格数学形式对应的。这有些技术化了而且对后文来讲没什么必要，但从这些条件我们可以知道，我们要找的最优解是这个由损失线性组合成的拉格朗日表达式上的一个鞍点。

将这点洞察与梯度下降无法找到鞍点的事实结合，就会注意到凹帕累托边界的场景下可能会有问题。所以我们仍旧是不清楚，拉格朗日优化加上梯度下降也同样是个危机四伏的领域。

下面我们就看一下各处文献中提到的方法，问题搭配方法一起看，看看哪种方法能令机器学习算法可调试。

### 对偶法

求解对偶问题（Solve-The-Dual）是做拉格朗日优化时的一种惯常做法，构建对偶并求解，希望找到理想的 $$\lambda$$。接着就是用梯度下降优化拉格朗日表达式，直观上我们可能认为给 $$\lambda$$ 赋个值，再用梯度下降优化一下就能解决这个带约束的最优化问题。


```python
def loss(θ, λ, ε):
  return loss_1(θ) - λ*(ε - loss_2(θ))

loss_derivative = grad(loss)
ε = 0.3 
λ = solve_dual(ε)  # The crux

for gradient_step in range(200):
  gradient = loss_derivative(θ, λ, ε)
  θ = θ - 0.02 * gradient
```

为可视化这一工作细节，我们将优化过程的损失变化画下来，并按参数初始化情况分配颜色。如下图所示，对 loss 2 的约束由黑色阴影线表示，希望借此使带约束优化问题和原始问题间的关系更加直观。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_the_solve-the-dual_method_convex_alpha.gif)

*图 9  凸条件下求解对偶问题*

该情形下问题顺利解决，我们也能用 $$\epsilon$$ 调整最优值。所以我们能达到我们想要的均衡点，无需多次执行优化程序来调整超参 $$\epsilon$$。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_the_solve-the-dual_method_concave_alpha.gif)

*图 10  凹条件下求解对偶问题*

但当我们用凹帕累托边界对模型重新建模时，便会有问题发生。不仅不能收敛到帕累托边界上，梯度下降得到的某些解甚至忽略、突破了我们的硬约束！

其中原因前文已经讲过。即使解开了对偶问题找到了与 $$\epsilon$$ 相配的 $$\lambda$$，我们仍是在对损失做线性调节，如前文所讲，梯度下降在这方面效果并不太好。所以，虽然很多论文都用了这个方法，这法子还是不通用。帕累托边界是凹的时候，约束可能被忽略掉而且调节超参数你也找不到所有优质解。况且一般来讲，你并不知道你的帕累托边界的形状，所以你也不会知道你当前处于哪种情况。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_the_solve-the-dual_method_concave_pareto.gif)

*图 11 凹帕累托边界下的优化*

### 硬约束优先

一个有效的替代方案是，**优先优化要梯度下降的约束项，并只在满足约束的情况下去优化主损失**。通过这种方法，约束总满足收敛条件且其他损失能取得最小。该方法对凸凹情形都适用。

```python
def constraint(θ, ε):
  return ε - loss_2(θ)

optimization_derivative = grad(loss_1)
constraint_derivative = grad(constraint)

ε = 0.7

for gradient_step in range(200):
  while constraint(θ, ε) < 0:
    # maximize until the constraint is positive again
    gradient = constraint_derivative(θ, ε)
    θ = θ + 0.02 * gradient
    
  gradient = optimization_derivative(θ)
  θ = θ - 0.02 * gradient
```

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_the_hard_constraint_first_method_concave_pareto.gif)

*图 12  凹帕累托边界下的约束优先优化*

该方法的主要缺点在于，梯度下降的时候你并没有真的在权衡损失，每一步都只考虑了其中一个损失。这也使得对许多应用来讲该方法没预期中的那么好。

一种常见失败情况是约束条件显然有解，但不知怎的此时参数空间内主损失几乎找不到可用梯度。当你每次解决约束都要撤销在主损失上取得的进度的时候，收敛可能也会是个问题。

此外，如果你想用随机梯度下降而非梯度下降的时候，该方法效果并不好。因为约束是定义在全部数据上的平均损失，只要一般情况下约束都有效，你不会想因一个未满足条件的样本而强行修改硬约束。这是很难解决的一个问题。

但该方法的优点就在于实现简单，可能在你的问题上效果也够好。

### 基础微分乘数法

目前已知能用梯度下降解开这个带约束优化问题的解是存在的。如果回到用拉格朗日法解决我们带约束版优化问题的思路上，会发现根本问题就出在求解对偶函数找到固定 $$\lambda$$ 和用梯度下降最小化其他参数两个任务的互相纠缠上了。我们能不能单用梯度下降同时找到最优参数和拉格朗日乘数呢？实际上，按下列算法就能做到：

```python
def lagrangian(θ, λ, ε):
 return loss_1(θ) - λ*(ε - loss_2(θ))

derivative = grad(lagrangian, (0,1))
ε = 0.7
λ = 0.0

for gradient_step in range(200):
  gradient_θ, gradient_λ = derivative(θ,λ,ε)
  θ = θ - 0.02 * gradient_θ  # Gradient descent
  λ = λ + gradient_λ  # Gradient ascent!
  if λ < 0:
    λ = 0
```

按表达式梯度，参数往下走而 $$\lambda$$ 往上走，所以参数是梯度下降而拉格朗日乘数是梯度上升。因为约束是个不等式，只要留意 $$\lambda$$ 别成了负数，前景应该比较光明。注意，我们是真的希望约束满足的时候 $$\lambda$$ 归零，可软软地加上甚至把它弄成指数型的以保证为正可是个馊主意，即便你可能在多个刊物、论文中见过这样的处理。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_the_basic_differential_multiplier_method_convex_pareto.gif)

*图 13 凸条件下的基础微分乘数法*

凸条件下该方法效果很好，每次梯度运算所有损失都考虑到了。这使得随机梯度下降也能用该方法，就是要多费点劲弄清楚拉格朗日算子是怎么工作的。还要注意单用一个梯度运算式既做梯度下降又做梯度上升是可以实现的，所以计算复杂度大体不变。

但它并未解决一般条件下我们的原始问题，看下它在凹帕累托边界情况下的表现就知道了。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_the_basic_differential_multiplier_method_concave_pareto.gif)

*图 14  凹条件下的基本微分乘数法*

尽管性能相当，但它并没有完成收敛。该优化方案一直在帕累托边界上振荡，不能定在一个优质解上。所以该方法可能能找到更好的解，但还是无法调试。可你还是能在很多论文中看到该方法，因为某个人可以精心挑选一个优化停止时刻，由此找到的解在同行评议时很有说服力。但当人工干预不可行的时候该方法就很难用了，比如，当优化过程是一个更大的难题的一部分时，例如强化学习。

### 改良微分乘数法

最后介绍一种解决方案，就我们所知是 [John 等，1988](https://papers.nips.cc/paper/1987/file/a87ff679a2f3e71d9181a67b7542122c-Paper.pdf) 第一次提出该方法。

有了上一幅图中振荡情形的直观感受，这方法理解起来就更容易了。只要违反了约束条件，$$\lambda$$ 就会持续增大。但当我们突然又满足了约束，$$\lambda$$ 还是那么大，在梯度下降将 $$\lambda$$ 归零前要花许多步。只要 $$\lambda$$ 是正的，解就会被进一步推离约束，最终 $$\lambda$$ 变成了零，约束被忽视而优化过程继续。可当解意外又撞上了约束条件，整个循环就得再来一次。你可以把拉格朗日乘子直观理解为振荡系统的势能。

基于这种情况，论文作者在他们的改良微分乘数法中加入了能量阻尼，这样就能防止系统不停振荡并收敛。

因为机器学习已经在最优化问题上有了不同的共识，论文已经变得有些难读了，所以我们不会讨论论文里的那些符号。但我们可以用当代 Jax 代码复现下他们 30 年前的思想。

```python
def lagrangian(θ, λ, ε):
 damp = 10 * stop_gradient(ε-loss_2(θ))
 return loss_1(θ) - (λ-damp) * (ε-loss_2(θ))

derivative = grad(lagrangian, (0,1))
ε = 0.7
λ = 0.0

for gradient_step in range(200):
  gradient_θ, gradient_λ = derivative(θ, λ, ε)
  θ = θ - 0.02 * gradient_θ
  λ = λ + gradient_λ
  if λ < 0:
    λ = 0
```

如下图所示，该方法无论对凸帕累托边界还是凹帕累托边界都适用且效果很好。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_the_modified_differential_method_of_multipliers_convex_pareto.gif)

*图 15  凸帕累托边界下的改良微分乘数法*

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2021-02-08_the_modified_differential_method_of_multipliers_concave_pareto.gif)

*图 16  凹帕累托边界下的改良微分乘数法*

该方法确实有个小缺点，即多了个阻尼超参数。多出来的这个参数要权衡找到帕累托边界的时间和收敛到边界上解的时间。注意阻尼参数并不改变找到的解，只影响多快能找到解。

但是，“哦不，不是额外超参数”的想法只会把水搅浑。**这是第一次我们有了一个对随机梯度下降也有效的可调试算法！**可以用有语义的方式通过梯度下降使用这个改良版微分乘数法来调节损失间的平衡，*无论未知的帕累托边界是个什么形状。*

以我们有限的经验来讲，该方法应该被多用些。实际上，我们推测无论你在哪看到了用梯度下降优化的线性组合损失，都可以用用这个更有原则性的方法。

在当前正在使用线性组合损失的场景中，将问题以约束形式进行重构可以得到更通用、可调试的算法。
