---
layout:		post
title:  	你该知道的卷积神经网络
subtitle:   CNN 速览
date:       2019-10-19
author:     一轩明月
header-img: img/post-bg-computer-vision.jpg
catalog: 	 true
tags:
    - CV
excerpt:    卷积神经网络 CNN 是神经网络家族的重要成员，主要用于图像识别，图像分类。物体检测和人脸识别等领域都是 CNN 的天下。本文从输入端到输出端顺序了介绍 CNN 基本概念与期间的优化举措，同时为了规避数学公式，使用了大量图示形象化 CNN 背后思想
---

> 文章编译自：
>
> https://towardsdatascience.com/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148

卷积神经网络（Convolutional Neural Network, CNN/ConvNets）是神经网络家族的重要成员，主要用于图像识别，图像分类。物体检测和人脸识别等领域都是 CNN 的天下。

图像分类任务中，输入一个图像，CNN 会进行处理并将其划归到某个类别（猫，狗，老虎等等）。计算机的眼里没有所谓的图像，都是像素数组，具体数值视分辨率而定。给定分辨率后，图像就会被 height × width × dimension 的矩阵数组表示。比如一张用 6 × 6 × 3 的 RGB 矩阵表示的图片，3 表示 RGB 的值，用 4 × 4 × 1 的矩阵数组表示的一张灰度图。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-10-19_rgb_matrix.png)

技术上讲，CNN 模型训练和预测过程中，每张图像都会走过一连串带有过滤器（核心）的卷积层，经池化（pooling）到达全连接层（fully connected layer,FC），最后经 softmax 函数激活得到介于 [0,1] 的预测概率值，并以此估计对象类别。整个流程如下图所示。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-10-19_cnn_flow.png)

## 卷积层

卷积是网络第一层，用于从图像中抽取特征。卷积通过特征学习使用小数据方块保留像素间关系，实质上是像素矩阵和过滤器间一种数学运算。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-10-19_img_filter_multi.png)

比如，现有 5 × 5 的 0-1 像素矩阵和 3 × 3 的过滤矩阵

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-10-19_5_mut_3.png)

像素矩阵的卷积与过滤矩阵相乘的操作叫做**特征映射**，结果如下图所示

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-10-19_5_3_output.gif)

卷积搭配不同的过滤方法可以对图像进行边缘检测，模糊和锐化等操作。下方图例展示了经不同过滤器处理后各种卷积图像的样子。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-10-19_common_filter.png)

## 步长

步长指定了每次在输入矩阵上跨过的像素个数。步长为 1，每次过滤器移动 1 个像素，步长为 2，那每次过滤器就移动 2 个像素，以此类推。下图展示了步长为 2 时卷积操作的样子

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-10-19_stride.png)

## 填充

有时过滤器抽取图片特征不理想。有两个选择：

1. 用 0 填充图像提升抽取效果。这种方法叫零填充
2. 丢弃拟合不理想的部分。这种叫有效填充，即只保留图像有效部分

## 非线性

开头流程图中有个叫 ReLU 的家伙，全称是非线性整流单元（Rectified Linear Unit for a non-linear operation)。运算规则是 $$f(x)=\max(0,x)$$

ReLU 的重要之处在于将非线性引入了 CNN。因为现实中，我们希望卷积神经网络接收的数据都是非负线性值。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-10-19_ReLU.png)

当然还有类似 tanh 或 sigmoid 这样的非线性函数可以替代 ReLU。但多数数据科学家使用 ReLU 因为性能比那两个好。

## 池化层

当图像太大，参数过多，会使用池化层（pooling layer）降低参数数量进行降维。空间池化又叫做下采样或子采样，缩减了映射维度又保留了重要信息。空间池化有多种选择：

- 最大池化法
- 平均池化法
- 加和池化法

最大池化法会从整型后的特征映射中选取最大的元素。如果要选最大元素用平均池化法也可以。对所有元素值累加求和则是加和池化法

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-10-19_5_max_pooling.png)

## 全连接层

简称 FC 层，我们将矩阵扁平化为向量传入全连接层，通常是一个神经网络。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-10-19_5_fc_layer.png)

上图中，特征映射矩阵被转换为向量 $$x_1,x_2,\ldots,x_n$$。通过全连接层将这些特征组合起来以创建模型。最后我们通过 softmax 或 sigmoid 这样的一个激活函数对结果分类，比如是猫、狗、鸡等等。

![](https://raw.githubusercontent.com/LibertyDream/diy_img_host/master/img/2019-10-19_5_complete_arch_cnn.png)

## 流程总结

- 将输入图像送入卷积层
- 选择参数，定好步长用过滤器过滤，看看是否需要填充。对图像卷积并用 ReLU 对矩阵整型
- 进行池化以降低维度
- 添加卷积层直到结果差强人意
- 将输出扁平化送入 FC 层
- 通过激活函数（带损失函数的逻辑回归）得到输出类别，完成图像分类