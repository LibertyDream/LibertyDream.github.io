---
layout:     post
title:      善用命令行工具可以比 Hadoop 集群快235倍
subtitle:   简单工具用到极致同样高效
date:       2019-07-20
author:     一轩明月
header-img: img/post-bg-computer-vision.jpg
catalog: 	 true
tags:
    - trick
    - command-line tools
---

```html
<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>
```

# 善用命令行工具可以比 Hadoop 集群快235倍

> 文章编译自：
>
> https://adamdrake.com/command-line-tools-can-be-235x-faster-than-your-hadoop-cluster.html

## 引言

不经意的一次的网上冲浪中我看到了 Tom Hayden 的一篇很酷的文章，文章借助 Amazon Elastic MapReduce（EMR）和 mrjob（_ps:一个 python MapReduce 计算库_） 统计国际象棋的输赢概率，棋局数据来自于 millionbase archive（_ps:存储了大量 pgn 格式棋局的网络数据库_），人们经常用 EMR 来处理这些数据。因为数据量只有 1.75G左右，大概 200 万局比赛，这种体量的数据用 Hadoop 来跑让我有些疑问，但我能理解他想学习和玩一玩 mrjob 和 EMR 的初心。

鉴于所要解决的问题只是获取每个文件的 result 行信息并统计一下差异，似乎用 shell 命令进行流处理更合适些。按照这个想法我进行了实践，同规模数据在我的笔记本电脑上12s能得到结果（处理速度 270MB/秒左右），而用  Hadoop 进行运算花了 26 分钟（处理速度 1.14MB/秒 左右）。

7 台 c1.medium 机器组成的集群处理数据花费26分钟，Tom 记录数据后评论说：

> 这可能比我本地串行处理要快，但大概比不上本地并行计算的效率

这无疑是正确的，尽管串行计算都可能比26分钟要快。虽然 Tom 做这个项目只是一时兴起，但是用 Hadoop 和其他的所谓大数据工具来解决工程环境下的计算和分析任务，人们通常认为这会比用简单工具和其他技术要快。

而用标准 shell 工具和命令处理数据的实力被人们低估了。这种方法的一大优势在于规模化，因为使用 shell 命令建立数据管道意味着所有处理步骤都能同步进行。甚至Spouts，Bolts 和 Sinks 这些概念也被移植到了 shell 管道和相关命令上。相比于现下流行的多数大数据工具，通过基本命令构建一个流处理管道不仅性能优异且实现简单。

另一点差别在于批处理和流式分析法。Tom 提到加载了 10000 局比赛并进行本地分析后，他的内存容量已经见底了。这是因为所有的数据分析前都要加载到内存里。但是仔细思考一下所面对的问题，用流式处理可以轻松搞定而且几乎不要什么内存。我们构建的数据处理管道在不怎么需要内存的情况下比 Hadoop 方法快 235 倍。

## 了解数据

首先我们要能从 PGN 文件里把数据读出来。因为我对这种格式没什么概念，上维基百科查了一下。

```
[Event "F/S Return Match"]
[Site "Belgrade, Serbia Yugoslavia|JUG"]
[Date "1992.11.04"]
[Round "29"]
[White "Fischer, Robert J."]
[Black "Spassky, Boris V."]
[Result "1/2-1/2"]
(moves from the game follow...)
```

我们关心的只是比赛结果，所以只有3种局面。1-0 意味着白棋胜，0-1 意味着黑棋胜，$\frac {1}{2}$-$\frac {1}{2}$ 意味着平局。还有一种情景是比赛仍在进行或者无法计分，这种情形不影响我们的任务所以忽略。

## 获取样本数据

了解格式后我们得搞到大量比赛数据，后来证实这比我想象的要困难。网上找了一圈后我找到了一个 Git 仓库 [rozim](https://github.com/rozim/ChessData) ，这里有大量比赛记录。我用这个库编译了一个 3.46G 的数据集，这大概是 Tom 进行试验数据集的两倍大小。下一步就是把数据导入我们的管道了。

## 构建处理管道

_如果你要跟踪进程并计算处理时间，别忘了清空系统页面缓存，否则你得到的处理时间不准_

shell 命令十分适于数据处理管道是因为它是自动并行化的。如果不信的话可以通过下面这个例子感受一下。

```shell
sleep 3 | echo "Hello world"
```

直觉告诉你上面的指令执行时应该是睡眠3秒，然后打印`Hello world`，但实际上这两步是同时进行的。这一基本事实可以给那些在单个机器上运行的、非 IO 绑定的处理系统带来十分可观的加速效果。

开始分析管道前，我们可以为管道处理速度找一个参照标准。这里我们设定为数据导入 `/dev/null`的速度。

```shell
cat .*pgn > /dev/null
```

这种情况下，共花费 13 秒传输完毕 3.46GB内容，大概 272MB/秒。这已经是这个系统在IO限制条件下能达到的数据处理速度上限了。

现在我们开始分析管道，首先要使用`cat`生成数据流

```shell
cat *.pgn
```

因为我们只对结果行感兴趣，我们可以快速扫描所有文件，用`grep`摘出所有带有`Results`的行

```shell
cat *.pgn | grep "Result"
```

这样我们就得到了文件中所有的`Result`行。如果愿意，现在可以使用`sort`和`uniq`命令对文件中的每一项按照其数量排序

```shell
cat *.pgn | grep "Reslut" | sort | uniq -c
```

这是十分直观的分析管道，大概70秒左右得到结果。我们当然可以做的更好，假设我们将这一过程线性推广到 Hadoop 集群上进行处理大概会花费 52 分钟。

为了更快的速度，我们将`sort | uniq`步骤摘去，替换为 AWK，这是一个很棒的基于事件的数据处理语言/工具。

```shell
cat *.pgn | grep "Result" | awk '{split($0, a, "-"); res = substr(a[1], length(a[1]), 1); if(res == 1) white++; if(res == 0) black++; if(res == 2) draw++;}END{print white+black+draw, white, black,draw}'
```

这条命令会将每条记录以连字符为分隔符切开，而后将字符传递给左侧，黑子获胜为0，白子获胜为1，平局则是2。注意`$0`是一个内置变量，表示整个记录

这一命令将运行时长压缩到了 65 秒，并且因为我们处理的是两倍的数据，算下来大概取得了 47 倍的加速效果。

即使到了这一步我们已经通过粗糙的本地方案得到了47倍的加速效果。此外，因为存储的只是计数数据，所以内存实际消耗为0，而多存3个整数对于内存空间来说可以忽略不计。

## 并行化瓶颈

为了充分使用计算核心，可以使用`xargs`命令，它能让我们并行执行`grep`。`xargs`要以特定格式输入，使用带`-print0`参数的`find`命令可以更快、更安全的保证将空值结尾的文件传给`xargs`。`-0`告诉`xargs`要接收空值结尾的输入。此外，`-n`指明每个进程有几个输入，`-P`表示并行运行的进程数量。同样需要你知晓的是，这样的并行管道不保证交付顺序，但如果你熟悉分布式处理系统，这就不是问题了。`-F`告诉`grep`我们只匹配固定字符串不做花里胡哨的正则匹配，这能再稍微加速一些，但我测试时没有感觉到。

```shell
find . -type f -name '*.pgn' -print0 | xargs -0 -n1 -P4 grep -F "Result" | gawk '{ split($0, a, "-"); res = substr(a[1], length(a[1]), 1); if (res == 1) white++; if (res == 0) black++; if (res == 2) draw++;} END { print NR, white, black, draw }'
```

这回运行时长在 38 秒左右，与在我们的管道内并行化`grep`数据处理前相比减少了40%的时间。这样我们比 Hadoop 实现快了大概77倍。

尽管我们通过在管道内并行化`grep`巨幅改善了性能，但我们实际可以将这部分全部删除，让`awk`过滤输入的记录，只处理带有"Result"字符串的记录。

```shell
find . -type f -name '*.pgn' -print0 | xargs -0 -n1 -P4 awk '/Result/ { split($0, a, "-"); res = substr(a[1], length(a[1]), 1); if (res == 1) white++; if (res == 0) black++; if (res == 2) draw++;} END { print white+black+draw, white, black, draw }'
```

你可能觉得这样就对了，但这会将每个文件的结果单独输出，而我想要全部的统计结果。对这一结果的修正过程十分像 MapReduce。

```shell
find . -type f -name '*.pgn' -print0 | xargs -0 -n4 -P4 awk '/Result/ { split($0, a, "-"); res = substr(a[1], length(a[1]), 1); if (res == 1) white++; if (res == 0) black++; if (res == 2) draw++ } END { print white+black+draw, white, black, draw }' | awk '{games += $1; white += $2; black += $3; draw += $4; } END { print games, white, black, draw }'
```

通过在最后再执行一次 awk 我们得到了我们希望的统计信息。

这进一步巨幅改善了加速效果，只要18秒左右，大概174倍于 Hadoop 实现。

但我们可以使用`mawk`让它再快一点，`mawk`通常是`gawk`的直接代替品并且性能更好。

```shell
find . -type f -name '*.pgn' -print0 | xargs -0 -n4 -P4 mawk '/Result/ { split($0, a, "-"); res = substr(a[1], length(a[1]), 1); if (res == 1) white++; if (res == 0) black++; if (res == 2) draw++ } END { print white+black+draw, white, black, draw }' | mawk '{games += $1; white += $2; black += $3; draw += $4; } END { print games, white, black, draw }'
```

这个`find | xargs mawk | mawk`管道让我们的运行时长减到了12秒左右，大概235倍于 Hadoop 实现。

## 总结

希望这篇文章已经说清了使用和滥用像 Hadoop 这样的工具进行数据处理时的一些问题，这些任务其实可以在一台机器上用简单的 shell 命令和工具更好的解决。如果你有大量数据要处理，或者真的要分布式处理，那么可能需要上 Hadoop，但是最近我经常看到一些使用 Hadoop 的场景，如果用传统的关系数据库或其他解决方案，无论性能、实现成本和持续维护性上都会好很多。