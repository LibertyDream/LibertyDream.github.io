---
layout:		post
title:  	模型部署时的接口设计
subtitle:   模型部署系列之二
date:       2020-03-01
author:     一轩明月
header-img: img/post-bg-hacker.jpg
catalog: 	 true
tags:
    - opinions
---

[前篇](https://libertydream.github.io/2020/02/23/模型部署到底是在说什么/)文章主要讨论了模型部署的真实含义，我们讲为了用户和其他软件模块能用上训练模型的预测结果，我们得考虑预测频率，每次预测一个还是一批，延迟性需求在内的诸多因素。本文开始讨论部署模型中的具体实施过程是怎样的。

鉴于许多博文直接走向 Flask API 实现或是使用一些流程调度工具，不妨从更基础的层面开始说起——接口。软件接口一贯被视为软件模块间的边界，一个模块是一个拼图，整个软件系统就是整幅拼图。设计精良的接口能方便你与其它模组间进行沟通，更易于构建大型复杂项目。就机器学习模型部署而言，好接口设计更利于实现模型的重用性、自动化以及即插即用的性能追求。同时，好接口也令模型更新、版本控制更加简便。

## 什么是接口？

假设经理让一个雇员起草一份报告。好经理可能会说：“需要你起草份报告，需要有这几张图和这几个表。你可能要用客户交易数据。”经理明确指定了期望结果（报告），并提示了实现方式（可以用客户交易数据）。

反之，差经理可能会出现下列问题：

- **输入不明确**。索要报告但不告诉基于哪个数据集做，也不告诉雇员哪些人可能知道报告所需数据的获取方式。
- **交付结果不清晰**。给了雇员一堆数据却没告诉他要实现什么。
- **过度管理**。告诉雇员作报告要用什么工具，操作步骤有哪些，还警告任何计划外的偏差都会受到处分

[软件接口](https://blog.robertelder.org/interfaces-most-important-software-engineering-concept/)就像经理。好的接口会清晰地阐述必须的输入有哪些，接口又会输出什么结果。比如函数做接口会列出所有需要的参数，并说清函数返回内容。接口可以被理解为不同软件模块间的“边界”，规定了不同模块互相沟通的规则。接口设计好的话，不同软件甚至是来自不同公司，不同团队开发的软件，互相都能相互协作完成任务。

软件工程师经常被教导要多关注他们开发的接口而不是函数方法的实现细节。实现是很重要，但总是可以更新的。但接口一经发布可就比更改实现难多了，特别是接口对外开放的时候。所以花时间定义一个好接口是值得的。

## 基本接口

软件工程师会怎么看待机器学习模型所做的工作呢？概括地讲，就是一个模型接收数据，以某种方式处理数据然后返回一个结果，就这么简单。模型处理数据地具体方式可以很复杂，比如会构建一个前馈卷积网络对图像张量进行卷积，但这都是实现细节了。

机器学习模型的边界由模型输入，也就是特征集合，和要返回的预测结果两部分组成。所以好接口也必须是基于输入特征和预测结果设计的。举一个简单的函数接口例子

```python
def predict(model, input_features):
    '''
    模型预测方法，接收一个模型和输入特征，返回预测结果
    
    参数：
    ------
    model：
    	某个机器学习模型
    input_features:
    	模型预测所需要的特征,是(1,n)的 Numpy 数组，n 代表特征向量维度
    	
    返回值：
    ------
    prediction：
    	模型预测结果，(1,)格式的 Numpy 数组
    '''
```

该函数接收一个模型 `model` 和一组特征 `input_features`，返回预测结果 `prediction`。注意我们并没有 _实现_ 这一方法，也就是说我们没有写模型会 _怎样_ 处理传入特征来获取预测结果。我们只是建立了一个协议或是约定——如果调用者提供了 `model` 和 `input_features` ，我们保证该方法会返回一个预测结果 `prediction`

## 批处理接口设计

上面定义的`predict()`方法一次只接收一个特征向量，返回一个结果。怎么知道这一点的？注释文档中指出 `input_features` 是一个大小为 `(1, n)` 的 Numpy 数组，`n` 是特征向量的维数。如果只是期望模型每次对一个样本做预测或许这就足够了，但如果想要该模型可以对一批样本进行预测那就还需要做点改进。写个循环不断重复或许可以解决，但这样效率不会很高。相对的，你该为此定义一个方法专门用于批量处理。比如说叫 `predict_batch`:

```python
def predict_batch(model, batch_input_features):
    '''
    	对一批样本进行处理的方法
    
    参数：
    --------------
    model：
    	某个机器学习模型
    batch_input_features:
    	模型预测所需的一组特征，为 (m, n) 的 Numpy 数组，m 表示样本数，n 则是特征向量维数
    	
    返回值：
    --------------
    predictions:
    	模型预测结果，(m,)的 Numpy 数组
    '''
```

新方法保证如果给予一批输入特征，它会返还相应的一组预测结果。这里我们依旧没有具体实现方法——留给开发工程师们去做吧。开发人员可能会选择写一个循环不断调用 `predict` ，也许是另一种实现方式。这都与部署目标无关了。重要的是我们有了两个接口：一个对单个样本做预测，另一个对一批数据样本做预测。

## 面向对象编程-MLOOP

目前为止我们都忽略了 `model` 这个无论是 `predict` 还是 `predict_batch` 都需要的参数。稍微解释一下其中的问题在哪。

今天，绝大多数部署机器学习模型的工程师都倾向于使用手头最好的工具。如果正在搭建的是一个传统模型，比如逻辑回归或是随机森林，工程师们可能会选择使用 [scikit-learn](https://scikit-learn.org/stable/)。要是是深度学习工程师可能会选择 [Tensorflow](https://www.tensorflow.org/) 或 [PyTorch](https://pytorch.org/)。经典模型另一个可能的选择是 [xgboost](https://xgboost.readthedocs.io/en/latest/) ，基于梯度提升树实现。每个库的模型对象的 API 都略有不同。我们无法预测将来这些模型库又会实现什么 API。这会造成我们的接口看起来混乱没有章法。比如说，我们着实不期望我们的实现是这个样子：

```python
def predict(model, input_features):
    ...
    if isinstance(model, sklearn.base.BaseEstimator)
    	...
    elif isinstance(model, xgboost.core.Booster)
    	...
    elif isinstance(model, tensorflow.keras.Model)
    	...
    elif isinstance(model, torch.nn.module)
    	...
    ...
```

这种实现既难以维护又难以调试。试想如果我们想传参数给某个特定模型的场景。比如说，我们只想传参数给 sklearn 模型来进行预测，函数接收的参数个数随之增长，但这些参数对 sklearn 意外的模型来说毫无意义。我们在文档里又该怎么解释这一切呢？这也是推荐使用面向对象编程，构造类和对象解决问题的部分原因。

我们的接口包含两个方法：`predict` 和 `predict_batch`。用这两个方法构造一个基类

```python
class Model:
    def __init__(self, model):
        self.model = model
    
    def predict(input_features):
    '''
    模型预测方法，接收样本数据并返回预测结果
    
    参数：
    ------
    input_features:
    	模型预测所需要的特征，为(1,n)大小的 Numpy 数组，n 代表特征向量维度
    	
    返回值：
    ------
    prediction：
    	模型预测结果，(1,)格式的 Numpy 数组
    '''
    	raise NotImplementedError
    
    def predict_batch(model, batch_input_features):
    '''
    	对一批样本进行处理的方法
    
    参数：
    --------------
    batch_input_features:
    	模型预测所需的一组特征，为 (m, n) 大小的 Numpy 数组，m 表示样本数，n 是特征向量维数
    	
    返回值：
    --------------
    prediction:
    	模型预测结果，为(m,1)大小的 Numpy 数组
    '''
    	raise NotImplementedError
```

我们的数据科学团队可以将该基类作为模板。如果某个数据科学家想用 scikit-learn 模型，只需要继承 `Model` 实现必要的方法即可。另一个工程师想用 Tensorflow？没问题，创建一个 Tensorflow 子类就行。下面是 sklearn 子类的样例代码

```python
class SklearnModel(Model):
    def __init__(self, model):
        super().__init__(model)
        
    def predict(self, input_features):
        y = self.model.predict(input_features.reshape(1, -1))
        return y
   	
    def predict_batch(self, batch_input_features):
        ys = self.model.predict(batch_input_features)
        return ys
```

因为  sklearn 的预测器 `Predictors` 需要的是二维输入，所以我们要在 `predict` 方法内对 `input_features` 做个变形。这是面向对象方法的巨大优势之一。我们可以定制和当下问题相关的接口类型，同时可以充分利用[优质第三方机器学习库](https://github.com/EthicalML/awesome-production-machine-learning)

此外我们还可以添加一些能够简化工作流程的方法。比如说，当模型训练好了之后我们需要一种方法将其序列化，预测推理时候再反序列化回来，因此我们向接口中添加 `serialize()` 和 `deserialize()` 两个方法。我们甚至可以在基类 `Model` 当中提供这些方法的默认实现并创建一个库指定不同子类当中的实现。还有一些有用的接口方法，像将序列化模型从本地传输到远程存储系统，加什么方法都可以。

预先设计好精良的接口会为你的机器学习团队节省大量的时间，自动化部署和良好的复用性对承接其他项目提供了有力保障。

## 总结

本文给出了软件接口的定义，简单举了一个机器学习模型接口设计的例子，我们说这些接口有利于部署模型，但还没讲到怎么做。下一篇文章就来探讨怎么利用这些接口实现批量推断，每次对一批样本进行预测。批量推断在要周期性预测计算的场景下是首选策略。